// src/app/mod.rs
// --------------
// src/app/mod.rs
// --------------
//
// Only change here is that ClipmapUpload now has x/y/w/h, so this compiles.

use std::sync::Arc;
use std::time::Instant;

use winit::{
    event::*,
    event_loop::{ControlFlow, EventLoop},
    window::Window,
};

use crate::{
    camera::Camera,
    clipmap::Clipmap,
    config,
    input::InputState,
    render::{CameraGpu, ClipmapGpu, OverlayGpu, Renderer},
    streaming::ChunkManager,
    world::WorldGen,
};

pub async fn run(event_loop: EventLoop<()>, window: Arc<Window>) {
    let mut app = App::new(window).await;

    event_loop
        .run(move |event, elwt| {
            elwt.set_control_flow(ControlFlow::Wait);

            match &event {
                Event::AboutToWait => {
                    app.window.request_redraw();
                }
                Event::WindowEvent {
                    event: WindowEvent::RedrawRequested,
                    ..
                } => {
                    app.frame(elwt);
                }
                _ => {
                    app.handle_event(event, elwt);
                }
            }
        })
        .unwrap();
}

pub struct App {
    window: Arc<Window>,
    start_time: Instant,

    _instance: wgpu::Instance,
    surface: wgpu::Surface<'static>,
    _adapter: wgpu::Adapter,
    _surface_format: wgpu::TextureFormat,
    config: wgpu::SurfaceConfiguration,

    renderer: Renderer,

    world: Arc<WorldGen>,
    chunks: ChunkManager,

    clipmap: Clipmap,

    input: InputState,
    camera: Camera,

    fps_value: u32,
    fps_frames: u32,
    fps_last: Instant,
}

impl App {
    pub async fn new(window: Arc<Window>) -> Self {
        let start_time = Instant::now();
        let size = window.inner_size();

        let instance = wgpu::Instance::default();
        let surface = instance.create_surface(window.clone()).unwrap();

        let adapter = instance
            .request_adapter(&wgpu::RequestAdapterOptions {
                compatible_surface: Some(&surface),
                power_preference: wgpu::PowerPreference::HighPerformance,
                force_fallback_adapter: false,
            })
            .await
            .unwrap();

        let surface_caps = surface.get_capabilities(&adapter);
        let surface_format = surface_caps.formats[0];

        let config_sc = wgpu::SurfaceConfiguration {
            usage: wgpu::TextureUsages::RENDER_ATTACHMENT,
            format: surface_format,
            width: size.width.max(1),
            height: size.height.max(1),
            present_mode: surface_caps.present_modes[0],
            alpha_mode: surface_caps.alpha_modes[0],
            view_formats: vec![],
            desired_maximum_frame_latency: 2,
        };

        let renderer =
            Renderer::new(&adapter, surface_format, config_sc.width, config_sc.height).await;

        surface.configure(renderer.device(), &config_sc);

        let world = Arc::new(WorldGen::new(12345));
        let chunks = ChunkManager::new(world.clone());

        let camera = Camera::new(config_sc.width as f32 / config_sc.height as f32);
        let input = InputState::default();

        let clipmap = Clipmap::new();

        Self {
            window,
            start_time,
            _instance: instance,
            surface,
            _adapter: adapter,
            _surface_format: surface_format,
            config: config_sc,
            renderer,
            world,
            chunks,
            clipmap,
            input,
            camera,
            fps_value: 0,
            fps_frames: 0,
            fps_last: Instant::now(),
        }
    }

    pub fn handle_event(
        &mut self,
        event: Event<()>,
        elwt: &winit::event_loop::EventLoopWindowTarget<()>,
    ) {
        match event {
            Event::DeviceEvent { event, .. } => {
                self.input.on_device_event(&event);
            }

            Event::WindowEvent { event, .. } => {
                let _ = self.input.on_window_event(&event, &self.window);

                match event {
                    WindowEvent::CloseRequested => elwt.exit(),

                    WindowEvent::Resized(new_size) => {
                        self.config.width = new_size.width.max(1);
                        self.config.height = new_size.height.max(1);

                        self.surface.configure(self.renderer.device(), &self.config);
                        self.renderer
                            .resize_output(self.config.width, self.config.height);

                        // IMPORTANT: the resize recreated clip_height, so force reupload next frame
                        self.clipmap.invalidate_all();
                    }

                    _ => {}
                }
            }

            Event::AboutToWait => self.frame(elwt),

            _ => {}
        }
    }

    fn frame(&mut self, elwt: &winit::event_loop::EventLoopWindowTarget<()>) {
        // 1) camera integrate
        self.camera.integrate_input(&mut self.input);

        // 2) streaming update
        let cam_pos = self.camera.position();
        let cam_fwd = self.camera.forward();
        let grid_changed = self.chunks.update(&self.world, cam_pos, cam_fwd);
        if grid_changed {
            self.renderer.write_chunk_grid(self.chunks.chunk_grid());
        }

        // 3) clipmap update + uploads
        let t = self.start_time.elapsed().as_secs_f32();
        let (clip_params_cpu, clip_uploads) = self.clipmap.update(self.world.as_ref(), cam_pos, t);

        let clip_gpu = ClipmapGpu::from_cpu(&clip_params_cpu);
        self.renderer.write_clipmap(&clip_gpu);

        for up in clip_uploads {
            self.renderer
                .write_clipmap_patch(up.level, up.x, up.y, up.w, up.h, &up.data_f16);
        }

        // 4) camera matrices -> CameraGpu
        let aspect = self.config.width as f32 / self.config.height as f32;
        let cf = self.camera.frame_matrices(aspect);

        let max_steps = (config::CHUNK_SIZE * 2).clamp(64, 256);

        let cam_gpu = CameraGpu {
            view_inv: cf.view_inv.to_cols_array_2d(),
            proj_inv: cf.proj_inv.to_cols_array_2d(),
            cam_pos: [cf.pos.x, cf.pos.y, cf.pos.z, 1.0],

            chunk_size: config::CHUNK_SIZE,
            chunk_count: self.chunks.chunk_count(),
            max_steps,
            _pad0: 0,

            voxel_params: [config::VOXEL_SIZE_M_F32, t, 2.0, 0.003],

            grid_origin_chunk: [
                self.chunks.grid_origin()[0],
                self.chunks.grid_origin()[1],
                self.chunks.grid_origin()[2],
                0,
            ],
            grid_dims: [
                self.chunks.grid_dims()[0],
                self.chunks.grid_dims()[1],
                self.chunks.grid_dims()[2],
                0,
            ],
        };

        self.renderer.write_camera(&cam_gpu);

        // 5) fps overlay
        self.fps_frames += 1;
        let dt = self.fps_last.elapsed().as_secs_f32();
        if dt >= 0.25 {
            let fps = (self.fps_frames as f32) / dt;
            self.fps_value = fps.round() as u32;
            self.fps_frames = 0;
            self.fps_last = Instant::now();
        }

        let overlay = OverlayGpu {
            fps: self.fps_value,
            width: self.config.width,
            height: self.config.height,
            _pad0: 0,
        };
        self.renderer.write_overlay(&overlay);

        // 6) update scene buffers if changed
        self.renderer.apply_chunk_uploads(self.chunks.take_uploads());

        // 7) acquire frame + encode passes
        let frame = match self.surface.get_current_texture() {
            Ok(f) => f,

            Err(wgpu::SurfaceError::Lost | wgpu::SurfaceError::Outdated) => {
                self.surface.configure(self.renderer.device(), &self.config);
                return;
            }

            Err(wgpu::SurfaceError::Timeout) => return,

            Err(wgpu::SurfaceError::OutOfMemory) => {
                elwt.exit();
                return;
            }
        };

        let frame_view = frame.texture.create_view(&Default::default());

        let mut encoder = self
            .renderer
            .device()
            .create_command_encoder(&wgpu::CommandEncoderDescriptor {
                label: Some("encoder"),
            });

        self.renderer
            .encode_compute(&mut encoder, self.config.width, self.config.height);

        self.renderer.encode_blit(&mut encoder, &frame_view);

        self.renderer.queue().submit(Some(encoder.finish()));
        frame.present();
    }
}

// src/camera.rs
// -------------
// src/camera.rs
use glam::{Mat4, Vec3};

use crate::{config, input::InputState};

pub struct Camera {
    pos: Vec3,
    yaw: f32,
    pitch: f32,
    fovy_rad: f32,
    z_near: f32,
    z_far: f32,
    // movement tuning
    speed_per_frame: f32,
    mouse_sens: f32,
}

pub struct CameraFrame {
    pub view_inv: Mat4,
    pub proj_inv: Mat4,
    pub pos: Vec3,
}

impl Camera {
    pub fn new(aspect: f32) -> Self {
        let _ = aspect; // kept for future (if you want aspect-dependent params)
        Self {
            pos: Vec3::new((config::CHUNK_SIZE as f32 * config::VOXEL_SIZE_M_F32) * 0.5, 20.0, -20.0),
            yaw: 0.0,
            pitch: 0.15,
            fovy_rad: 60.0_f32.to_radians(),
            z_near: 0.1,
            z_far: 1000.0,
            speed_per_frame: 0.35,
            mouse_sens: 0.0025,
        }
    }

    pub fn position(&self) -> Vec3 {
        self.pos
    }

    pub fn forward(&self) -> glam::Vec3 {
        let (yaw, pitch) = (self.yaw, self.pitch);
        glam::Vec3::new(
            yaw.sin() * pitch.cos(),
            pitch.sin(),
            yaw.cos() * pitch.cos(),
        )
        .normalize()
    }

    pub fn integrate_input(&mut self, input: &mut InputState) {
        // mouse look
        if input.focused {
            let (dx, dy) = input.take_mouse_delta();
            self.yaw -= dx * self.mouse_sens;
            self.pitch = (self.pitch - dy * self.mouse_sens).clamp(-1.55, 1.55);
        } else {
            // still clear deltas
            let _ = input.take_mouse_delta();
        }

        // basis
        let forward = Vec3::new(
            self.yaw.sin() * self.pitch.cos(),
            self.pitch.sin(),
            self.yaw.cos() * self.pitch.cos(),
        )
        .normalize();

        let right = forward.cross(Vec3::Y).normalize();
        let up = right.cross(forward).normalize();

        // movement (per-frame like your original)
        let k = input.keys;
        let mut vel = Vec3::ZERO;
        if k.w { vel += forward; }
        if k.s { vel -= forward; }
        if k.d { vel += right; }
        if k.a { vel -= right; }
        if k.space { vel += up; }
        if k.alt { vel -= up; }

        if vel.length_squared() > 0.0 {
            self.pos += vel.normalize() * self.speed_per_frame;
        }
    }

    pub fn frame_matrices(&self, aspect: f32) -> CameraFrame {
        let forward = Vec3::new(
            self.yaw.sin() * self.pitch.cos(),
            self.pitch.sin(),
            self.yaw.cos() * self.pitch.cos(),
        )
        .normalize();

        let view = Mat4::look_at_rh(self.pos, self.pos + forward, Vec3::Y);
        let proj = Mat4::perspective_rh(self.fovy_rad, aspect, self.z_near, self.z_far);

        CameraFrame {
            view_inv: view.inverse(),
            proj_inv: proj.inverse(),
            pos: self.pos,
        }
    }
}

// src/clipmap.rs
// --------------
// src/clipmap.rs
// --------------
//
// CPU-updated 2D clipmap height texture data (nested levels around camera).
//
// FP16 OPTIMIZATION:
// - Each level stores CLIPMAP_RES * CLIPMAP_RES heights in *half float* (u16 bits).
// - This halves upload bandwidth and reduces VRAM traffic.
// - WGSL textureLoad still returns f32 when sampling R16Float.
//
// Strategy (ring clipmap / strip updates):
// - Each level is a CLIPMAP_RES x CLIPMAP_RES height map (meters) stored as a TORUS.
// - Level i has cell size = CLIPMAP_BASE_CELL_M * 2^i.
// - We "snap" the *logical* origin (world cell coords) to cell boundaries for stability.
// - When the origin changes by a small delta (dx,dz in cells), we DO NOT full refresh.
//   Instead we:
//     1) advance a per-level torus offset (texel origin) by (dx,dz)
//     2) upload only the newly exposed rows/columns as strip patches
// - Shader maps world->logical texel (0..res-1) then applies torus offset modulo res.
//
// Uniform packing (per level):
// - We keep the clipmap uniform array as vec4<f32> per level.
// - We store:
//     x = origin_x_m
//     y = origin_z_m
//     z = cell_size_m
//     w = packed offsets (u16 off_x | (u16 off_z << 16)) bitcast via f32 bits
// - We KEEP inv_cell_size_m on CPU side for any legacy uses, but shader can compute 1/cell.
//

use glam::Vec3;

use crate::{config, world::WorldGen};

#[derive(Clone, Copy, Debug)]
pub struct ClipLevelParams {
    pub origin_x_m: f32,
    pub origin_z_m: f32,
    pub cell_size_m: f32,
    pub inv_cell_size_m: f32,
    /// Packed torus offsets: off_x in low 16 bits, off_z in high 16 bits.
    pub packed_offsets: u32,
}

/// CPU-side clipmap params (fed into GPU packing in `render/gpu_types.rs`).
#[derive(Clone, Copy, Debug)]
pub struct ClipmapParamsCpu {
    pub levels: u32,
    pub res: u32,
    pub base_cell_m: f32,
    pub _pad0: f32,
    pub level: [ClipLevelParams; config::CLIPMAP_LEVELS_USIZE],
}

/// A sub-rectangle upload into a clipmap level texture layer.
///
/// IMPORTANT: this struct used to be `{ level, data_f16 }` in your tree, which is
/// why you were seeing the E0609 errors. Ring/strip updates require the rect.
pub struct ClipmapUpload {
    pub level: u32,
    pub x: u32,
    pub y: u32,
    pub w: u32,
    pub h: u32,
    /// w*h heights, FP16 bits (IEEE-754 half), row-major for the patch.
    pub data_f16: Vec<u16>,
}

pub struct Clipmap {
    last_origin_cell: [(i32, i32); config::CLIPMAP_LEVELS_USIZE],
    /// Toroidal storage offset per level (in texels).
    /// Mapping: storage = (logical + offset) mod res
    tex_offset: [(u16, u16); config::CLIPMAP_LEVELS_USIZE],
    last_update_time_s: [f32; config::CLIPMAP_LEVELS_USIZE],
}

impl Clipmap {
    pub fn new() -> Self {
        Self {
            last_origin_cell: [(i32::MIN, i32::MIN); config::CLIPMAP_LEVELS_USIZE],
            tex_offset: [(0, 0); config::CLIPMAP_LEVELS_USIZE],
            last_update_time_s: [f32::NEG_INFINITY; config::CLIPMAP_LEVELS_USIZE],
        }
    }

    #[inline]
    fn level_cell_size(i: u32) -> f32 {
        config::CLIPMAP_BASE_CELL_M * (1u32 << i) as f32
    }

    /// Compute snapped origin in *cell coordinates* (integer grid), for a given camera xz.
    ///
    /// We keep the camera roughly centered in the texture:
    /// origin = snap(cam - (res/2)*cell).
    #[inline]
    fn snapped_origin_cell(cam_x_m: f32, cam_z_m: f32, cell_m: f32) -> (i32, i32) {
        let half = (config::CLIPMAP_RES as f32) * 0.5;
        let ox_m = cam_x_m - half * cell_m;
        let oz_m = cam_z_m - half * cell_m;

        let ox_c = (ox_m / cell_m).floor() as i32;
        let oz_c = (oz_m / cell_m).floor() as i32;
        (ox_c, oz_c)
    }

    #[inline]
    fn cell_to_origin_m(cell_x: i32, cell_z: i32, cell_m: f32) -> (f32, f32) {
        (cell_x as f32 * cell_m, cell_z as f32 * cell_m)
    }

    #[inline]
    fn pack_offsets(off_x: u16, off_z: u16) -> u32 {
        (off_x as u32) | ((off_z as u32) << 16)
    }

    #[inline]
    fn wrap_i32_mod_u16(v: i32, m: i32) -> u16 {
        let mut r = v % m;
        if r < 0 {
            r += m;
        }
        r as u16
    }

    // -------------------------------------------------------------------------
    // f32 -> f16 (bits) conversion, IEEE-754 half precision
    // -------------------------------------------------------------------------
    #[inline]
    fn f32_to_f16_bits(v: f32) -> u16 {
        let x = v.to_bits();

        let sign = ((x >> 16) & 0x8000) as u16;
        let exp = ((x >> 23) & 0xFF) as i32;
        let mant = x & 0x007F_FFFF;

        // NaN/Inf
        if exp == 255 {
            if mant == 0 {
                return sign | 0x7C00; // Inf
            } else {
                let payload = (mant >> 13) as u16;
                return sign | 0x7C00 | (payload.max(1));
            }
        }

        // Unbias exponent from f32, then bias to f16
        let e = exp - 127;
        let e16 = e + 15;

        // Too large => Inf
        if e16 >= 31 {
            return sign | 0x7C00;
        }

        // Too small => subnormal or zero
        if e16 <= 0 {
            if e16 < -10 {
                return sign;
            }

            let m = mant | 0x0080_0000;

            let shift = 14 - e16;
            let mut mant16 = (m >> shift) as u16;

            // Round to nearest-even
            let rem_mask = (1u32 << shift) - 1;
            let rem = m & rem_mask;
            let half = 1u32 << (shift - 1);

            if rem > half || (rem == half && (mant16 & 1) != 0) {
                mant16 = mant16.wrapping_add(1);
            }

            return sign | mant16;
        }

        // Normal f16
        let mut mant16 = (mant >> 13) as u16;

        let round_bits = mant & 0x0000_1FFF;
        if round_bits > 0x1000 || (round_bits == 0x1000 && (mant16 & 1) != 0) {
            mant16 = mant16.wrapping_add(1);

            // Mantissa overflow => bump exponent
            if mant16 & 0x0400 != 0 {
                mant16 = 0;
                let e_out = (e16 + 1) as u16;
                if e_out >= 31 {
                    return sign | 0x7C00;
                }
                return sign | (e_out << 10) | mant16;
            }
        }

        sign | ((e16 as u16) << 10) | (mant16 & 0x03FF)
    }

    #[inline]
    fn sample_height_f16(world: &WorldGen, wx_m: f32, wz_m: f32) -> u16 {
        let vs = config::VOXEL_SIZE_M_F32;

        let wx_vx = (wx_m / vs).floor() as i32;
        let wz_vx = (wz_m / vs).floor() as i32;

        let h_vx = world.ground_height(wx_vx, wz_vx);
        let h_m = (h_vx as f32) * vs;

        Self::f32_to_f16_bits(h_m)
    }

    fn build_full_level(world: &WorldGen, ox_m: f32, oz_m: f32, cell_m: f32) -> Vec<u16> {
        let res = config::CLIPMAP_RES as usize;
        let mut data = vec![0u16; res * res];

        for tz in 0..res {
            let wz_m = oz_m + (tz as f32 + 0.5) * cell_m;
            let row = tz * res;

            for tx in 0..res {
                let wx_m = ox_m + (tx as f32 + 0.5) * cell_m;
                data[row + tx] = Self::sample_height_f16(world, wx_m, wz_m);
            }
        }

        data
    }

    fn build_row_patch(
        world: &WorldGen,
        ox_m: f32,
        oz_m: f32,
        cell_m: f32,
        logical_z0: u32,
        rows: u32,
    ) -> Vec<u16> {
        let res = config::CLIPMAP_RES as usize;
        let w = res as u32;

        let h = rows as usize;
        let mut data = vec![0u16; (w as usize) * h];

        for rz in 0..rows {
            let lz = logical_z0 + rz;
            let wz_m = oz_m + (lz as f32 + 0.5) * cell_m;

            let row = (rz as usize) * res;
            for tx in 0..res {
                let wx_m = ox_m + (tx as f32 + 0.5) * cell_m;
                data[row + tx] = Self::sample_height_f16(world, wx_m, wz_m);
            }
        }

        data
    }

    fn build_col_patch(
        world: &WorldGen,
        ox_m: f32,
        oz_m: f32,
        cell_m: f32,
        logical_x0: u32,
        cols: u32,
    ) -> Vec<u16> {
        let res = config::CLIPMAP_RES as usize;
        let w = cols as usize;
        let h = res;

        let mut data = vec![0u16; w * h];

        for tz in 0..res {
            let wz_m = oz_m + (tz as f32 + 0.5) * cell_m;
            let row = tz * w;

            for cx in 0..cols {
                let lx = logical_x0 + cx;
                let wx_m = ox_m + (lx as f32 + 0.5) * cell_m;
                data[row + (cx as usize)] = Self::sample_height_f16(world, wx_m, wz_m);
            }
        }

        data
    }

    /// Update clipmap data around camera.
    ///
    /// Returns:
    /// - CPU params for GPU packing
    /// - uploads:
    ///     - full refresh on first touch or huge jump
    ///     - otherwise strip patches (rows/cols)
    pub fn update(
        &mut self,
        world: &WorldGen,
        cam_pos_m: Vec3,
        time_s: f32,
    ) -> (ClipmapParamsCpu, Vec<ClipmapUpload>) {
        let mut params = ClipmapParamsCpu {
            levels: config::CLIPMAP_LEVELS,
            res: config::CLIPMAP_RES,
            base_cell_m: config::CLIPMAP_BASE_CELL_M,
            _pad0: 0.0,
            level: [ClipLevelParams {
                origin_x_m: 0.0,
                origin_z_m: 0.0,
                cell_size_m: 1.0,
                inv_cell_size_m: 1.0,
                packed_offsets: 0,
            }; config::CLIPMAP_LEVELS_USIZE],
        };

        let mut uploads = Vec::new();

        let res_u = config::CLIPMAP_RES;
        let res_i = res_u as i32;

        for i in 0..config::CLIPMAP_LEVELS {
            let li = i as usize;
            let cell_m = Self::level_cell_size(i);
            let inv_cell_m = 1.0 / cell_m.max(1e-6);

            let (new_ox_c, new_oz_c) = Self::snapped_origin_cell(cam_pos_m.x, cam_pos_m.z, cell_m);
            let (new_ox_m, new_oz_m) = Self::cell_to_origin_m(new_ox_c, new_oz_c, cell_m);

            // Current torus offsets
            let (mut off_x, mut off_z) = self.tex_offset[li];

            let (old_ox_c, old_oz_c) = self.last_origin_cell[li];
            let first = old_ox_c == i32::MIN;

            let dx = if first { 0 } else { new_ox_c - old_ox_c };
            let dz = if first { 0 } else { new_oz_c - old_oz_c };

            let mut want_update = first || dx != 0 || dz != 0;

            let allow_by_time =
                (time_s - self.last_update_time_s[li]) >= config::CLIPMAP_MIN_UPDATE_INTERVAL_S;

            if !allow_by_time {
                want_update = false;
            }

            if want_update {
                self.last_update_time_s[li] = time_s;

                if first {
                    // Full refresh first time
                    self.last_origin_cell[li] = (new_ox_c, new_oz_c);
                    off_x = 0;
                    off_z = 0;
                    self.tex_offset[li] = (off_x, off_z);

                    let full = Self::build_full_level(world, new_ox_m, new_oz_m, cell_m);
                    uploads.push(ClipmapUpload {
                        level: i,
                        x: 0,
                        y: 0,
                        w: res_u,
                        h: res_u,
                        data_f16: full,
                    });
                } else {
                    let adx = dx.unsigned_abs() as u32;
                    let adz = dz.unsigned_abs() as u32;
                    let big_jump = adx >= res_u || adz >= res_u;

                    if big_jump {
                        // Teleport-scale jump: full refresh
                        self.last_origin_cell[li] = (new_ox_c, new_oz_c);
                        off_x = 0;
                        off_z = 0;
                        self.tex_offset[li] = (off_x, off_z);

                        let full = Self::build_full_level(world, new_ox_m, new_oz_m, cell_m);
                        uploads.push(ClipmapUpload {
                            level: i,
                            x: 0,
                            y: 0,
                            w: res_u,
                            h: res_u,
                            data_f16: full,
                        });
                    } else {
                        // Scroll torus offsets
                        off_x = Self::wrap_i32_mod_u16((off_x as i32) + dx, res_i);
                        off_z = Self::wrap_i32_mod_u16((off_z as i32) + dz, res_i);
                        self.tex_offset[li] = (off_x, off_z);
                        self.last_origin_cell[li] = (new_ox_c, new_oz_c);

                        // logical -> storage
                        let map_x = |lx: u32| -> u32 { (lx + (off_x as u32)) % res_u };
                        let map_z = |lz: u32| -> u32 { (lz + (off_z as u32)) % res_u };

                        // New columns
                        if dx != 0 {
                            let cols = dx.unsigned_abs() as u32;

                            if dx > 0 {
                                // logical [res-cols .. res-1]
                                let logical_x0 = res_u - cols;
                                let sx0 = map_x(logical_x0);
                                let end = sx0 + cols;

                                if end <= res_u {
                                    let data = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0, cols,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: sx0,
                                        y: 0,
                                        w: cols,
                                        h: res_u,
                                        data_f16: data,
                                    });
                                } else {
                                    let a = res_u - sx0;
                                    let b = end - res_u;

                                    let data_a = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0, a,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: sx0,
                                        y: 0,
                                        w: a,
                                        h: res_u,
                                        data_f16: data_a,
                                    });

                                    let data_b = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0 + a, b,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: 0,
                                        w: b,
                                        h: res_u,
                                        data_f16: data_b,
                                    });
                                }
                            } else {
                                // dx < 0: logical [0 .. cols-1]
                                let logical_x0 = 0;
                                let sx0 = map_x(logical_x0);
                                let end = sx0 + cols;

                                if end <= res_u {
                                    let data = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0, cols,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: sx0,
                                        y: 0,
                                        w: cols,
                                        h: res_u,
                                        data_f16: data,
                                    });
                                } else {
                                    let a = res_u - sx0;
                                    let b = end - res_u;

                                    let data_a = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0, a,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: sx0,
                                        y: 0,
                                        w: a,
                                        h: res_u,
                                        data_f16: data_a,
                                    });

                                    let data_b = Self::build_col_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_x0 + a, b,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: 0,
                                        w: b,
                                        h: res_u,
                                        data_f16: data_b,
                                    });
                                }
                            }
                        }

                        // New rows
                        if dz != 0 {
                            let rows = dz.unsigned_abs() as u32;

                            if dz > 0 {
                                // logical [res-rows .. res-1]
                                let logical_z0 = res_u - rows;
                                let sy0 = map_z(logical_z0);
                                let end = sy0 + rows;

                                if end <= res_u {
                                    let data = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0, rows,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: sy0,
                                        w: res_u,
                                        h: rows,
                                        data_f16: data,
                                    });
                                } else {
                                    let a = res_u - sy0;
                                    let b = end - res_u;

                                    let data_a = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0, a,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: sy0,
                                        w: res_u,
                                        h: a,
                                        data_f16: data_a,
                                    });

                                    let data_b = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0 + a, b,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: 0,
                                        w: res_u,
                                        h: b,
                                        data_f16: data_b,
                                    });
                                }
                            } else {
                                // dz < 0: logical [0 .. rows-1]
                                let logical_z0 = 0;
                                let sy0 = map_z(logical_z0);
                                let end = sy0 + rows;

                                if end <= res_u {
                                    let data = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0, rows,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: sy0,
                                        w: res_u,
                                        h: rows,
                                        data_f16: data,
                                    });
                                } else {
                                    let a = res_u - sy0;
                                    let b = end - res_u;

                                    let data_a = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0, a,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: sy0,
                                        w: res_u,
                                        h: a,
                                        data_f16: data_a,
                                    });

                                    let data_b = Self::build_row_patch(
                                        world, new_ox_m, new_oz_m, cell_m, logical_z0 + a, b,
                                    );
                                    uploads.push(ClipmapUpload {
                                        level: i,
                                        x: 0,
                                        y: 0,
                                        w: res_u,
                                        h: b,
                                        data_f16: data_b,
                                    });
                                }
                            }
                        }
                    }
                }
            }

            let packed = Self::pack_offsets(off_x, off_z);
            params.level[li] = ClipLevelParams {
                origin_x_m: new_ox_m,
                origin_z_m: new_oz_m,
                cell_size_m: cell_m,
                inv_cell_size_m: inv_cell_m,
                packed_offsets: packed,
            };
        }

        (params, uploads)
    }

    pub fn invalidate_all(&mut self) {
        self.last_origin_cell = [(i32::MIN, i32::MIN); config::CLIPMAP_LEVELS_USIZE];
        self.tex_offset = [(0, 0); config::CLIPMAP_LEVELS_USIZE];
        self.last_update_time_s = [f32::NEG_INFINITY; config::CLIPMAP_LEVELS_USIZE];
    }
}

// src/config.rs
// -------------
// src/config.rs
// -------------
// Global config knobs for the voxel/SVO renderer + streaming.

pub const CHUNK_SIZE: u32 = 64;

pub const ACTIVE_RADIUS: i32 = 10;
pub const KEEP_RADIUS: i32 = ACTIVE_RADIUS + 5;

pub const VOXEL_SIZE_M_F32: f32 = 0.10;
pub const VOXEL_SIZE_M_F64: f64 = 0.10;

// Keep this explicit so you can change voxel size later without hunting constants.
pub const VOXELS_PER_METER: i32 = 10; // 1.0 / 0.10

pub const WORKER_THREADS: usize = 4;
pub const MAX_IN_FLIGHT: usize = 8;

// GPU node arena budget (storage buffer capacity).
pub const NODE_BUDGET_BYTES: usize = 1024 * 1024 * 1024; // 1 GB

// CPU chunk cache budget (SVO nodes stored on CPU so we don't rebuild chunks).
// This is the *total* bytes of cached NodeGpu arrays across all cached chunks.
pub const CHUNK_CACHE_BUDGET_BYTES: usize = 1024 * 1024 * 1024; // 1024 MB

// -----------------------------------------------------------------------------
// Clipmap (far terrain fallback)
// -----------------------------------------------------------------------------
//
// A set of nested 2D height textures around the camera (CPU updated).
// The primary compute shader samples this when the SVO grid doesn't cover the ray
// (or when no voxel hit occurs).
//
// Height units: meters (f32).
//
// NOTE: These constants MUST match shader-side constants in `shaders/clipmap.wgsl`.

pub const CLIPMAP_LEVELS: u32 = 8;
pub const CLIPMAP_LEVELS_USIZE: usize = CLIPMAP_LEVELS as usize;

// Texture resolution per level (square).
pub const CLIPMAP_RES: u32 = 256;

// Base cell size (meters) for level 0. Level i cell size = BASE * 2^i.
pub const CLIPMAP_BASE_CELL_M: f32 = 0.3;

// How often we allow a full refresh per level at most (seconds).
// (Prevents thrashing if you ever tie updates to very tiny camera jitter.)
pub const CLIPMAP_MIN_UPDATE_INTERVAL_S: f32 = 0.0;

// src/input.rs
// ------------
// src/input.rs
use winit::{
    event::{DeviceEvent, ElementState, KeyEvent, WindowEvent},
    keyboard::{KeyCode, PhysicalKey},
    window::{CursorGrabMode, Window},
};

#[derive(Default, Clone, Copy)]
pub struct KeyState {
    pub w: bool,
    pub a: bool,
    pub s: bool,
    pub d: bool,
    pub space: bool,
    pub alt: bool,
}

impl KeyState {
    pub fn set(&mut self, code: KeyCode, down: bool) {
        match code {
            KeyCode::KeyW => self.w = down,
            KeyCode::KeyA => self.a = down,
            KeyCode::KeyS => self.s = down,
            KeyCode::KeyD => self.d = down,
            KeyCode::Space => self.space = down,
            KeyCode::AltLeft | KeyCode::AltRight => self.alt = down,
            _ => {}
        }
    }
}

#[derive(Default)]
pub struct InputState {
    pub keys: KeyState,
    pub focused: bool,
    pub mouse_dx: f32,
    pub mouse_dy: f32,
}

impl InputState {
    pub fn on_device_event(&mut self, event: &DeviceEvent) {
        if !self.focused {
            return;
        }
        if let DeviceEvent::MouseMotion { delta } = event {
            self.mouse_dx += delta.0 as f32;
            self.mouse_dy += delta.1 as f32;
        }
    }

    /// Returns true if event is fully handled/consumed.
    pub fn on_window_event(&mut self, event: &WindowEvent, window: &Window) -> bool {
        match event {
            WindowEvent::Focused(f) => {
                self.focused = *f;
                if self.focused {
                    let _ = window
                        .set_cursor_grab(CursorGrabMode::Locked)
                        .or_else(|_| window.set_cursor_grab(CursorGrabMode::Confined));
                    window.set_cursor_visible(false);
                } else {
                    let _ = window.set_cursor_grab(CursorGrabMode::None);
                    window.set_cursor_visible(true);
                }
                true
            }

            WindowEvent::KeyboardInput { event, .. } => {
                if let KeyEvent {
                    physical_key: PhysicalKey::Code(code),
                    state,
                    ..
                } = event
                {
                    let down = *state == ElementState::Pressed;
                    self.keys.set(*code, down);

                    if down && *code == KeyCode::Escape {
                        self.focused = false;
                        let _ = window.set_cursor_grab(CursorGrabMode::None);
                        window.set_cursor_visible(true);
                        return true;
                    }
                }
                false
            }

            _ => false,
        }
    }

    pub fn take_mouse_delta(&mut self) -> (f32, f32) {
        let dx = self.mouse_dx;
        let dy = self.mouse_dy;
        self.mouse_dx = 0.0;
        self.mouse_dy = 0.0;
        (dx, dy)
    }
}

// src/main.rs
// -----------
// src/main.rs
mod app;
mod camera;
mod clipmap;
mod config;
mod input;
mod render;
mod streaming;
mod svo;
mod world;

use std::sync::Arc;
use winit::{
    dpi::PhysicalSize,
    event_loop::EventLoop,
    window::{Fullscreen, WindowBuilder},
};

fn main() {
    let event_loop = EventLoop::new().unwrap();

    let window = Arc::new(
        WindowBuilder::new()
            .with_title("SVO MVP")
            .with_inner_size(PhysicalSize::new(1280, 720))
            .build(&event_loop)
            .unwrap(),
    );
    window.set_fullscreen(Some(Fullscreen::Borderless(None)));

    pollster::block_on(app::run(event_loop, window));
}

// src/render/gpu_types.rs
// -----------------------
// src/render/gpu_types.rs
// -----------------------
//
// Fix: ClipLevelParams now has `packed_offsets`, but we keep its existing
// `inv_cell_size_m` field on CPU side.
// GPU uniform uses vec4 per level with packed offsets in .w.

use bytemuck::{Pod, Zeroable};

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable, Debug)]
pub struct NodeGpu {
    pub child_base: u32,
    pub child_mask: u32,
    pub material: u32,
    pub _pad: u32,
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
pub struct ChunkMetaGpu {
    pub origin: [i32; 4],
    pub node_base: u32,
    pub node_count: u32,
    pub _pad0: u32,
    pub _pad1: u32,
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
pub struct CameraGpu {
    pub view_inv: [[f32; 4]; 4],
    pub proj_inv: [[f32; 4]; 4],
    pub cam_pos: [f32; 4],

    pub chunk_size: u32,
    pub chunk_count: u32,
    pub max_steps: u32,
    pub _pad0: u32,

    pub voxel_params: [f32; 4],

    pub grid_origin_chunk: [i32; 4],
    pub grid_dims: [u32; 4],
}

/// Clipmap uniform payload.
///
/// Matches `shaders/clipmap.wgsl`.
///
/// Per level vec4:
///   x = origin_x_m
///   y = origin_z_m
///   z = cell_size_m
///   w = packed offsets bits (off_x u16 | (off_z u16 << 16)) stored via f32::from_bits
#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
pub struct ClipmapGpu {
    pub levels: u32,
    pub res: u32,
    pub base_cell_m: f32,
    pub _pad0: f32,

    pub level: [[f32; 4]; crate::config::CLIPMAP_LEVELS_USIZE],
}

impl ClipmapGpu {
    pub fn from_cpu(cpu: &crate::clipmap::ClipmapParamsCpu) -> Self {
        let mut level = [[0.0f32; 4]; crate::config::CLIPMAP_LEVELS_USIZE];

        for i in 0..crate::config::CLIPMAP_LEVELS_USIZE {
            let p = cpu.level[i];
            level[i] = [
                p.origin_x_m,
                p.origin_z_m,
                p.cell_size_m,
                f32::from_bits(p.packed_offsets),
            ];
        }

        Self {
            levels: cpu.levels,
            res: cpu.res,
            base_cell_m: cpu.base_cell_m,
            _pad0: 0.0,
            level,
        }
    }
}

#[repr(C)]
#[derive(Clone, Copy, Pod, Zeroable)]
pub struct OverlayGpu {
    pub fps: u32,
    pub width: u32,
    pub height: u32,
    pub _pad0: u32,
}

// src/render/mod.rs
// -----------------
// src/render/mod.rs

pub mod gpu_types;
pub mod resources;
pub mod shaders;
pub mod state;

pub use gpu_types::*;
pub use state::Renderer;

// src/render/resources.rs
// -----------------------
// src/render/resources.rs
//
// Small GPU resource helpers that don't fit cleanly into the renderer "state" modules.
//
// Right now this file provides the final full-resolution output texture:
// - written as a STORAGE texture by the composite compute pass
// - sampled as a regular texture by the final blit render pass
//
// Keeping this as a tiny helper makes the main texture set code a bit cleaner.

/// Wrapper for the renderer's final output texture view.
///
/// The renderer stores only the TextureView; the view keeps the underlying texture alive
/// for as long as it exists (wgpu uses ref-counted internal ownership).
pub struct OutputTex {
    /// Texture view bound in bind groups (storage write in compute, sampled in blit).
    pub view: wgpu::TextureView,
}

/// Create the final output texture (full resolution).
///
/// Properties:
/// - Format: RGBA16F (high dynamic range, good for post-processing)
/// - Usage:
///   - STORAGE_BINDING: composite pass writes into it as a storage texture
///   - TEXTURE_BINDING: blit pass samples it in the fragment shader
///
/// Notes:
/// - wgpu forbids zero-sized textures, so we clamp `w`/`h` to at least 1.
pub fn create_output_texture(device: &wgpu::Device, w: u32, h: u32) -> OutputTex {
    // Avoid creating zero-sized textures (can happen during minimize/resizes).
    let w = w.max(1);
    let h = h.max(1);

    // Allocate the GPU texture backing store.
    let tex = device.create_texture(&wgpu::TextureDescriptor {
        label: Some("output_tex"),
        size: wgpu::Extent3d {
            width: w,
            height: h,
            depth_or_array_layers: 1,
        },
        mip_level_count: 1,
        sample_count: 1,
        dimension: wgpu::TextureDimension::D2,
        format: wgpu::TextureFormat::Rgba16Float,
        // Must support both compute writes and render sampling.
        usage: wgpu::TextureUsages::STORAGE_BINDING | wgpu::TextureUsages::TEXTURE_BINDING,
        view_formats: &[],
    });

    // Default view covers the whole texture.
    let view = tex.create_view(&Default::default());

    OutputTex { view }
}

// src/render/shaders.rs
// ---------------------
// src/render/shaders.rs
//
// Centralized shader sources. WGSL has no native include mechanism in wgpu,
// so we concatenate multiple WGSL files into a single source string.

pub const RAY_CS_WGSL: &str = concat!(
    include_str!("../shaders/common.wgsl"),
    "\n",
    include_str!("../shaders/ray_core.wgsl"),
    "\n",
    include_str!("../shaders/clipmap.wgsl"),
    "\n",
    include_str!("../shaders/ray_main.wgsl"),
    "\n",
);

pub const BLIT_WGSL: &str = include_str!("../shaders/blit.wgsl");

#[inline]
pub fn ray_cs_wgsl() -> &'static str {
    RAY_CS_WGSL
}

#[inline]
pub fn blit_wgsl() -> &'static str {
    BLIT_WGSL
}

// src/render/state/bindgroups.rs
// ------------------------------
// src/render/state/bindgroups.rs
//
// Bind group creation.

use super::{buffers::Buffers, layout::Layouts, textures::TextureSet};

pub struct BindGroups {
    pub primary: wgpu::BindGroup,
    pub scene: wgpu::BindGroup,
    pub godray: [wgpu::BindGroup; 2],
    pub composite: [wgpu::BindGroup; 2],
    pub empty: wgpu::BindGroup,
    pub blit: wgpu::BindGroup,
}

fn make_primary_bg(
    device: &wgpu::Device,
    layout: &wgpu::BindGroupLayout,
    buffers: &Buffers,
    textures: &TextureSet,
) -> wgpu::BindGroup {
    device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some("primary_bg"),
        layout,
        entries: &[
            wgpu::BindGroupEntry {
                binding: 0,
                resource: buffers.camera.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 1,
                resource: buffers.chunk.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 2,
                resource: buffers.node.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 3,
                resource: buffers.chunk_grid.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 4,
                resource: wgpu::BindingResource::TextureView(&textures.color.view),
            },
            wgpu::BindGroupEntry {
                binding: 5,
                resource: wgpu::BindingResource::TextureView(&textures.depth.view),
            },
            // Clipmap params uniform
            wgpu::BindGroupEntry {
                binding: 6,
                resource: buffers.clipmap.as_entire_binding(),
            },
            // Clipmap height texture array
            wgpu::BindGroupEntry {
                binding: 7,
                resource: wgpu::BindingResource::TextureView(&textures.clip_height.view),
            },
        ],
    })
}

fn make_scene_bg(
    device: &wgpu::Device,
    layout: &wgpu::BindGroupLayout,
    buffers: &Buffers,
) -> wgpu::BindGroup {
    device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some("scene_bg"),
        layout,
        entries: &[
            wgpu::BindGroupEntry {
                binding: 0,
                resource: buffers.camera.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 1,
                resource: buffers.chunk.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 2,
                resource: buffers.node.as_entire_binding(),
            },
            wgpu::BindGroupEntry {
                binding: 3,
                resource: buffers.chunk_grid.as_entire_binding(),
            },
        ],
    })
}

fn make_godray_bg(
    device: &wgpu::Device,
    layout: &wgpu::BindGroupLayout,
    depth_view: &wgpu::TextureView,
    hist_view: &wgpu::TextureView,
    out_view: &wgpu::TextureView,
    label: &str,
) -> wgpu::BindGroup {
    device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some(label),
        layout,
        entries: &[
            wgpu::BindGroupEntry {
                binding: 0,
                resource: wgpu::BindingResource::TextureView(depth_view),
            },
            wgpu::BindGroupEntry {
                binding: 1,
                resource: wgpu::BindingResource::TextureView(hist_view),
            },
            wgpu::BindGroupEntry {
                binding: 2,
                resource: wgpu::BindingResource::TextureView(out_view),
            },
        ],
    })
}

fn make_composite_bg(
    device: &wgpu::Device,
    layout: &wgpu::BindGroupLayout,
    color_view: &wgpu::TextureView,
    godray_view: &wgpu::TextureView,
    output_view: &wgpu::TextureView,
    depth_view: &wgpu::TextureView, // NEW
    label: &str,
) -> wgpu::BindGroup {
    device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some(label),
        layout,
        entries: &[
            wgpu::BindGroupEntry { binding: 0, resource: wgpu::BindingResource::TextureView(color_view) },
            wgpu::BindGroupEntry { binding: 1, resource: wgpu::BindingResource::TextureView(godray_view) },
            wgpu::BindGroupEntry { binding: 2, resource: wgpu::BindingResource::TextureView(output_view) },
            wgpu::BindGroupEntry { binding: 3, resource: wgpu::BindingResource::TextureView(depth_view) },
        ],
    })
}



fn make_blit_bg(
    device: &wgpu::Device,
    layout: &wgpu::BindGroupLayout,
    output_view: &wgpu::TextureView,
    sampler: &wgpu::Sampler,
    overlay_buf: &wgpu::Buffer,
) -> wgpu::BindGroup {
    device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some("blit_bg"),
        layout,
        entries: &[
            wgpu::BindGroupEntry {
                binding: 0,
                resource: wgpu::BindingResource::TextureView(output_view),
            },
            wgpu::BindGroupEntry {
                binding: 1,
                resource: wgpu::BindingResource::Sampler(sampler),
            },
            wgpu::BindGroupEntry {
                binding: 2,
                resource: overlay_buf.as_entire_binding(),
            },
        ],
    })
}

pub fn create_bind_groups(
    device: &wgpu::Device,
    layouts: &Layouts,
    buffers: &Buffers,
    textures: &TextureSet,
    sampler: &wgpu::Sampler,
) -> BindGroups {
    let primary = make_primary_bg(device, &layouts.primary, buffers, textures);
    let scene = make_scene_bg(device, &layouts.scene, buffers);

    let empty = device.create_bind_group(&wgpu::BindGroupDescriptor {
        label: Some("empty_bg"),
        layout: &layouts.empty,
        entries: &[],
    });

    let godray = [
        make_godray_bg(
            device,
            &layouts.godray,
            &textures.depth.view,
            &textures.godray[0].view,
            &textures.godray[1].view,
            "godray_bg_a_to_b",
        ),
        make_godray_bg(
            device,
            &layouts.godray,
            &textures.depth.view,
            &textures.godray[1].view,
            &textures.godray[0].view,
            "godray_bg_b_to_a",
        ),
    ];

    let composite = [
        make_composite_bg(
            device,
            &layouts.composite,
            &textures.color.view,
            &textures.godray[0].view,
            &textures.output.view,
            &textures.depth.view,
            "composite_bg_read_a",
        ),
        make_composite_bg(
            device,
            &layouts.composite,
            &textures.color.view,
            &textures.godray[1].view,
            &textures.output.view,
            &textures.depth.view,
            "composite_bg_read_b",
        ),
    ];

    let blit = make_blit_bg(
        device,
        &layouts.blit,
        &textures.output.view,
        sampler,
        &buffers.overlay,
    );

    BindGroups {
        primary,
        scene,
        godray,
        composite,
        empty,
        blit,
    }
}

// src/render/state/buffers.rs
// ---------------------------
// src/render/state/buffers.rs
//
// Persistent GPU buffers and capacities.

use crate::{
    config,
    render::gpu_types::{ChunkMetaGpu, ClipmapGpu, NodeGpu},
};

pub struct Buffers {
    // --- Uniforms ---
    pub camera: wgpu::Buffer,
    pub overlay: wgpu::Buffer,

    /// Clipmap params (primary compute pass only).
    pub clipmap: wgpu::Buffer,

    // --- Storage buffers ---
    pub node: wgpu::Buffer,
    pub chunk: wgpu::Buffer,
    pub chunk_grid: wgpu::Buffer,

    // --- Capacities ---
    pub node_capacity: u32,
    pub chunk_capacity: u32,
    pub grid_capacity: u32,
}

fn make_uniform_buffer<T: Sized>(device: &wgpu::Device, label: &str) -> wgpu::Buffer {
    device.create_buffer(&wgpu::BufferDescriptor {
        label: Some(label),
        size: std::mem::size_of::<T>() as u64,
        usage: wgpu::BufferUsages::UNIFORM | wgpu::BufferUsages::COPY_DST,
        mapped_at_creation: false,
    })
}

fn make_storage_buffer(device: &wgpu::Device, label: &str, size_bytes: u64) -> wgpu::Buffer {
    device.create_buffer(&wgpu::BufferDescriptor {
        label: Some(label),
        size: size_bytes,
        usage: wgpu::BufferUsages::STORAGE | wgpu::BufferUsages::COPY_DST,
        mapped_at_creation: false,
    })
}

pub fn create_persistent_buffers(device: &wgpu::Device) -> Buffers {
    let camera = make_uniform_buffer::<crate::render::gpu_types::CameraGpu>(device, "camera_buf");
    let overlay = make_uniform_buffer::<crate::render::gpu_types::OverlayGpu>(device, "overlay_buf");

    let clipmap = make_uniform_buffer::<ClipmapGpu>(device, "clipmap_buf");

    let node_capacity = (config::NODE_BUDGET_BYTES / std::mem::size_of::<NodeGpu>()) as u32;

    let node = make_storage_buffer(
        device,
        "svo_nodes_arena",
        (node_capacity as u64) * (std::mem::size_of::<NodeGpu>() as u64),
    );

    let chunk_capacity =
        (2 * config::KEEP_RADIUS + 1) as u32 * 4u32 * (2 * config::KEEP_RADIUS + 1) as u32;

    let chunk = make_storage_buffer(
        device,
        "chunk_meta_persistent",
        (chunk_capacity as u64) * (std::mem::size_of::<ChunkMetaGpu>() as u64),
    );

    let grid_capacity = chunk_capacity;

    let chunk_grid = make_storage_buffer(
        device,
        "chunk_grid_buf",
        (grid_capacity as u64) * (std::mem::size_of::<u32>() as u64),
    );

    Buffers {
        camera,
        overlay,
        clipmap,
        node,
        chunk,
        chunk_grid,
        node_capacity,
        chunk_capacity,
        grid_capacity,
    }
}

// src/render/state/layout.rs
// --------------------------
// src/render/state/layout.rs
//
// Bind group layouts and small helpers.

pub struct Layouts {
    pub primary: wgpu::BindGroupLayout,
    pub scene: wgpu::BindGroupLayout,
    pub godray: wgpu::BindGroupLayout,
    pub composite: wgpu::BindGroupLayout,
    pub empty: wgpu::BindGroupLayout,
    pub blit: wgpu::BindGroupLayout,
}

fn bgl_sampler(binding: u32, visibility: wgpu::ShaderStages) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::Sampler(wgpu::SamplerBindingType::Filtering),
        count: None,
    }
}


fn bgl_uniform(binding: u32, visibility: wgpu::ShaderStages) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::Buffer {
            ty: wgpu::BufferBindingType::Uniform,
            has_dynamic_offset: false,
            min_binding_size: None,
        },
        count: None,
    }
}

fn bgl_storage_ro(binding: u32, visibility: wgpu::ShaderStages) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::Buffer {
            ty: wgpu::BufferBindingType::Storage { read_only: true },
            has_dynamic_offset: false,
            min_binding_size: None,
        },
        count: None,
    }
}

fn bgl_tex_sample_2d(
    binding: u32,
    visibility: wgpu::ShaderStages,
    sample_type: wgpu::TextureSampleType,
) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::Texture {
            sample_type,
            view_dimension: wgpu::TextureViewDimension::D2,
            multisampled: false,
        },
        count: None,
    }
}

fn bgl_tex_sample_2d_array(
    binding: u32,
    visibility: wgpu::ShaderStages,
    sample_type: wgpu::TextureSampleType,
) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::Texture {
            sample_type,
            view_dimension: wgpu::TextureViewDimension::D2Array,
            multisampled: false,
        },
        count: None,
    }
}

fn bgl_storage_tex_wo(
    binding: u32,
    visibility: wgpu::ShaderStages,
    format: wgpu::TextureFormat,
) -> wgpu::BindGroupLayoutEntry {
    wgpu::BindGroupLayoutEntry {
        binding,
        visibility,
        ty: wgpu::BindingType::StorageTexture {
            access: wgpu::StorageTextureAccess::WriteOnly,
            format,
            view_dimension: wgpu::TextureViewDimension::D2,
        },
        count: None,
    }
}

pub fn create_layouts(device: &wgpu::Device) -> Layouts {
    let cs_vis = wgpu::ShaderStages::COMPUTE;

    let scene_entries: [wgpu::BindGroupLayoutEntry; 4] = [
        bgl_uniform(0, cs_vis),
        bgl_storage_ro(1, cs_vis),
        bgl_storage_ro(2, cs_vis),
        bgl_storage_ro(3, cs_vis),
    ];

    let scene = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("scene_bgl"),
        entries: &scene_entries,
    });

    // PRIMARY: add clipmap uniform + clipmap height texture array
    // bindings:
    // 0 camera
    // 1 chunks
    // 2 nodes
    // 3 chunk_grid
    // 4 color storage
    // 5 depth storage
    // 6 clipmap uniform
    // 7 clipmap height texture array (R32Float)
    let mut primary_entries = Vec::with_capacity(8);
    primary_entries.extend_from_slice(&scene_entries);

    primary_entries.push(bgl_storage_tex_wo(4, cs_vis, wgpu::TextureFormat::Rgba16Float));
    primary_entries.push(bgl_storage_tex_wo(5, cs_vis, wgpu::TextureFormat::R32Float));

    primary_entries.push(bgl_uniform(6, cs_vis));
    primary_entries.push(bgl_tex_sample_2d_array(
        7,
        cs_vis,
        wgpu::TextureSampleType::Float { filterable: false },
    ));

    let primary = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("primary_bgl"),
        entries: &primary_entries,
    });

    let godray = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("godray_bgl"),
        entries: &[
            bgl_tex_sample_2d(
                0,
                cs_vis,
                wgpu::TextureSampleType::Float { filterable: false },
            ),
            bgl_tex_sample_2d(
                1,
                cs_vis,
                wgpu::TextureSampleType::Float { filterable: false },
            ),
            bgl_storage_tex_wo(2, cs_vis, wgpu::TextureFormat::Rgba16Float),
        ],
    });

    let composite = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("composite_bgl"),
        entries: &[
            bgl_tex_sample_2d(
                0,
                cs_vis,
                wgpu::TextureSampleType::Float { filterable: false },
            ),
            bgl_tex_sample_2d(
                1,
                cs_vis,
                wgpu::TextureSampleType::Float { filterable: false },
            ),
            bgl_storage_tex_wo(2, cs_vis, wgpu::TextureFormat::Rgba16Float),

            // NEW: full-res depth for depth-aware upsample
            bgl_tex_sample_2d(
                3,
                cs_vis,
                wgpu::TextureSampleType::Float { filterable: false },
            ),
        ],
    });

    let empty = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("empty_bgl"),
        entries: &[],
    });

    let blit = device.create_bind_group_layout(&wgpu::BindGroupLayoutDescriptor {
        label: Some("blit_bgl"),
        entries: &[
            bgl_tex_sample_2d(
                0,
                wgpu::ShaderStages::FRAGMENT,
                wgpu::TextureSampleType::Float { filterable: true },
            ),
            wgpu::BindGroupLayoutEntry {
                binding: 1,
                visibility: wgpu::ShaderStages::FRAGMENT,
                ty: wgpu::BindingType::Sampler(wgpu::SamplerBindingType::Filtering),
                count: None,
            },
            bgl_uniform(2, wgpu::ShaderStages::FRAGMENT),
        ],
    });

    Layouts {
        primary,
        scene,
        godray,
        composite,
        empty,
        blit,
    }
}

// src/render/state/mod.rs
// -----------------------
// src/render/state/mod.rs
// -----------------------
mod bindgroups;
mod buffers;
mod layout;
mod pipelines;
pub mod textures;

use crate::{
    config,
    render::gpu_types::{CameraGpu, ClipmapGpu, OverlayGpu},
    streaming::ChunkUpload,
};

use bindgroups::{create_bind_groups, BindGroups};
use buffers::{create_persistent_buffers, Buffers};
use layout::{create_layouts, Layouts};
use pipelines::{create_pipelines, Pipelines};
use textures::{create_textures, quarter_dim, TextureSet};

pub struct Renderer {
    device: wgpu::Device,
    queue: wgpu::Queue,

    sampler: wgpu::Sampler,

    layouts: Layouts,
    pipelines: Pipelines,
    buffers: Buffers,
    textures: TextureSet,
    bind_groups: BindGroups,

    ping: usize,
}

impl Renderer {
    pub async fn new(
        adapter: &wgpu::Adapter,
        surface_format: wgpu::TextureFormat,
        width: u32,
        height: u32,
    ) -> Self {
        let adapter_limits = adapter.limits();
        let required_limits = wgpu::Limits {
            max_storage_buffer_binding_size: adapter_limits.max_storage_buffer_binding_size,
            max_buffer_size: adapter_limits.max_buffer_size,
            ..wgpu::Limits::default()
        };

        let (device, queue) = adapter
            .request_device(
                &wgpu::DeviceDescriptor {
                    label: Some("device"),
                    required_features: wgpu::Features::empty(),
                    required_limits,
                },
                None,
            )
            .await
            .unwrap();

        let cs_module = device.create_shader_module(wgpu::ShaderModuleDescriptor {
            label: Some("ray_cs"),
            source: wgpu::ShaderSource::Wgsl(crate::render::shaders::ray_cs_wgsl().into()),
        });

        let fs_module = device.create_shader_module(wgpu::ShaderModuleDescriptor {
            label: Some("blit"),
            source: wgpu::ShaderSource::Wgsl(crate::render::shaders::blit_wgsl().into()),
        });

        let sampler = device.create_sampler(&wgpu::SamplerDescriptor {
            label: Some("nearest_sampler"),
            mag_filter: wgpu::FilterMode::Nearest,
            min_filter: wgpu::FilterMode::Nearest,
            mipmap_filter: wgpu::FilterMode::Nearest,
            ..Default::default()
        });

        let layouts = create_layouts(&device);
        let buffers = create_persistent_buffers(&device);

        let textures = create_textures(&device, width, height);

        let pipelines = create_pipelines(&device, &layouts, &cs_module, &fs_module, surface_format);

        let bind_groups = create_bind_groups(&device, &layouts, &buffers, &textures, &sampler);

        Self {
            device,
            queue,
            sampler,
            layouts,
            pipelines,
            buffers,
            textures,
            bind_groups,
            ping: 0,
        }
    }

    pub fn device(&self) -> &wgpu::Device {
        &self.device
    }

    pub fn queue(&self) -> &wgpu::Queue {
        &self.queue
    }

    pub fn resize_output(&mut self, width: u32, height: u32) {
        self.textures = create_textures(&self.device, width, height);
        self.bind_groups = create_bind_groups(
            &self.device,
            &self.layouts,
            &self.buffers,
            &self.textures,
            &self.sampler,
        );

        self.ping = 0;
    }

    pub fn write_chunk_grid(&self, grid: &[u32]) {
        let n = grid.len().min(self.buffers.grid_capacity as usize);
        self.queue.write_buffer(
            &self.buffers.chunk_grid,
            0,
            bytemuck::cast_slice(&grid[..n]),
        );
    }

    pub fn write_camera(&self, cam: &CameraGpu) {
        self.queue
            .write_buffer(&self.buffers.camera, 0, bytemuck::bytes_of(cam));
    }

    pub fn write_overlay(&self, ov: &OverlayGpu) {
        self.queue
            .write_buffer(&self.buffers.overlay, 0, bytemuck::bytes_of(ov));
    }

    pub fn write_clipmap(&self, clip: &ClipmapGpu) {
        self.queue
            .write_buffer(&self.buffers.clipmap, 0, bytemuck::bytes_of(clip));
    }

    /// FP16 clipmap patch upload into a sub-rectangle of a level.
    ///
    /// `data_f16` is w*h u16 values (IEEE half bits), row-major for the patch.
    ///
    /// IMPORTANT: WebGPU requires `bytes_per_row` to be a multiple of 256 bytes.
    /// For narrow strips (especially columns), we pad each row on the CPU when needed.
    pub fn write_clipmap_patch(&self, level: u32, x: u32, y: u32, w: u32, h: u32, data_f16: &[u16]) {
        let res = config::CLIPMAP_RES;
        if level >= config::CLIPMAP_LEVELS {
            return;
        }
        if w == 0 || h == 0 {
            return;
        }
        if x + w > res || y + h > res {
            return;
        }

        let expected = (w as usize) * (h as usize);
        if data_f16.len() != expected {
            return;
        }

        // Source row pitch (tightly packed)
        let row_bytes = (w * 2) as usize; // R16Float => 2 bytes per texel

        // WebGPU alignment requirement
        let align = 256usize;
        let padded_row_bytes = ((row_bytes + align - 1) / align) * align;

        let bytes: Vec<u8>;
        let bytes_ref: &[u8];

        if padded_row_bytes == row_bytes {
            bytes_ref = bytemuck::cast_slice(data_f16);
        } else {
            // Pad each row up to padded_row_bytes
            bytes = {
                let mut out = vec![0u8; padded_row_bytes * (h as usize)];
                let src: &[u8] = bytemuck::cast_slice(data_f16);

                for row in 0..(h as usize) {
                    let src_off = row * row_bytes;
                    let dst_off = row * padded_row_bytes;
                    out[dst_off..dst_off + row_bytes].copy_from_slice(&src[src_off..src_off + row_bytes]);
                }
                out
            };
            bytes_ref = &bytes;
        }

        self.queue.write_texture(
            wgpu::ImageCopyTexture {
                texture: &self.textures.clip_height.tex,
                mip_level: 0,
                origin: wgpu::Origin3d { x, y, z: level },
                aspect: wgpu::TextureAspect::All,
            },
            bytes_ref,
            wgpu::ImageDataLayout {
                offset: 0,
                bytes_per_row: Some(padded_row_bytes as u32),
                rows_per_image: Some(h),
            },
            wgpu::Extent3d {
                width: w,
                height: h,
                depth_or_array_layers: 1,
            },
        );
    }

    /// Convenience full-level upload (kept for compatibility / debugging).
    pub fn write_clipmap_level(&self, level: u32, data_f16: &[u16]) {
        let res = config::CLIPMAP_RES as usize;
        let expected = res * res;
        if data_f16.len() != expected {
            return;
        }
        self.write_clipmap_patch(
            level,
            0,
            0,
            config::CLIPMAP_RES,
            config::CLIPMAP_RES,
            data_f16,
        );
    }

    pub fn apply_chunk_uploads(&self, uploads: Vec<ChunkUpload>) {
        let node_stride = std::mem::size_of::<crate::render::gpu_types::NodeGpu>() as u64;
        let meta_stride = std::mem::size_of::<crate::render::gpu_types::ChunkMetaGpu>() as u64;

        for u in uploads {
            if u.slot < self.buffers.chunk_capacity {
                let meta_off = (u.slot as u64) * meta_stride;
                self.queue
                    .write_buffer(&self.buffers.chunk, meta_off, bytemuck::bytes_of(&u.meta));
            }

            if !u.nodes.is_empty() {
                let needed = u.nodes.len() as u32;

                if u.node_base <= self.buffers.node_capacity
                    && u.node_base + needed <= self.buffers.node_capacity
                {
                    let node_off = (u.node_base as u64) * node_stride;
                    self.queue.write_buffer(
                        &self.buffers.node,
                        node_off,
                        bytemuck::cast_slice(u.nodes.as_ref()),
                    );
                }
            }
        }
    }

    pub fn encode_compute(&mut self, encoder: &mut wgpu::CommandEncoder, width: u32, height: u32) {
        {
            let mut cpass = encoder.begin_compute_pass(&wgpu::ComputePassDescriptor {
                label: Some("primary_pass"),
                timestamp_writes: None,
            });

            cpass.set_pipeline(&self.pipelines.primary);
            cpass.set_bind_group(0, &self.bind_groups.primary, &[]);

            let gx = (width + 7) / 8;
            let gy = (height + 7) / 8;
            cpass.dispatch_workgroups(gx, gy, 1);
        }

        let ping = self.ping;
        let pong = 1 - ping;

        {
            let qw = quarter_dim(width);
            let qh = quarter_dim(height);

            let mut cpass = encoder.begin_compute_pass(&wgpu::ComputePassDescriptor {
                label: Some("godray_pass"),
                timestamp_writes: None,
            });

            cpass.set_pipeline(&self.pipelines.godray);
            cpass.set_bind_group(0, &self.bind_groups.scene, &[]);
            cpass.set_bind_group(1, &self.bind_groups.godray[ping], &[]);

            let gx = (qw + 7) / 8;
            let gy = (qh + 7) / 8;
            cpass.dispatch_workgroups(gx, gy, 1);
        }

        {
            let mut cpass = encoder.begin_compute_pass(&wgpu::ComputePassDescriptor {
                label: Some("composite_pass"),
                timestamp_writes: None,
            });

            cpass.set_pipeline(&self.pipelines.composite);

            // group(0) must match layouts.scene now
            cpass.set_bind_group(0, &self.bind_groups.scene, &[]);

            // group(1) is still empty (or you can omit setting it)
            cpass.set_bind_group(1, &self.bind_groups.empty, &[]);

            // group(2) is your composite textures
            cpass.set_bind_group(2, &self.bind_groups.composite[pong], &[]);

            let gx = (width + 7) / 8;
            let gy = (height + 7) / 8;
            cpass.dispatch_workgroups(gx, gy, 1);
        }

        self.ping = pong;
    }

    pub fn encode_blit(&self, encoder: &mut wgpu::CommandEncoder, frame_view: &wgpu::TextureView) {
        let mut rpass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
            label: Some("blit_pass"),
            color_attachments: &[Some(wgpu::RenderPassColorAttachment {
                view: frame_view,
                resolve_target: None,
                ops: wgpu::Operations {
                    load: wgpu::LoadOp::Clear(wgpu::Color::BLACK),
                    store: wgpu::StoreOp::Store,
                },
            })],
            depth_stencil_attachment: None,
            timestamp_writes: None,
            occlusion_query_set: None,
        });

        rpass.set_pipeline(&self.pipelines.blit);
        rpass.set_bind_group(0, &self.bind_groups.blit, &[]);
        rpass.draw(0..3, 0..1);
    }
}

// src/render/state/pipelines.rs
// -----------------------------
// src/render/state/pipelines.rs
//
// Pipeline creation.
// This is intentionally isolated so the renderer logic (per-frame encoding) isn't
// buried under wgpu setup boilerplate.
//
// Terminology:
// - BindGroupLayout (BGL): describes what resources exist at @group/@binding.
// - PipelineLayout (PL): ordered list of BGLs for group(0), group(1), ...
// - Pipeline: compiled/validated shader entry point + fixed state + pipeline layout.
//
// Rule of thumb:
// The order of BGLs in `bind_group_layouts` must match the group indices used in WGSL.
// If a shader references @group(2), then the pipeline layout must include entries
// for group(0) and group(1) as well (even if they're "empty" placeholders).

use super::layout::Layouts;

pub struct Pipelines {
    /// Compute pipeline for the primary full-resolution pass (writes color/depth).
    pub primary: wgpu::ComputePipeline,

    /// Compute pipeline for the quarter-resolution godray pass (ping-pong temporal).
    pub godray: wgpu::ComputePipeline,

    /// Compute pipeline for the full-resolution composite pass (writes final output).
    pub composite: wgpu::ComputePipeline,

    /// Render pipeline for the final blit to the swapchain (fullscreen triangle).
    pub blit: wgpu::RenderPipeline,
}

/// Helper to build a compute pipeline with a specific entry point and bind group layout list.
///
/// `bgls` order defines the pipeline layout's group indices:
/// - bgls[0] => group(0)
/// - bgls[1] => group(1)
/// - ...
fn make_compute_pipeline(
    device: &wgpu::Device,
    label: &str,
    module: &wgpu::ShaderModule,
    entry: &str,
    bgls: &[&wgpu::BindGroupLayout],
) -> wgpu::ComputePipeline {
    // Create a pipeline layout named "{label}_pl" that fixes the bind group schema.
    let pl = device.create_pipeline_layout(&wgpu::PipelineLayoutDescriptor {
        label: Some(&format!("{label}_pl")),
        bind_group_layouts: bgls,
        // No push constants used by these shaders.
        push_constant_ranges: &[],
    });

    // Create the compute pipeline referencing the WGSL entry point.
    device.create_compute_pipeline(&wgpu::ComputePipelineDescriptor {
        label: Some(label),
        layout: Some(&pl),
        module,
        entry_point: entry,
        compilation_options: Default::default(),
    })
}

/// Create all pipelines (compute + blit).
///
/// Inputs:
/// - `cs_module`: WGSL module containing compute entry points.
/// - `fs_module`: WGSL module containing vertex/fragment entry points for blit.
/// - `surface_format`: swapchain format used for the final render target.
pub fn create_pipelines(
    device: &wgpu::Device,
    layouts: &Layouts,
    cs_module: &wgpu::ShaderModule,
    fs_module: &wgpu::ShaderModule,
    surface_format: wgpu::TextureFormat,
) -> Pipelines {
    // -------------------------------------------------------------------------
    // Compute pipelines
    // -------------------------------------------------------------------------

    // Primary pass:
    // Uses group(0) = layouts.primary, which includes:
    // - camera + scene buffers
    // - storage outputs for color/depth
    let primary = make_compute_pipeline(
        device,
        "primary_pipeline",
        cs_module,
        "main_primary",
        &[&layouts.primary],
    );

    // Godray pass:
    // Uses:
    //   group(0) = layouts.scene  (camera + scene buffers only)
    //   group(1) = layouts.godray (depth sample + history sample + out storage)
    let godray = make_compute_pipeline(
        device,
        "godray_pipeline",
        cs_module,
        "main_godray",
        &[&layouts.scene, &layouts.godray],
    );

    // Composite pass:
    // Shader reads from @group(2) (color + godray + output storage).
    // wgpu requires the pipeline layout to include group(0) and group(1) slots too,
    // so we provide empty placeholder layouts for those indices.
    let composite = make_compute_pipeline(
        device,
        "composite_pipeline",
        cs_module,
        "main_composite",
        // group(0)=scene (cam + buffers), group(1)=empty, group(2)=composite textures
        &[&layouts.scene, &layouts.empty, &layouts.composite],
    );

    // -------------------------------------------------------------------------
    // Render pipeline: blit
    // -------------------------------------------------------------------------
    //
    // Full-screen triangle approach:
    // - No vertex buffers.
    // - Vertex shader generates positions from vertex_index.
    // - Fragment shader samples the renderer output texture.

    // Pipeline layout for blit uses a single bind group: group(0) = layouts.blit.
    let blit_pl = device.create_pipeline_layout(&wgpu::PipelineLayoutDescriptor {
        label: Some("blit_pl"),
        bind_group_layouts: &[&layouts.blit],
        push_constant_ranges: &[],
    });

    // Render pipeline state:
    // - Targets the swapchain format.
    // - Uses REPLACE blending (overwrite framebuffer).
    // - Default primitive/multisample state is fine for a simple fullscreen draw.
    let blit = device.create_render_pipeline(&wgpu::RenderPipelineDescriptor {
        label: Some("blit_pipeline"),
        layout: Some(&blit_pl),
        vertex: wgpu::VertexState {
            module: fs_module,
            entry_point: "vs_main",
            // No vertex buffers; vertices are synthesized in the vertex shader.
            buffers: &[],
            compilation_options: Default::default(),
        },
        fragment: Some(wgpu::FragmentState {
            module: fs_module,
            entry_point: "fs_main",
            targets: &[Some(wgpu::ColorTargetState {
                format: surface_format,
                // Overwrite swapchain pixel with sampled color.
                blend: Some(wgpu::BlendState::REPLACE),
                write_mask: wgpu::ColorWrites::ALL,
            })],
            compilation_options: Default::default(),
        }),
        // Default triangle list, CCW front face, etc. (fullscreen triangle doesn't care much).
        primitive: wgpu::PrimitiveState::default(),
        depth_stencil: None,
        multisample: wgpu::MultisampleState::default(),
        multiview: None,
    });

    Pipelines {
        primary,
        godray,
        composite,
        blit,
    }
}

// src/render/state/textures.rs
// ----------------------------
// src/render/state/textures.rs
// ----------------------------

use crate::{
    config,
    render::resources::{create_output_texture, OutputTex},
};

pub struct Tex2D {
    pub view: wgpu::TextureView,
}

pub struct Tex2DArray {
    pub tex: wgpu::Texture,
    pub view: wgpu::TextureView,
}

pub struct TextureSet {
    pub output: OutputTex,
    pub color: Tex2D,
    pub depth: Tex2D,
    pub godray: [Tex2D; 2],

    pub clip_height: Tex2DArray,
}

pub fn quarter_dim(x: u32) -> u32 {
    (x + 3) / 4
}

fn make_tex2d(
    device: &wgpu::Device,
    label: &str,
    w: u32,
    h: u32,
    format: wgpu::TextureFormat,
    usage: wgpu::TextureUsages,
) -> Tex2D {
    let w = w.max(1);
    let h = h.max(1);

    let tex = device.create_texture(&wgpu::TextureDescriptor {
        label: Some(label),
        size: wgpu::Extent3d {
            width: w,
            height: h,
            depth_or_array_layers: 1,
        },
        mip_level_count: 1,
        sample_count: 1,
        dimension: wgpu::TextureDimension::D2,
        format,
        usage,
        view_formats: &[],
    });

    let view = tex.create_view(&Default::default());
    Tex2D { view }
}

fn make_tex2d_array(
    device: &wgpu::Device,
    label: &str,
    w: u32,
    h: u32,
    layers: u32,
    format: wgpu::TextureFormat,
    usage: wgpu::TextureUsages,
) -> Tex2DArray {
    let w = w.max(1);
    let h = h.max(1);
    let layers = layers.max(1);

    let tex = device.create_texture(&wgpu::TextureDescriptor {
        label: Some(label),
        size: wgpu::Extent3d {
            width: w,
            height: h,
            depth_or_array_layers: layers,
        },
        mip_level_count: 1,
        sample_count: 1,
        dimension: wgpu::TextureDimension::D2,
        format,
        usage,
        view_formats: &[],
    });

    let view = tex.create_view(&wgpu::TextureViewDescriptor {
        label: Some(&format!("{label}_view")),
        format: Some(format),
        dimension: Some(wgpu::TextureViewDimension::D2Array),
        aspect: wgpu::TextureAspect::All,
        base_mip_level: 0,
        mip_level_count: Some(1),
        base_array_layer: 0,
        array_layer_count: Some(layers),
    });

    Tex2DArray { tex, view }
}

pub fn create_textures(device: &wgpu::Device, width: u32, height: u32) -> TextureSet {
    let width = width.max(1);
    let height = height.max(1);

    let rw_tex_usage =
        wgpu::TextureUsages::STORAGE_BINDING | wgpu::TextureUsages::TEXTURE_BINDING;

    let output = create_output_texture(device, width, height);

    let color = make_tex2d(
        device,
        "color_tex",
        width,
        height,
        wgpu::TextureFormat::Rgba16Float,
        rw_tex_usage,
    );

    let depth = make_tex2d(
        device,
        "depth_tex",
        width,
        height,
        wgpu::TextureFormat::R32Float,
        rw_tex_usage,
    );

    let qw = quarter_dim(width);
    let qh = quarter_dim(height);

    let godray = [
        make_tex2d(
            device,
            "godray_a",
            qw,
            qh,
            wgpu::TextureFormat::Rgba16Float,
            rw_tex_usage,
        ),
        make_tex2d(
            device,
            "godray_b",
            qw,
            qh,
            wgpu::TextureFormat::Rgba16Float,
            rw_tex_usage,
        ),
    ];

    // FP16 clipmap height: R16Float (half bandwidth vs R32Float)
    let clip_height = make_tex2d_array(
        device,
        "clip_height",
        config::CLIPMAP_RES,
        config::CLIPMAP_RES,
        config::CLIPMAP_LEVELS,
        wgpu::TextureFormat::R16Float,
        wgpu::TextureUsages::TEXTURE_BINDING | wgpu::TextureUsages::COPY_DST,
    );

    TextureSet {
        output,
        color,
        depth,
        godray,
        clip_height,
    }
}

