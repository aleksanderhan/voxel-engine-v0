// src/app/mod.rs
// --------------
// src/app/mod.rs
//
// High-level application glue:
// - Owns the window + wgpu surface configuration (swapchain-ish state).
// - Owns input + camera state.
// - Owns world/chunk streaming state.
// - Delegates all GPU resource ownership and rendering work to `Renderer`.
//
// The core loop is driven by winit events. We run with `ControlFlow::Poll`,
// so we continually render (and handle input) as fast as the system allows.

use std::sync::Arc;
use std::time::Instant;

use winit::{
    event::*,
    event_loop::{ControlFlow, EventLoop},
    window::Window,
};

use crate::{
    camera::Camera,
    config,
    input::InputState,
    render::{CameraGpu, OverlayGpu, Renderer},
    streaming::ChunkManager,
    world::WorldGen,
};

/// Entrypoint called by main:
/// - Builds the `App` (async, because wgpu adapter/device acquisition is async).
/// - Starts the winit event loop and forwards events into the app.
pub async fn run(event_loop: EventLoop<()>, window: Arc<Window>) {
    let mut app = App::new(window).await;

    // winit's `run` never returns in normal operation (it exits the process/event loop).
    event_loop.run(move |event, elwt| {
        elwt.set_control_flow(ControlFlow::Wait);

        match &event {
            Event::AboutToWait => {
                // ask for one redraw; OS will pace this (vsync / compositor)
                app.window.request_redraw();
            }
            Event::WindowEvent { event: WindowEvent::RedrawRequested, .. } => {
                app.frame(elwt);
            }
            _ => {
                app.handle_event(event, elwt);
            }
        }
    }).unwrap();

}

/// Application state that lives for the duration of the event loop.
///
/// Ownership split:
/// - `App` owns the *presentation surface* and surface config (format/size/present mode).
/// - `Renderer` owns the wgpu `Device` and `Queue` and all GPU resources/pipelines.
///   This keeps GPU ownership centralized and makes `App` mostly orchestration.
pub struct App {
    /// Shared window handle (Arc keeps it alive as long as needed).
    window: Arc<Window>,

    /// Time origin for animations / time-based shader params.
    start_time: Instant,

    // --- WGPU "presentation" state (kept here, not in Renderer) ---
    //
    // NOTE: The underscore-prefixed fields are intentionally retained so their
    // lifetimes match expectations and to avoid "never read" warnings.
    //
    // - Instance: top-level wgpu context (backend selection, surface creation).
    // - Surface: platform swapchain surface tied to the window.
    // - Adapter: selected physical GPU.
    // - Surface format: chosen swapchain pixel format.
    // - Surface configuration: width/height/present mode/usage, etc.
    _instance: wgpu::Instance,
    surface: wgpu::Surface<'static>,
    _adapter: wgpu::Adapter,
    _surface_format: wgpu::TextureFormat,
    config: wgpu::SurfaceConfiguration,

    /// All actual GPU pipelines/resources and per-frame encoding helpers.
    renderer: Renderer,

    // --- World + streaming state ---
    /// Procedural world generator (shared, so streaming can keep refs cheaply).
    world: Arc<WorldGen>,
    /// Chunk streaming / residency manager (decides what to load/unload/upload).
    chunks: ChunkManager,

    // --- Interaction state ---
    /// Aggregated input state updated from winit events.
    input: InputState,
    /// Camera pose/orientation and input integration.
    camera: Camera,

    // --- FPS overlay bookkeeping ---
    /// Most recent FPS value (rounded).
    fps_value: u32,
    /// Frames counted since last FPS update.
    fps_frames: u32,
    /// Timestamp of last FPS update sample window.
    fps_last: Instant,
}

impl App {
    /// Build a new `App`.
    ///
    /// Steps:
    /// 1) Create wgpu instance + surface from the window.
    /// 2) Pick adapter (GPU).
    /// 3) Choose surface format + configure surface for the initial window size.
    /// 4) Create `Renderer` (device/queue + pipelines).
    /// 5) Create world generator, chunk manager, camera, and input.
    pub async fn new(window: Arc<Window>) -> Self {
        let start_time = Instant::now();

        // Initial size (may be zero on some platforms during resize/minimize, so we clamp later).
        let size = window.inner_size();

        // Create the wgpu instance (selects backend internally).
        let instance = wgpu::Instance::default();

        // Surface must outlive the event loop; Arc<Window> makes this easy.
        // The 'static surface lifetime comes from the fact the window is kept alive.
        let surface = instance.create_surface(window.clone()).unwrap();

        // Ask wgpu to pick an adapter (GPU) that can present to this surface.
        let adapter = instance
            .request_adapter(&wgpu::RequestAdapterOptions {
                compatible_surface: Some(&surface),
                // Prefer a discrete / high perf GPU if available.
                power_preference: wgpu::PowerPreference::HighPerformance,
                // Don't force a fallback adapter (software/low-feature) unless needed.
                force_fallback_adapter: false,
            })
            .await
            .unwrap();

        // Query what the surface supports with this adapter (formats, modes, etc.).
        let surface_caps = surface.get_capabilities(&adapter);

        // Pick the first advertised format.
        // (Often this is a sensible SRGB-ish format, but you could choose based on preference.)
        let surface_format = surface_caps.formats[0];

        // Create the surface configuration ("swapchain config"):
        // - usage: we render into it as a render attachment.
        // - width/height: clamp to >= 1 to avoid invalid zero-sized surfaces.
        // - present_mode/alpha_mode: choose first supported.
        // - desired_maximum_frame_latency: reduce queued frames (helps latency).
        let config_sc = wgpu::SurfaceConfiguration {
            usage: wgpu::TextureUsages::RENDER_ATTACHMENT,
            format: surface_format,
            width: size.width.max(1),
            height: size.height.max(1),
            present_mode: surface_caps.present_modes[0],
            alpha_mode: surface_caps.alpha_modes[0],
            view_formats: vec![],
            desired_maximum_frame_latency: 2,
        };

        // Renderer owns the real device/queue; App owns surface/config.
        // Renderer is async because it requests/creates the wgpu Device/Queue.
        let renderer =
            Renderer::new(&adapter, surface_format, config_sc.width, config_sc.height).await;

        // Configure once, with the real device we will render with.
        surface.configure(renderer.device(), &config_sc);

        // Create world generation & chunk streaming controller.
        let world = Arc::new(WorldGen::new(12345));
        let chunks = ChunkManager::new(world.clone());

        // Camera starts with an initial aspect ratio derived from the surface size.
        let camera = Camera::new(config_sc.width as f32 / config_sc.height as f32);

        // Input begins empty (no keys pressed, no mouse delta, etc.).
        let input = InputState::default();

        Self {
            window,
            start_time,
            _instance: instance,
            surface,
            _adapter: adapter,
            _surface_format: surface_format,
            config: config_sc,
            renderer,
            world,
            chunks,
            input,
            camera,
            fps_value: 0,
            fps_frames: 0,
            fps_last: Instant::now(),
        }
    }

    /// Central event dispatcher called by the event loop.
    ///
    /// We route:
    /// - `DeviceEvent` into raw input (mouse motion, etc.).
    /// - `WindowEvent` into window-related input and resize/close handling.
    /// - `AboutToWait` as a "tick" to render a frame.
    pub fn handle_event(
        &mut self,
        event: Event<()>,
        elwt: &winit::event_loop::EventLoopWindowTarget<()>,
    ) {
        match event {
            // DeviceEvent fires for raw input independent of focus/window coords
            // (e.g. mouse delta from high precision devices).
            Event::DeviceEvent { event, .. } => {
                self.input.on_device_event(&event);
            }

            // WindowEvent includes keyboard, mouse buttons, focus, resize, etc.
            Event::WindowEvent { event, .. } => {
                // Let input layer consume/track events first (focus changes, key state, etc.).
                // Return value is ignored here, but could indicate "consumed".
                let _ = self.input.on_window_event(&event, &self.window);

                match event {
                    // OS requested the window close (Alt+F4, close button, etc.).
                    WindowEvent::CloseRequested => elwt.exit(),

                    // Window was resized; update surface config and renderer output.
                    WindowEvent::Resized(new_size) => {
                        // Clamp to avoid 0-sized surfaces when minimized.
                        self.config.width = new_size.width.max(1);
                        self.config.height = new_size.height.max(1);

                        // Reconfigure the surface swapchain and notify renderer
                        // so any size-dependent textures can be resized.
                        self.surface.configure(self.renderer.device(), &self.config);
                        self.renderer
                            .resize_output(self.config.width, self.config.height);
                    }

                    _ => {}
                }
            }

            // `AboutToWait` is emitted once winit has processed all pending events
            // and is about to sleep. Under Poll control flow, this is effectively
            // our per-frame callback.
            Event::AboutToWait => self.frame(elwt),

            _ => {}
        }
    }

    /// Render/update one frame.
    ///
    /// Pipeline:
    /// 1) Integrate input into camera state.
    /// 2) Update chunk streaming decisions based on camera position/forward.
    /// 3) Build GPU camera parameters (inverse matrices, chunk grid info, etc.).
    /// 4) Update FPS overlay values and write overlay uniforms.
    /// 5) Upload any newly-streamed chunk data to GPU.
    /// 6) Acquire swapchain image, encode compute + blit passes, submit, present.
    fn frame(&mut self, elwt: &winit::event_loop::EventLoopWindowTarget<()>) {
        // 1) camera integrate
        //
        // Convert accumulated input state (keys/mouse deltas) into updated camera pose.
        self.camera.integrate_input(&mut self.input);

        // 2) streaming update
        //
        // Use camera pose to decide which chunks should be present/resident.
        // Then write the chunk grid metadata (addresses/ids) to the renderer.
        let cam_pos = self.camera.position();
        let cam_fwd = self.camera.forward();
        let grid_changed = self.chunks.update(&self.world, cam_pos, cam_fwd);
        if grid_changed {
            self.renderer.write_chunk_grid(self.chunks.chunk_grid());
        }


        // 3) camera matrices -> CameraGpu
        //
        // Compute view/projection matrices and pack their inverses for shader usage.
        // Inverse matrices let shaders go from screen-space rays back into world-space.
        let aspect = self.config.width as f32 / self.config.height as f32;
        let cf = self.camera.frame_matrices(aspect);

        // Elapsed time since startup (typically used for animation/noise jitter/etc.).
        let t = self.start_time.elapsed().as_secs_f32();

        // Raymarch/trace step limit: derived from chunk size but clamped to a sane band.
        // (Avoids tiny chunk sizes producing too few steps, and huge sizes producing too many.)
        let max_steps = (config::CHUNK_SIZE * 2).clamp(48, 96);

        // Camera uniform/SSBO payload for GPU.
        let cam_gpu = CameraGpu {
            view_inv: cf.view_inv.to_cols_array_2d(),
            proj_inv: cf.proj_inv.to_cols_array_2d(),
            cam_pos: [cf.pos.x, cf.pos.y, cf.pos.z, 1.0],

            // Chunking parameters used by shaders to interpret the streamed grid.
            chunk_size: config::CHUNK_SIZE,
            chunk_count: self.chunks.chunk_count(),
            max_steps,
            _pad0: 0,

            // Misc voxel/shader params:
            // [voxel_size_in_meters, time, ?, ?] (the last two likely tune lighting/density).
            voxel_params: [config::VOXEL_SIZE_M_F32, t, 2.0, 0.002],

            // Chunk grid origin and dimensions in chunk coordinates.
            // Packed as ivec-ish arrays with a trailing padding element.
            grid_origin_chunk: [
                self.chunks.grid_origin()[0],
                self.chunks.grid_origin()[1],
                self.chunks.grid_origin()[2],
                0,
            ],
            grid_dims: [
                self.chunks.grid_dims()[0],
                self.chunks.grid_dims()[1],
                self.chunks.grid_dims()[2],
                0,
            ],
        };

        // Upload camera params to GPU.
        self.renderer.write_camera(&cam_gpu);

        // 4) fps overlay
        //
        // We update FPS roughly 4 times per second (every 0.25s) to smooth noise.
        self.fps_frames += 1;
        let dt = self.fps_last.elapsed().as_secs_f32();
        if dt >= 0.25 {
            let fps = (self.fps_frames as f32) / dt;
            self.fps_value = fps.round() as u32;
            self.fps_frames = 0;
            self.fps_last = Instant::now();
        }

        // Overlay uniform payload for the GPU overlay pass.
        let overlay = OverlayGpu {
            fps: self.fps_value,
            width: self.config.width,
            height: self.config.height,
            _pad0: 0,
        };
        self.renderer.write_overlay(&overlay);

        // 5) update scene buffers if changed
        //
        // If the chunk manager has produced new/updated chunk data (meshes/voxels/etc),
        // apply those uploads to GPU resources before encoding this frame.
        self.renderer.apply_chunk_uploads(self.chunks.take_uploads());

        // 6) acquire frame + encode passes
        //
        // Acquire the next drawable surface texture. Handle common surface errors.
        let frame = match self.surface.get_current_texture() {
            Ok(f) => f,

            // Surface got invalidated (resize, display mode change, etc.) -> reconfigure.
            Err(wgpu::SurfaceError::Lost | wgpu::SurfaceError::Outdated) => {
                self.surface.configure(self.renderer.device(), &self.config);
                return;
            }

            // Temporary issue: skip this frame.
            Err(wgpu::SurfaceError::Timeout) => return,

            // Fatal-ish: GPU memory exhaustion -> exit.
            Err(wgpu::SurfaceError::OutOfMemory) => {
                elwt.exit();
                return;
            }
        };

        // View into the swapchain image used as render target in the blit pass.
        let frame_view = frame.texture.create_view(&Default::default());

        // Command encoder collects GPU commands for this frame into a single submission.
        let mut encoder = self
            .renderer
            .device()
            .create_command_encoder(&wgpu::CommandEncoderDescriptor {
                label: Some("encoder"),
            });

        // First: run compute (likely raymarching / voxel traversal) into an offscreen target.
        self.renderer
            .encode_compute(&mut encoder, self.config.width, self.config.height);

        // Then: blit (copy/compose) the offscreen output into the swapchain image.
        self.renderer.encode_blit(&mut encoder, &frame_view);

        // Submit GPU work and present the swapchain image.
        self.renderer.queue().submit(Some(encoder.finish()));
        frame.present();
    }
}

// src/camera.rs
// -------------
// src/camera.rs
use glam::{Mat4, Vec3};

use crate::{config, input::InputState};

pub struct Camera {
    pos: Vec3,
    yaw: f32,
    pitch: f32,
    fovy_rad: f32,
    z_near: f32,
    z_far: f32,
    // movement tuning
    speed_per_frame: f32,
    mouse_sens: f32,
}

pub struct CameraFrame {
    pub view_inv: Mat4,
    pub proj_inv: Mat4,
    pub pos: Vec3,
}

impl Camera {
    pub fn new(aspect: f32) -> Self {
        let _ = aspect; // kept for future (if you want aspect-dependent params)
        Self {
            pos: Vec3::new((config::CHUNK_SIZE as f32 * config::VOXEL_SIZE_M_F32) * 0.5, 20.0, -20.0),
            yaw: 0.0,
            pitch: 0.15,
            fovy_rad: 60.0_f32.to_radians(),
            z_near: 0.1,
            z_far: 1000.0,
            speed_per_frame: 0.35,
            mouse_sens: 0.0025,
        }
    }

    pub fn position(&self) -> Vec3 {
        self.pos
    }

    pub fn forward(&self) -> glam::Vec3 {
        let (yaw, pitch) = (self.yaw, self.pitch);
        glam::Vec3::new(
            yaw.sin() * pitch.cos(),
            pitch.sin(),
            yaw.cos() * pitch.cos(),
        )
        .normalize()
    }

    pub fn integrate_input(&mut self, input: &mut InputState) {
        // mouse look
        if input.focused {
            let (dx, dy) = input.take_mouse_delta();
            self.yaw -= dx * self.mouse_sens;
            self.pitch = (self.pitch - dy * self.mouse_sens).clamp(-1.55, 1.55);
        } else {
            // still clear deltas
            let _ = input.take_mouse_delta();
        }

        // basis
        let forward = Vec3::new(
            self.yaw.sin() * self.pitch.cos(),
            self.pitch.sin(),
            self.yaw.cos() * self.pitch.cos(),
        )
        .normalize();

        let right = forward.cross(Vec3::Y).normalize();
        let up = right.cross(forward).normalize();

        // movement (per-frame like your original)
        let k = input.keys;
        let mut vel = Vec3::ZERO;
        if k.w { vel += forward; }
        if k.s { vel -= forward; }
        if k.d { vel += right; }
        if k.a { vel -= right; }
        if k.space { vel += up; }
        if k.alt { vel -= up; }

        if vel.length_squared() > 0.0 {
            self.pos += vel.normalize() * self.speed_per_frame;
        }
    }

    pub fn frame_matrices(&self, aspect: f32) -> CameraFrame {
        let forward = Vec3::new(
            self.yaw.sin() * self.pitch.cos(),
            self.pitch.sin(),
            self.yaw.cos() * self.pitch.cos(),
        )
        .normalize();

        let view = Mat4::look_at_rh(self.pos, self.pos + forward, Vec3::Y);
        let proj = Mat4::perspective_rh(self.fovy_rad, aspect, self.z_near, self.z_far);

        CameraFrame {
            view_inv: view.inverse(),
            proj_inv: proj.inverse(),
            pos: self.pos,
        }
    }
}

// src/config.rs
// -------------
// src/config.rs
// -------------
// Global config knobs for the voxel/SVO renderer + streaming.

pub const CHUNK_SIZE: u32 = 128;

pub const ACTIVE_RADIUS: i32 = 4;
pub const KEEP_RADIUS: i32 = ACTIVE_RADIUS + 13;

pub const VOXEL_SIZE_M_F32: f32 = 0.10;
pub const VOXEL_SIZE_M_F64: f64 = 0.10;

// Keep this explicit so you can change voxel size later without hunting constants.
pub const VOXELS_PER_METER: i32 = 10; // 1.0 / 0.10

pub const WORKER_THREADS: usize = 4;
pub const MAX_IN_FLIGHT: usize = 8;

// GPU node arena budget (storage buffer capacity).
pub const NODE_BUDGET_BYTES: usize = 1024 * 1024 * 1024; // 1 GB

// CPU chunk cache budget (SVO nodes stored on CPU so we don't rebuild chunks).
// This is the *total* bytes of cached NodeGpu arrays across all cached chunks.
pub const CHUNK_CACHE_BUDGET_BYTES: usize = 512 * 1024 * 1024; // 512 MB

// src/input.rs
// ------------
// src/input.rs
use winit::{
    event::{DeviceEvent, ElementState, KeyEvent, WindowEvent},
    keyboard::{KeyCode, PhysicalKey},
    window::{CursorGrabMode, Window},
};

#[derive(Default, Clone, Copy)]
pub struct KeyState {
    pub w: bool,
    pub a: bool,
    pub s: bool,
    pub d: bool,
    pub space: bool,
    pub alt: bool,
}

impl KeyState {
    pub fn set(&mut self, code: KeyCode, down: bool) {
        match code {
            KeyCode::KeyW => self.w = down,
            KeyCode::KeyA => self.a = down,
            KeyCode::KeyS => self.s = down,
            KeyCode::KeyD => self.d = down,
            KeyCode::Space => self.space = down,
            KeyCode::AltLeft | KeyCode::AltRight => self.alt = down,
            _ => {}
        }
    }
}

#[derive(Default)]
pub struct InputState {
    pub keys: KeyState,
    pub focused: bool,
    pub mouse_dx: f32,
    pub mouse_dy: f32,
}

impl InputState {
    pub fn on_device_event(&mut self, event: &DeviceEvent) {
        if !self.focused {
            return;
        }
        if let DeviceEvent::MouseMotion { delta } = event {
            self.mouse_dx += delta.0 as f32;
            self.mouse_dy += delta.1 as f32;
        }
    }

    /// Returns true if event is fully handled/consumed.
    pub fn on_window_event(&mut self, event: &WindowEvent, window: &Window) -> bool {
        match event {
            WindowEvent::Focused(f) => {
                self.focused = *f;
                if self.focused {
                    let _ = window
                        .set_cursor_grab(CursorGrabMode::Locked)
                        .or_else(|_| window.set_cursor_grab(CursorGrabMode::Confined));
                    window.set_cursor_visible(false);
                } else {
                    let _ = window.set_cursor_grab(CursorGrabMode::None);
                    window.set_cursor_visible(true);
                }
                true
            }

            WindowEvent::KeyboardInput { event, .. } => {
                if let KeyEvent {
                    physical_key: PhysicalKey::Code(code),
                    state,
                    ..
                } = event
                {
                    let down = *state == ElementState::Pressed;
                    self.keys.set(*code, down);

                    if down && *code == KeyCode::Escape {
                        self.focused = false;
                        let _ = window.set_cursor_grab(CursorGrabMode::None);
                        window.set_cursor_visible(true);
                        return true;
                    }
                }
                false
            }

            _ => false,
        }
    }

    pub fn take_mouse_delta(&mut self) -> (f32, f32) {
        let dx = self.mouse_dx;
        let dy = self.mouse_dy;
        self.mouse_dx = 0.0;
        self.mouse_dy = 0.0;
        (dx, dy)
    }
}

// src/main.rs
// -----------
// src/main.rs
mod app;
mod camera;
mod config;
mod input;
mod render;
mod streaming;
mod svo;
mod world;

use std::sync::Arc;
use winit::{event_loop::EventLoop, window::{Fullscreen, WindowBuilder}, dpi::PhysicalSize};

fn main() {
    let event_loop = EventLoop::new().unwrap();

    let window = Arc::new(
        WindowBuilder::new()
            .with_title("SVO MVP")
            .with_inner_size(PhysicalSize::new(1280, 720))
            .build(&event_loop)
            .unwrap(),
    );
    window.set_fullscreen(Some(Fullscreen::Borderless(None)));

    pollster::block_on(app::run(event_loop, window));
}

// src/shaders/blit.wgsl
// ---------------------
// blit.wgsl
//
// Minimal fullscreen blit + tiny HUD:
//
// 1) Vertex shader emits a single fullscreen triangle (no vertex buffers).
//    This is a common trick to avoid cracks/precision issues on a fullscreen quad.
// 2) Fragment shader:
//    - samples the HDR-ish compute output texture
//    - applies a simple tonemap-like curve: c / (c + 1)
//    - optionally draws a tiny 3x5-pixel-font FPS overlay in the top-right.
//
// Bindings (must match Rust bind group layout `layouts.blit`):
//   @group(0) @binding(0): sampled output texture (img)
//   @group(0) @binding(1): sampler (samp)
//   @group(0) @binding(2): uniform overlay struct (fps + dimensions)

@group(0) @binding(0) var img : texture_2d<f32>;
@group(0) @binding(1) var samp : sampler;

// Overlay uniform block written from CPU each frame (or periodically for fps).
// `width/height` are used to place the overlay in screen space.
// `_pad0` keeps the struct 16-byte aligned (nice for uniform layout rules).
struct Overlay {
  fps    : u32,
  width  : u32,
  height : u32,
  _pad0  : u32,
};
@group(0) @binding(2) var<uniform> overlay : Overlay;


// -----------------------------------------------------------------------------
// 3x5 digit font helpers
// -----------------------------------------------------------------------------
//
// Digits are encoded as a 3x5 bitmap packed into 15 bits, row-major:
//   bit = y*3 + x
// with (x,y) = (0,0) being the top-left pixel of the digit cell.
//
// Example for "0":
//   111
//   101
//   101
//   101
//   111
//
// The returned constants are the 15-bit masks for digits 0..9.

fn digit_mask(d: u32) -> u32 {
  // 3x5 digits packed into 15 bits (row-major), bit0 = top-left.
  if (d == 0u) { return 0x7B6Fu; } // 111 101 101 101 111
  if (d == 1u) { return 0x749Au; } // 010 110 010 010 111
  if (d == 2u) { return 0x73E7u; } // 111 001 111 100 111
  if (d == 3u) { return 0x79E7u; } // 111 001 111 001 111
  if (d == 4u) { return 0x49EDu; } // 101 101 111 001 001
  if (d == 5u) { return 0x79CFu; } // 111 100 111 001 111
  if (d == 6u) { return 0x7BCFu; } // 111 100 111 101 111
  if (d == 7u) { return 0x4927u; } // 111 001 001 001 001
  if (d == 8u) { return 0x7BEFu; } // 111 101 111 101 111
  if (d == 9u) { return 0x79EFu; } // 111 101 111 001 111
  return 0u;
}

// Return true if the digit mask has a "pixel on" at (x,y) in a 3x5 grid.
fn mask_bit(mask: u32, x: u32, y: u32) -> bool {
  // x in [0..2], y in [0..4]
  let bit = y * 3u + x;
  return ((mask >> bit) & 1u) != 0u;
}


// -----------------------------------------------------------------------------
// Fullscreen triangle vertex shader
// -----------------------------------------------------------------------------
//
// Output:
// - @builtin(position): clip-space position
// - @location(0): UV in [0..1] (with overshoot values on the other two verts)
//   that interpolates correctly across the fullscreen triangle.

struct VSOut {
  @builtin(position) pos: vec4<f32>,
  @location(0) uv: vec2<f32>,
};

@vertex
fn vs_main(@builtin(vertex_index) i: u32) -> VSOut {
  // Fullscreen triangle in clip space.
  //
  // (-1,-1) is bottom-left, (3,-1) and (-1,3) extend beyond the screen so the
  // triangle fully covers the viewport after clipping.
  var p = array<vec2<f32>, 3>(
    vec2<f32>(-1.0, -1.0),
    vec2<f32>( 3.0, -1.0),
    vec2<f32>(-1.0,  3.0)
  );

  // UVs chosen so the interpolated UV lands in [0..1] over the visible region.
  // This avoids needing a quad/indices/vertex buffer.
  var uv = array<vec2<f32>, 3>(
    vec2<f32>(0.0, 1.0),
    vec2<f32>(2.0, 1.0),
    vec2<f32>(0.0, -1.0)
  );

  var o: VSOut;
  o.pos = vec4<f32>(p[i], 0.0, 1.0);
  o.uv = uv[i];
  return o;
}


// -----------------------------------------------------------------------------
// Fragment shader: sample + tonemap + FPS overlay
// -----------------------------------------------------------------------------

@fragment
fn fs_main(@builtin(position) frag_pos: vec4<f32>, @location(0) uv: vec2<f32>) -> @location(0) vec4<f32> {

  // Sample the renderer's final output texture.
  let c = textureSample(img, samp, uv);

  // Simple tonemap-ish curve:
  // - keeps values in [0..1)
  // - preserves highlight detail somewhat for HDR-ish inputs
  var rgb = c.rgb / (c.rgb + vec3<f32>(1.0));

  // ---- FPS overlay (top-right) ----
  //
  // The overlay draws up to 4 digits (clamped to 9999) using the 3x5 font,
  // scaled by `scale`, with a small margin from the top-right corner.
  //
  // Coordinate note:
  // `@builtin(position) frag_pos` is in framebuffer pixel coordinates.
  // This code treats (0,0) as the *top-left* for overlay placement by using
  // the provided overlay.height/width and direct pixel comparisons.

  // Screen size passed from CPU.
  let dims = vec2<u32>(overlay.width, overlay.height);

  // Current fragment coordinates as integer pixels.
  let px = vec2<u32>(u32(frag_pos.x), u32(frag_pos.y));

  // Layout parameters (edit to taste)
  let scale: u32 = 8u;     // size multiplier for each font pixel
  let digit_w: u32 = 3u * scale;
  let digit_h: u32 = 5u * scale;
  let gap: u32 = 1u * scale;
  let margin: u32 = 12u;

  // We always reserve 4 digits worth of space (right-aligned by placement).
  let num_digits: u32 = 4u;
  let total_w: u32 = num_digits * digit_w + (num_digits - 1u) * gap;

  // Compute overlay origin in signed integer space first to avoid u32 underflow.
  // This allows small windows where (dims.x - margin - total_w) would go negative.
  let ox_i: i32 = i32(dims.x) - i32(margin) - i32(total_w);
  let oy_i: i32 = i32(margin);

  // Clamp origin to >= 0 to keep comparisons valid.
  let origin_x: u32 = u32(max(ox_i, 0));
  let origin_y: u32 = u32(max(oy_i, 0));

  // Extract 4 digits from FPS (clamp to 0..9999).
  // d0 is ones, d3 is thousands.
  var v: u32 = min(overlay.fps, 9999u);
  let d0: u32 = v % 10u; v = v / 10u;
  let d1: u32 = v % 10u; v = v / 10u;
  let d2: u32 = v % 10u; v = v / 10u;
  let d3: u32 = v % 10u;

  // Overlay bounds test: only do digit math if we're inside the overlay rectangle.
  if (px.x >= origin_x && px.x < origin_x + total_w && px.y >= origin_y && px.y < origin_y + digit_h) {
    // Local pixel coords relative to the overlay origin.
    let local_x = px.x - origin_x;
    let local_y = px.y - origin_y;

    // Each digit occupies digit_w, followed by gap (except after last digit).
    let stride = digit_w + gap;

    // Which digit column is this pixel in? (0 = leftmost).
    let digit_i = local_x / stride;

    // Position within the digit+gap region.
    let in_digit_x = local_x % stride;

    // If we're in the gap column area, do nothing (leave underlying rgb).
    if (in_digit_x < digit_w) {
      // Map pixel coords into the 3x5 cell coordinates.
      let cell_x = (in_digit_x / scale); // 0..2
      let cell_y = (local_y / scale);    // 0..4

      // Choose the digit value for this column.
      // digit_i = 0 is leftmost, so we use d3..d0 to display thousands..ones.
      var dig: u32 = 0u;
      if (digit_i == 0u) { dig = d3; }
      if (digit_i == 1u) { dig = d2; }
      if (digit_i == 2u) { dig = d1; }
      if (digit_i == 3u) { dig = d0; }

      // If the corresponding font bit is set, paint the pixel white.
      let m = digit_mask(dig);
      if (mask_bit(m, cell_x, cell_y)) {
        rgb = vec3<f32>(1.0, 1.0, 1.0);
      }
    }
  }

  // Opaque output.
  return vec4<f32>(rgb, 1.0);
}

// src/shaders/common.wgsl
// -----------------------
// common.wgsl
//
// Shared WGSL across compute passes.
// - Constants / tuning knobs (ALL constants live here)
// - GPU-side struct defs + scene bindings
// - Shared math + grid helpers + sky/cloud/fog utilities

// ------------------------------------------------------------
// IDs / numeric
// ------------------------------------------------------------

const LEAF_U32 : u32 = 0xFFFFFFFFu; // Sentinel for "leaf node" in child_base.
const INVALID_U32 : u32 = 0xFFFFFFFFu; // Sentinel for invalid grid slot (chunk_grid entry).

const BIG_F32  : f32 = 1e30;
const EPS_INV  : f32 = 1e-8;

// Materials (keeps magic numbers out of core code)
const MAT_AIR   : u32 = 0u;
const MAT_GRASS : u32 = 1u;
const MAT_DIRT  : u32 = 2u;
const MAT_STONE : u32 = 3u;
const MAT_WOOD  : u32 = 4u;
const MAT_LEAF  : u32 = 5u;

// ------------------------------------------------------------
// Sun / sky
// ------------------------------------------------------------

const SUN_DIR : vec3<f32> = vec3<f32>(0.61237244, 0.5, 0.61237244);
const SUN_COLOR     : vec3<f32> = vec3<f32>(1.0, 0.98, 0.90);
const SUN_INTENSITY : f32 = 3.5;

const SUN_DISC_ANGULAR_RADIUS : f32 = 0.009;
const SUN_DISC_SOFTNESS       : f32 = 0.004;

const SKY_EXPOSURE : f32 = 0.40;

// ------------------------------------------------------------
// Shadows
// ------------------------------------------------------------

const SHADOW_BIAS : f32 = 2e-4;

// Shadow traversal tuning
const SHADOW_STEPS : u32 = 32u;

// If false: leaves cast shadows using their undisplaced cube (faster).
// If true : shadows match displaced leaf cubes (slower but consistent).
const SHADOW_DISPLACED_LEAVES : bool = false;

// Volumetric “sun transmittance” tuning (leafy canopy)
const VSM_STEPS : u32 = 24u;
const LEAF_LIGHT_TRANSMIT : f32 = 0.50;
const MIN_TRANS : f32 = 0.03;

// ------------------------------------------------------------
// Fog / volumetrics
// ------------------------------------------------------------

const FOG_HEIGHT_FALLOFF : f32 = 0.18;
const FOG_MAX_DIST       : f32 = 100.0;

const FOG_PRIMARY_SCALE : f32 = 0.02;
const FOG_GODRAY_SCALE  : f32 = 2.0;

const FOG_PRIMARY_VIS   : f32 = 0.08;

const FOG_COLOR_GROUND     : vec3<f32> = vec3<f32>(0.62, 0.64, 0.66);
const FOG_COLOR_SKY_BLEND  : f32 = 0.20;

const GODRAY_MAX_DIST    : f32 = 80.0;
const GODRAY_STRENGTH    : f32 = 4.0;

const GODRAY_OFFAXIS_POW : f32 = 3.0;
const GODRAY_OFFAXIS_W   : f32 = 0.18;

// Godray scattering height behavior (ONLY affects added beam light, not fog density)
const GODRAY_SCATTER_HEIGHT_FALLOFF : f32 = 0.04; // << smaller than FOG_HEIGHT_FALLOFF (0.18)
const GODRAY_SCATTER_MIN_FRAC       : f32 = 0.35; // floor as fraction of sea-level scatter

const GODRAY_SIDE_BOOST : f32 = 0.65; // 0..1
const GODRAY_BLACK_LEVEL : f32 = 0.018; // try 0.010..0.030

const GODRAY_TS_LP_ALPHA   : f32 = 0.50; // 0.2..0.5 (higher = smoother, less noisy)
const GODRAY_EDGE0         : f32 = 0.015;
const GODRAY_EDGE1         : f32 = 0.10;

const GODRAY_BASE_HAZE     : f32 = 0.08; // 0.02..0.10 (tiny DC term)
const GODRAY_HAZE_NEAR_FADE: f32 = 18.0; // meters: haze ramps in with distance


const INV_4PI      : f32 = 0.0795774715;
const PHASE_G      : f32 = 0.10;
const PHASE_MIE_W  : f32 = 0.25;

// ------------------------------------------------------------
// Fractal clouds
// ------------------------------------------------------------

const CLOUD_H : f32 = 200.0;
const CLOUD_UV_SCALE : f32 = 0.002;
const CLOUD_WIND : vec2<f32> = vec2<f32>(0.020, 0.012);

const CLOUD_COVERAGE : f32 = 0.45;
const CLOUD_SOFTNESS : f32 = 0.10;

const CLOUD_HORIZON_Y0 : f32 = 0.02;
const CLOUD_HORIZON_Y1 : f32 = 0.25;

const CLOUD_SKY_DARKEN : f32 = 0.95;
const CLOUD_ABSORB : f32 = 10.0;

const CLOUD_BASE_COL   : vec3<f32> = vec3<f32>(0.72, 0.74, 0.76);
const CLOUD_SILVER_POW : f32 = 8.0;
const CLOUD_SILVER_STR : f32 = 0.6;
const CLOUD_BLEND      : f32 = 0.85;

const CLOUD_DIM_SUN_DISC : bool = true;
const CLOUD_SUN_DISC_ABSORB_SCALE : f32 = 0.8;

// ------------------------------------------------------------
// Leaf wind (displaced cubes)
// ------------------------------------------------------------

const WIND_CELL_FREQ : f32 = 2.5;
const WIND_DIR_XZ : vec2<f32> = vec2<f32>(0.9, 0.4);

const WIND_RAMP_Y0 : f32 = 2.0;
const WIND_RAMP_Y1 : f32 = 14.0;

const WIND_GUST_TIME_FREQ    : f32 = 0.9;
const WIND_FLUTTER_TIME_FREQ : f32 = 4.2;

const WIND_GUST_XZ_FREQ    : vec2<f32> = vec2<f32>(0.35, 0.22);
const WIND_FLUTTER_XZ_FREQ : vec2<f32> = vec2<f32>(1.7,  1.1);

const WIND_GUST_WEIGHT    : f32 = 0.75;
const WIND_FLUTTER_WEIGHT : f32 = 0.25;

const WIND_VERTICAL_SCALE : f32 = 0.25;
const LEAF_VERTICAL_REDUCE : f32 = 0.15;

const LEAF_OFFSET_AMP : f32 = 0.45;
const LEAF_OFFSET_MAX_FRAC : f32 = 0.45;

const WIND_PHASE_OFF_1 : vec3<f32> = vec3<f32>(19.0, 7.0, 11.0);
const TAU : f32 = 6.28318530718;

// ------------------------------------------------------------
// Ray/main pass knobs (moved from ray_main)
// ------------------------------------------------------------

const PRIMARY_NUDGE_VOXEL_FRAC : f32 = 1e-4;

// Godray sampling pattern
const GODRAY_FRAME_FPS : f32 = 60.0;
const GODRAY_BLOCK_SIZE : i32 = 4;
const GODRAY_PATTERN_HASH_SCALE : f32 = 0.73;

const J0_SCALE : f32 = 1.31;
const J1_SCALE : f32 = 2.11;
const J2_SCALE : f32 = 3.01;
const J3_SCALE : f32 = 4.19;

const J0_F : vec2<f32> = vec2<f32>(0.11, 0.17);
const J1_F : vec2<f32> = vec2<f32>(0.23, 0.29);
const J2_F : vec2<f32> = vec2<f32>(0.37, 0.41);
const J3_F : vec2<f32> = vec2<f32>(0.53, 0.59);

const GODRAY_TV_CUTOFF : f32 = 0.02;
const GODRAY_STEPS_FAST : u32 = 8u;

// Composite
const COMPOSITE_SHARPEN : f32 = 0.35;
const COMPOSITE_GOD_SCALE : f32 = 3.0;
const COMPOSITE_BEAM_COMPRESS : bool = true;

// Post
const POST_EXPOSURE : f32 = 1.15;

// ------------------------------------------------------------
// GPU structs (must match Rust layouts)
// ------------------------------------------------------------

struct Node {
  child_base : u32,
  child_mask : u32,
  material   : u32,
  _pad       : u32,
};

struct Camera {
  view_inv    : mat4x4<f32>,
  proj_inv    : mat4x4<f32>,
  cam_pos     : vec4<f32>,

  chunk_size  : u32,
  chunk_count : u32,
  max_steps   : u32,
  _pad0       : u32,

  // x = voxel_size_m, y = time_seconds, z = wind_strength, w = fog_density
  voxel_params : vec4<f32>,

  grid_origin_chunk : vec4<i32>,
  grid_dims         : vec4<u32>,
};

struct ChunkMeta {
  origin     : vec4<i32>,
  node_base  : u32,
  node_count : u32,
  _pad0      : u32,
  _pad1      : u32,
};

// ------------------------------------------------------------
// Scene bindings (group(0))
// ------------------------------------------------------------

@group(0) @binding(0) var<uniform> cam : Camera;
@group(0) @binding(1) var<storage, read> chunks : array<ChunkMeta>;
@group(0) @binding(2) var<storage, read> nodes  : array<Node>;
@group(0) @binding(3) var<storage, read> chunk_grid : array<u32>;

// ------------------------------------------------------------
// Ray reconstruction
// ------------------------------------------------------------

fn ray_dir_from_pixel(px: vec2<f32>, res: vec2<f32>) -> vec3<f32> {
  let ndc = vec4<f32>(
    2.0 * px.x / res.x - 1.0,
    1.0 - 2.0 * px.y / res.y,
    1.0,
    1.0
  );

  let view = cam.proj_inv * ndc;
  let vdir = vec4<f32>(view.xyz / view.w, 0.0);
  let wdir = (cam.view_inv * vdir).xyz;
  return normalize(wdir);
}

// ------------------------------------------------------------
// AABB intersection (slab)
// ------------------------------------------------------------

fn intersect_aabb(ro: vec3<f32>, rd: vec3<f32>, bmin: vec3<f32>, bmax: vec3<f32>) -> vec2<f32> {
  let eps = 1e-8;

  var t_enter = -1e30;
  var t_exit  =  1e30;

  if (abs(rd.x) < eps) {
    if (ro.x < bmin.x || ro.x > bmax.x) { return vec2<f32>(1.0, 0.0); }
  } else {
    let inv = 1.0 / rd.x;
    let t0 = (bmin.x - ro.x) * inv;
    let t1 = (bmax.x - ro.x) * inv;
    t_enter = max(t_enter, min(t0, t1));
    t_exit  = min(t_exit,  max(t0, t1));
  }

  if (abs(rd.y) < eps) {
    if (ro.y < bmin.y || ro.y > bmax.y) { return vec2<f32>(1.0, 0.0); }
  } else {
    let inv = 1.0 / rd.y;
    let t0 = (bmin.y - ro.y) * inv;
    let t1 = (bmax.y - ro.y) * inv;
    t_enter = max(t_enter, min(t0, t1));
    t_exit  = min(t_exit,  max(t0, t1));
  }

  if (abs(rd.z) < eps) {
    if (ro.z < bmin.z || ro.z > bmax.z) { return vec2<f32>(1.0, 0.0); }
  } else {
    let inv = 1.0 / rd.z;
    let t0 = (bmin.z - ro.z) * inv;
    let t1 = (bmax.z - ro.z) * inv;
    t_enter = max(t_enter, min(t0, t1));
    t_exit  = min(t_exit,  max(t0, t1));
  }

  return vec2<f32>(t_enter, t_exit);
}

// ------------------------------------------------------------
// Sparse children addressing (compact child list)
// ------------------------------------------------------------

fn child_rank(mask: u32, ci: u32) -> u32 {
  let bit = 1u << ci;
  let lower = mask & (bit - 1u);
  return countOneBits(lower);
}

// ------------------------------------------------------------
// Chunk-grid helpers (moved from ray_main; used by shadows too)
// ------------------------------------------------------------

fn grid_lookup_slot(cx: i32, cy: i32, cz: i32) -> u32 {
  let ox = cam.grid_origin_chunk.x;
  let oy = cam.grid_origin_chunk.y;
  let oz = cam.grid_origin_chunk.z;

  let ix_i = cx - ox;
  let iy_i = cy - oy;
  let iz_i = cz - oz;

  if (ix_i < 0 || iy_i < 0 || iz_i < 0) { return INVALID_U32; }

  let nx = cam.grid_dims.x;
  let ny = cam.grid_dims.y;
  let nz = cam.grid_dims.z;

  let ix = u32(ix_i);
  let iy = u32(iy_i);
  let iz = u32(iz_i);

  if (ix >= nx || iy >= ny || iz >= nz) { return INVALID_U32; }

  let idx = (iz * ny * nx) + (iy * nx) + ix;
  return chunk_grid[idx];
}

fn chunk_coord_from_pos(p: vec3<f32>, chunk_size_m: f32) -> vec3<i32> {
  return vec3<i32>(
    i32(floor(p.x / chunk_size_m)),
    i32(floor(p.y / chunk_size_m)),
    i32(floor(p.z / chunk_size_m))
  );
}

// ------------------------------------------------------------
// Hash / noise / FBM (clouds)
// ------------------------------------------------------------

fn hash12(p: vec2<f32>) -> f32 {
  let h = dot(p, vec2<f32>(127.1, 311.7));
  return fract(sin(h) * 43758.5453);
}

fn hash21(p: vec2<f32>) -> f32 {
  let h = dot(p, vec2<f32>(127.1, 311.7));
  return fract(sin(h) * 43758.5453);
}

fn value_noise(p: vec2<f32>) -> f32 {
  let i = floor(p);
  let f = fract(p);

  let a = hash21(i);
  let b = hash21(i + vec2<f32>(1.0, 0.0));
  let c = hash21(i + vec2<f32>(0.0, 1.0));
  let d = hash21(i + vec2<f32>(1.0, 1.0));

  let u = f * f * (3.0 - 2.0 * f);

  let x1 = mix(a, b, u.x);
  let x2 = mix(c, d, u.x);
  return mix(x1, x2, u.y);
}

fn fbm(p: vec2<f32>) -> f32 {
  var x = p;
  var sum = 0.0;
  var amp = 0.5;

  let rot = mat2x2<f32>(0.8, -0.6, 0.6, 0.8);

  for (var i: u32 = 0u; i < 5u; i = i + 1u) {
    sum += amp * value_noise(x);
    x = rot * x * 2.0 + vec2<f32>(17.0, 9.0);
    amp *= 0.5;
  }
  return sum;
}

fn cloud_coverage_at_xz(xz: vec2<f32>, time_s: f32) -> f32 {
  var uv = xz * CLOUD_UV_SCALE + CLOUD_WIND * time_s;

  let n  = fbm(uv);
  let n2 = fbm(uv * 2.3 + vec2<f32>(13.2, 7.1));
  let field = 0.65 * n + 0.35 * n2;

  return smoothstep(CLOUD_COVERAGE, CLOUD_COVERAGE + CLOUD_SOFTNESS, field);
}

fn cloud_sun_transmittance(p: vec3<f32>, sun_dir: vec3<f32>) -> f32 {
  if (sun_dir.y <= 0.01) { return 1.0; }

  let t = (CLOUD_H - p.y) / sun_dir.y;
  if (t <= 0.0) { return 1.0; }

  let time_s = cam.voxel_params.y;
  let hit = p + sun_dir * t;
  let cov = cloud_coverage_at_xz(hit.xz, time_s);
  return exp(-CLOUD_ABSORB * cov);
}

// ------------------------------------------------------------
// Phase functions
// ------------------------------------------------------------

fn phase_mie(costh: f32) -> f32 {
  let g = PHASE_G;
  let gg = g * g;
  let denom = pow(1.0 + gg - 2.0 * g * costh, 1.5);
  return (1.0 - gg) / max(denom, 1e-3);
}

fn phase_blended(costh: f32) -> f32 {
  let mie = phase_mie(costh);
  return mix(INV_4PI, mie, PHASE_MIE_W);
}

// ------------------------------------------------------------
// Sky
// ------------------------------------------------------------

fn sky_color(rd: vec3<f32>) -> vec3<f32> {
  let tsky = clamp(0.5 * (rd.y + 1.0), 0.0, 1.0);
  var col = mix(
    vec3<f32>(0.05, 0.08, 0.12),
    vec3<f32>(0.55, 0.75, 0.95),
    tsky
  );

  col *= SKY_EXPOSURE;

  let mu  = dot(rd, SUN_DIR);
  let ang = acos(clamp(mu, -1.0, 1.0));
  let disc = 1.0 - smoothstep(
    SUN_DISC_ANGULAR_RADIUS,
    SUN_DISC_ANGULAR_RADIUS + SUN_DISC_SOFTNESS,
    ang
  );
  let halo = exp(-ang * 30.0) * 0.15;

  var cloud = 0.0;

  if (rd.y > 0.01) {
    let ro = cam.cam_pos.xyz;
    let t = (CLOUD_H - ro.y) / rd.y;

    if (t > 0.0) {
      let hit = ro + rd * t;
      let time_s = cam.voxel_params.y;

      cloud = cloud_coverage_at_xz(hit.xz, time_s);

      let horizon = clamp((rd.y - CLOUD_HORIZON_Y0) / CLOUD_HORIZON_Y1, 0.0, 1.0);
      cloud *= horizon;

      col *= mix(1.0, CLOUD_SKY_DARKEN, cloud);

      let toward_sun = clamp(mu, 0.0, 1.0);
      let silver = pow(toward_sun, CLOUD_SILVER_POW) * CLOUD_SILVER_STR;
      let cloud_col = mix(CLOUD_BASE_COL, vec3<f32>(1.0), silver);

      col = mix(col, cloud_col, cloud * CLOUD_BLEND);
    }
  }

  var sun_term = (disc + halo);
  if (CLOUD_DIM_SUN_DISC) {
    let Tc_view = exp(-CLOUD_ABSORB * cloud * CLOUD_SUN_DISC_ABSORB_SCALE);
    sun_term *= Tc_view;
  }

  col += SUN_COLOR * SUN_INTENSITY * sun_term;
  return col;
}

// Fog color used by primary composition
fn fog_color(rd: vec3<f32>) -> vec3<f32> {
  let up = clamp(rd.y * 0.5 + 0.5, 0.0, 1.0);
  let sky = sky_color(rd);
  return mix(FOG_COLOR_GROUND, sky, FOG_COLOR_SKY_BLEND * up);
}

// ------------------------------------------------------------
// Fog helpers
// ------------------------------------------------------------

fn fog_density_primary() -> f32 {
  return max(cam.voxel_params.w * FOG_PRIMARY_SCALE, 0.0);
}

fn fog_density_godray() -> f32 {
  return max(cam.voxel_params.w * FOG_GODRAY_SCALE, 0.0);
}

fn fog_optical_depth_with_base(base: f32, ro: vec3<f32>, rd: vec3<f32>, t: f32) -> f32 {
  if (base <= 0.0) { return 0.0; }

  let k = FOG_HEIGHT_FALLOFF;
  let y0 = ro.y;
  let dy = rd.y;

  if (abs(dy) < 1e-4) {
    return base * exp(-k * y0) * t;
  }

  let a = exp(-k * y0);
  let b = exp(-k * (y0 + dy * t));
  return base * (a - b) / (k * dy);
}

fn fog_transmittance_primary(ro: vec3<f32>, rd: vec3<f32>, t: f32) -> f32 {
  let od = max(fog_optical_depth_with_base(fog_density_primary(), ro, rd, t), 0.0);
  return exp(-od);
}

fn fog_transmittance_godray(ro: vec3<f32>, rd: vec3<f32>, t: f32) -> f32 {
  let od = max(fog_optical_depth_with_base(fog_density_godray(), ro, rd, t), 0.0);
  return exp(-od);
}

// src/shaders/ray_core.wgsl
// -------------------------
// ray_core.wgsl
//
// Consolidated core:
// - SVO queries + hybrid traversal
// - Leaf wind + displaced hit
// - Shadows + sun transmittance
// - Material palette + shading

// Depends on: common.wgsl (constants, structs, bindings, helpers)

fn safe_inv(x: f32) -> f32 {
  return select(1.0 / x, BIG_F32, abs(x) < EPS_INV);
}

// ------------------------------------------------------------
// Leaf query: point -> leaf cell in SVO
// ------------------------------------------------------------

struct LeafQuery {
  bmin : vec3<f32>,
  size : f32,
  mat  : u32,
};

fn query_leaf_at(
  p_in: vec3<f32>,
  root_bmin: vec3<f32>,
  root_size: f32,
  node_base: u32
) -> LeafQuery {
  var idx: u32 = node_base;
  var bmin: vec3<f32> = root_bmin;
  var size: f32 = root_size;

  let min_leaf: f32 = cam.voxel_params.x;
  var p = p_in;

  for (var d: u32 = 0u; d < 32u; d = d + 1u) {
    let n = nodes[idx];

    if (n.child_base == LEAF_U32) {
      return LeafQuery(bmin, size, n.material);
    }

    if (size <= min_leaf) {
      return LeafQuery(bmin, size, MAT_AIR);
    }

    let half = size * 0.5;
    let mid  = bmin + vec3<f32>(half);

    let e = 1e-6 * size;

    let hx = select(0u, 1u, p.x > mid.x + e);
    let hy = select(0u, 1u, p.y > mid.y + e);
    let hz = select(0u, 1u, p.z > mid.z + e);
    let ci = hx | (hy << 1u) | (hz << 2u);

    let child_bmin = bmin + vec3<f32>(
      select(0.0, half, hx != 0u),
      select(0.0, half, hy != 0u),
      select(0.0, half, hz != 0u)
    );

    let bit = 1u << ci;
    if ((n.child_mask & bit) == 0u) {
      return LeafQuery(child_bmin, half, MAT_AIR);
    }

    let rank = child_rank(n.child_mask, ci);
    idx = node_base + (n.child_base + rank);

    bmin = child_bmin;
    size = half;
  }

  return LeafQuery(bmin, size, MAT_AIR);
}

// ------------------------------------------------------------
// Fast stepping: cube exit time with inv dir
// ------------------------------------------------------------

fn exit_time_from_cube_inv(
  ro: vec3<f32>,
  rd: vec3<f32>,
  inv: vec3<f32>,
  bmin: vec3<f32>,
  size: f32
) -> f32 {
  let bmax = bmin + vec3<f32>(size);

  let tx = (select(bmin.x, bmax.x, rd.x > 0.0) - ro.x) * inv.x;
  let ty = (select(bmin.y, bmax.y, rd.y > 0.0) - ro.y) * inv.y;
  let tz = (select(bmin.z, bmax.z, rd.z > 0.0) - ro.z) * inv.z;

  return min(tx, min(ty, tz));
}

// ------------------------------------------------------------
// AABB hit + stable normal selection
// ------------------------------------------------------------

struct BoxHit {
  hit : bool,
  t   : f32,
  n   : vec3<f32>,
};

fn aabb_hit_normal_inv(
  ro: vec3<f32>,
  rd: vec3<f32>,
  inv: vec3<f32>,
  bmin: vec3<f32>,
  size: f32,
  t_min: f32,
  t_max: f32
) -> BoxHit {
  let bmax = bmin + vec3<f32>(size);

  let tx0 = (bmin.x - ro.x) * inv.x;
  let tx1 = (bmax.x - ro.x) * inv.x;
  let ty0 = (bmin.y - ro.y) * inv.y;
  let ty1 = (bmax.y - ro.y) * inv.y;
  let tz0 = (bmin.z - ro.z) * inv.z;
  let tz1 = (bmax.z - ro.z) * inv.z;

  let tminx = min(tx0, tx1);
  let tmaxx = max(tx0, tx1);
  let tminy = min(ty0, ty1);
  let tmaxy = max(ty0, ty1);
  let tminz = min(tz0, tz1);
  let tmaxz = max(tz0, tz1);

  let t_enter = max(tminx, max(tminy, tminz));
  let t_exit  = min(tmaxx, min(tmaxy, tmaxz));

  let t0 = max(t_enter, t_min);

  if (t_exit < t0 || t0 > t_max) {
    return BoxHit(false, BIG_F32, vec3<f32>(0.0));
  }

  let eps = 1e-6 * size;

  var best_abs = -1.0;
  var pick: u32 = 0u;

  if (abs(t_enter - tminx) <= eps) {
    let a = abs(rd.x);
    if (a > best_abs) { best_abs = a; pick = 0u; }
  }
  if (abs(t_enter - tminy) <= eps) {
    let a = abs(rd.y);
    if (a > best_abs) { best_abs = a; pick = 1u; }
  }
  if (abs(t_enter - tminz) <= eps) {
    let a = abs(rd.z);
    if (a > best_abs) { best_abs = a; pick = 2u; }
  }

  var n = vec3<f32>(0.0);
  if (pick == 0u) { n = vec3<f32>(select( 1.0, -1.0, rd.x > 0.0), 0.0, 0.0); }
  if (pick == 1u) { n = vec3<f32>(0.0, select( 1.0, -1.0, rd.y > 0.0), 0.0); }
  if (pick == 2u) { n = vec3<f32>(0.0, 0.0, select( 1.0, -1.0, rd.z > 0.0)); }

  return BoxHit(true, t0, n);
}

// ------------------------------------------------------------
// Leaf wind field + displaced cube hit
// ------------------------------------------------------------

fn hash1(p: vec3<f32>) -> f32 {
  let h = dot(p, vec3<f32>(127.1, 311.7, 74.7));
  return fract(sin(h) * 43758.5453);
}

fn wind_field(pos_m: vec3<f32>, t: f32) -> vec3<f32> {
  let cell = floor(pos_m * WIND_CELL_FREQ);

  let ph0 = hash1(cell);
  let ph1 = hash1(cell + WIND_PHASE_OFF_1);

  let dir = normalize(WIND_DIR_XZ);

  let h = clamp((pos_m.y - WIND_RAMP_Y0) / max(WIND_RAMP_Y1 - WIND_RAMP_Y0, 1e-3), 0.0, 1.0);

  let gust = sin(
    t * WIND_GUST_TIME_FREQ +
    dot(pos_m.xz, WIND_GUST_XZ_FREQ) +
    ph0 * TAU
  );

  let flutter = sin(
    t * WIND_FLUTTER_TIME_FREQ +
    dot(pos_m.xz, WIND_FLUTTER_XZ_FREQ) +
    ph1 * TAU
  );

  let xz = dir * (WIND_GUST_WEIGHT * gust + WIND_FLUTTER_WEIGHT * flutter) * h;
  let y  = WIND_VERTICAL_SCALE * flutter * h;

  return vec3<f32>(xz.x, y, xz.y);
}

fn clamp_len(v: vec3<f32>, max_len: f32) -> vec3<f32> {
  let l2 = dot(v, v);
  if (l2 <= max_len * max_len) { return v; }
  return v * (max_len / sqrt(l2));
}

fn leaf_cube_offset(bmin: vec3<f32>, size: f32, time_s: f32, strength: f32) -> vec3<f32> {
  let center = bmin + vec3<f32>(0.5 * size);

  var w = wind_field(center, time_s) * strength;
  w = vec3<f32>(w.x, LEAF_VERTICAL_REDUCE * w.y, w.z);

  let amp = LEAF_OFFSET_AMP * size;
  return clamp_len(w * amp, LEAF_OFFSET_MAX_FRAC * size);
}

struct LeafCubeHit {
  hit  : bool,
  t    : f32,
  n    : vec3<f32>,
};

fn leaf_displaced_cube_hit(
  ro: vec3<f32>,
  rd: vec3<f32>,
  bmin: vec3<f32>,
  size: f32,
  time_s: f32,
  strength: f32,
  t_min: f32,
  t_max: f32
) -> LeafCubeHit {
  let off   = leaf_cube_offset(bmin, size, time_s, strength);
  let bmin2 = bmin + off;

  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));
  let bh  = aabb_hit_normal_inv(ro, rd, inv, bmin2, size, t_min, t_max);

  return LeafCubeHit(bh.hit, bh.t, bh.n);
}

// ------------------------------------------------------------
// Chunk tracing: hybrid point-query + interval stepping
// ------------------------------------------------------------

struct HitGeom {
  hit : bool,
  t   : f32,
  mat : u32,
  n   : vec3<f32>,
};

fn trace_chunk_hybrid_interval(
  ro: vec3<f32>,
  rd: vec3<f32>,
  ch: ChunkMeta,
  t_enter: f32,
  t_exit: f32
) -> HitGeom {
  let voxel_size = cam.voxel_params.x;

  let root_bmin_vox = vec3<f32>(f32(ch.origin.x), f32(ch.origin.y), f32(ch.origin.z));
  let root_bmin = root_bmin_vox * voxel_size;
  let root_size = f32(cam.chunk_size) * voxel_size;

  let eps_step = 1e-4 * voxel_size;

  var tcur = max(t_enter, 0.0) + eps_step;

  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));

  for (var step_i: u32 = 0u; step_i < cam.max_steps; step_i = step_i + 1u) {
    if (tcur > t_exit) { break; }

    let p  = ro + tcur * rd;
    let pq = p + rd * (1e-4 * voxel_size);

    let q = query_leaf_at(pq, root_bmin, root_size, ch.node_base);

    if (q.mat != MAT_AIR) {
      if (q.mat == MAT_LEAF) {
        let time_s   = cam.voxel_params.y;
        let strength = cam.voxel_params.z;

        let h2 = leaf_displaced_cube_hit(
          ro, rd,
          q.bmin, q.size,
          time_s, strength,
          t_enter,
          t_exit
        );

        if (h2.hit) {
          return HitGeom(true, h2.t, MAT_LEAF, h2.n);
        }

        let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
        tcur = max(t_leave, tcur) + eps_step;
        continue;
      }

      let bh = aabb_hit_normal_inv(
        ro, rd, inv,
        q.bmin, q.size,
        t_enter,
        t_exit
      );

      if (bh.hit) {
        return HitGeom(true, bh.t, q.mat, bh.n);
      }

      let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
      tcur = max(t_leave, tcur) + eps_step;
      continue;
    }

    let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
    tcur = max(t_leave, tcur) + eps_step;
  }

  return HitGeom(false, BIG_F32, MAT_AIR, vec3<f32>(0.0));
}

// ------------------------------------------------------------
// Shadow traversal
// ------------------------------------------------------------

fn trace_chunk_shadow_interval(
  ro: vec3<f32>,
  rd: vec3<f32>,
  ch: ChunkMeta,
  t_enter: f32,
  t_exit: f32
) -> bool {
  let voxel_size = cam.voxel_params.x;
  let nudge_s = 0.18 * voxel_size;

  let root_bmin_vox = vec3<f32>(f32(ch.origin.x), f32(ch.origin.y), f32(ch.origin.z));
  let root_bmin = root_bmin_vox * voxel_size;
  let root_size = f32(cam.chunk_size) * voxel_size;

  var tcur = max(t_enter, 0.0) + nudge_s;
  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));

  for (var step_i: u32 = 0u; step_i < SHADOW_STEPS; step_i = step_i + 1u) {
    if (tcur > t_exit) { break; }

    let p = ro + tcur * rd;
    let q = query_leaf_at(p, root_bmin, root_size, ch.node_base);

    if (q.mat != MAT_AIR) {
      if (q.mat == MAT_LEAF) {
        if (!SHADOW_DISPLACED_LEAVES) {
          return true;
        }

        let time_s   = cam.voxel_params.y;
        let strength = cam.voxel_params.z;

        let h2 = leaf_displaced_cube_hit(
          ro, rd,
          q.bmin, q.size,
          time_s, strength,
          tcur - nudge_s,
          t_exit
        );

        if (h2.hit) { return true; }

        let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
        tcur = max(t_leave, tcur) + nudge_s;
        continue;
      }

      return true;
    }

    let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
    tcur = max(t_leave, tcur) + nudge_s;
  }

  return false;
}

fn in_shadow(p: vec3<f32>, sun_dir: vec3<f32>) -> bool {
  let voxel_size   = cam.voxel_params.x;
  let nudge_s      = 0.18 * voxel_size;
  let chunk_size_m = f32(cam.chunk_size) * voxel_size;

  let go = cam.grid_origin_chunk;
  let gd = cam.grid_dims;

  let grid_bmin = vec3<f32>(
    f32(go.x) * chunk_size_m,
    f32(go.y) * chunk_size_m,
    f32(go.z) * chunk_size_m
  );

  let grid_bmax = grid_bmin + vec3<f32>(
    f32(gd.x) * chunk_size_m,
    f32(gd.y) * chunk_size_m,
    f32(gd.z) * chunk_size_m
  );

  let bias = max(SHADOW_BIAS, 0.50 * voxel_size);
  let ro   = p + sun_dir * bias;
  let rd   = sun_dir;

  let rtg = intersect_aabb(ro, rd, grid_bmin, grid_bmax);
  let t_enter = max(rtg.x, 0.0);
  let t_exit  = rtg.y;
  if (t_exit < t_enter) { return false; }

  let start_t = t_enter + nudge_s;
  let p0 = ro + start_t * rd;

  var t_local: f32 = 0.0;
  let t_exit_local = max(t_exit - start_t, 0.0);

  var c = chunk_coord_from_pos(p0, chunk_size_m);
  var cx: i32 = c.x;
  var cy: i32 = c.y;
  var cz: i32 = c.z;

  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));

  let step_x: i32 = select(-1, 1, rd.x > 0.0);
  let step_y: i32 = select(-1, 1, rd.y > 0.0);
  let step_z: i32 = select(-1, 1, rd.z > 0.0);

  let bx = select(f32(cx) * chunk_size_m, f32(cx + 1) * chunk_size_m, rd.x > 0.0);
  let by = select(f32(cy) * chunk_size_m, f32(cy + 1) * chunk_size_m, rd.y > 0.0);
  let bz = select(f32(cz) * chunk_size_m, f32(cz + 1) * chunk_size_m, rd.z > 0.0);

  var tMaxX: f32 = (bx - p0.x) * inv.x;
  var tMaxY: f32 = (by - p0.y) * inv.y;
  var tMaxZ: f32 = (bz - p0.z) * inv.z;

  let tDeltaX: f32 = abs(chunk_size_m * inv.x);
  let tDeltaY: f32 = abs(chunk_size_m * inv.y);
  let tDeltaZ: f32 = abs(chunk_size_m * inv.z);

  if (abs(rd.x) < EPS_INV) { tMaxX = BIG_F32; }
  if (abs(rd.y) < EPS_INV) { tMaxY = BIG_F32; }
  if (abs(rd.z) < EPS_INV) { tMaxZ = BIG_F32; }

  let max_chunk_steps = min((gd.x + gd.y + gd.z) * 6u + 8u, 1024u);

  for (var s: u32 = 0u; s < max_chunk_steps; s = s + 1u) {
    if (t_local > t_exit_local) { break; }

    let tNextLocal = min(tMaxX, min(tMaxY, tMaxZ));

    let slot = grid_lookup_slot(cx, cy, cz);
    if (slot != INVALID_U32 && slot < cam.chunk_count) {
      let ch = chunks[slot];

      let cell_enter = start_t + t_local;
      let cell_exit  = start_t + min(tNextLocal, t_exit_local);

      if (trace_chunk_shadow_interval(ro, rd, ch, cell_enter, cell_exit)) {
        return true;
      }
    }

    if (tMaxX < tMaxY) {
      if (tMaxX < tMaxZ) { cx += step_x; t_local = tMaxX; tMaxX += tDeltaX; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    } else {
      if (tMaxY < tMaxZ) { cy += step_y; t_local = tMaxY; tMaxY += tDeltaY; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    }

    let ox = cam.grid_origin_chunk.x;
    let oy = cam.grid_origin_chunk.y;
    let oz = cam.grid_origin_chunk.z;

    let nx = i32(cam.grid_dims.x);
    let ny = i32(cam.grid_dims.y);
    let nz = i32(cam.grid_dims.z);

    if (cx < ox || cy < oy || cz < oz || cx >= ox + nx || cy >= oy + ny || cz >= oz + nz) {
      break;
    }
  }

  return false;
}

fn trace_chunk_shadow_trans_interval(
  ro: vec3<f32>,
  rd: vec3<f32>,
  ch: ChunkMeta,
  t_enter: f32,
  t_exit: f32
) -> f32 {
  let voxel_size = cam.voxel_params.x;
  let nudge_s = 0.18 * voxel_size;

  let root_bmin_vox = vec3<f32>(f32(ch.origin.x), f32(ch.origin.y), f32(ch.origin.z));
  let root_bmin = root_bmin_vox * voxel_size;
  let root_size = f32(cam.chunk_size) * voxel_size;

  var tcur = max(t_enter, 0.0) + nudge_s;
  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));

  var trans = 1.0;

  for (var step_i: u32 = 0u; step_i < VSM_STEPS; step_i = step_i + 1u) {
    if (tcur > t_exit) { break; }
    if (trans < MIN_TRANS) { break; }

    let p = ro + tcur * rd;
    let qeps = 1e-4 * cam.voxel_params.x;
    let pq   = p + rd * qeps;

    let q = query_leaf_at(pq, root_bmin, root_size, ch.node_base);

    if (q.mat != MAT_AIR) {
      if (q.mat == MAT_LEAF) {
        trans *= LEAF_LIGHT_TRANSMIT;
        let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
        tcur = max(t_leave, tcur) + nudge_s;
        continue;
      }
      return 0.0;
    }

    let t_leave = exit_time_from_cube_inv(ro, rd, inv, q.bmin, q.size);
    tcur = max(t_leave, tcur) + nudge_s;
  }

  return trans;
}

fn sun_transmittance(p: vec3<f32>, sun_dir: vec3<f32>) -> f32 {
  let Tc = cloud_sun_transmittance(p, sun_dir);

  let voxel_size   = cam.voxel_params.x;
  let nudge_s      = 0.18 * voxel_size;
  let chunk_size_m = f32(cam.chunk_size) * voxel_size;

  let go = cam.grid_origin_chunk;
  let gd = cam.grid_dims;

  let grid_bmin = vec3<f32>(
    f32(go.x) * chunk_size_m,
    f32(go.y) * chunk_size_m,
    f32(go.z) * chunk_size_m
  );

  let grid_bmax = grid_bmin + vec3<f32>(
    f32(gd.x) * chunk_size_m,
    f32(gd.y) * chunk_size_m,
    f32(gd.z) * chunk_size_m
  );

  let bias = max(SHADOW_BIAS, 0.50 * voxel_size);
  let ro   = p + sun_dir * bias;
  let rd   = sun_dir;

  let rtg = intersect_aabb(ro, rd, grid_bmin, grid_bmax);
  let t_enter = max(rtg.x, 0.0);
  let t_exit  = rtg.y;
  if (t_exit < t_enter) { return Tc; }

  let start_t = t_enter + nudge_s;
  let p0 = ro + start_t * rd;

  var t_local: f32 = 0.0;
  let t_exit_local = max(t_exit - start_t, 0.0);

  var c = chunk_coord_from_pos(p0, chunk_size_m);
  var cx: i32 = c.x;
  var cy: i32 = c.y;
  var cz: i32 = c.z;

  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));

  let step_x: i32 = select(-1, 1, rd.x > 0.0);
  let step_y: i32 = select(-1, 1, rd.y > 0.0);
  let step_z: i32 = select(-1, 1, rd.z > 0.0);

  let bx = select(f32(cx) * chunk_size_m, f32(cx + 1) * chunk_size_m, rd.x > 0.0);
  let by = select(f32(cy) * chunk_size_m, f32(cy + 1) * chunk_size_m, rd.y > 0.0);
  let bz = select(f32(cz) * chunk_size_m, f32(cz + 1) * chunk_size_m, rd.z > 0.0);

  var tMaxX: f32 = (bx - p0.x) * inv.x;
  var tMaxY: f32 = (by - p0.y) * inv.y;
  var tMaxZ: f32 = (bz - p0.z) * inv.z;

  let tDeltaX: f32 = abs(chunk_size_m * inv.x);
  let tDeltaY: f32 = abs(chunk_size_m * inv.y);
  let tDeltaZ: f32 = abs(chunk_size_m * inv.z);

  if (abs(rd.x) < EPS_INV) { tMaxX = BIG_F32; }
  if (abs(rd.y) < EPS_INV) { tMaxY = BIG_F32; }
  if (abs(rd.z) < EPS_INV) { tMaxZ = BIG_F32; }

  var trans = 1.0;

  let max_chunk_steps = min((gd.x + gd.y + gd.z) * 6u + 8u, 512u);

  for (var s: u32 = 0u; s < max_chunk_steps; s = s + 1u) {
    if (t_local > t_exit_local) { break; }
    if (trans < MIN_TRANS) { break; }

    let tNextLocal = min(tMaxX, min(tMaxY, tMaxZ));
    let slot = grid_lookup_slot(cx, cy, cz);

    if (slot != INVALID_U32 && slot < cam.chunk_count) {
      let ch = chunks[slot];

      let cell_enter = start_t + t_local;
      let cell_exit  = start_t + min(tNextLocal, t_exit_local);

      trans *= trace_chunk_shadow_trans_interval(ro, rd, ch, cell_enter, cell_exit);
      if (trans < MIN_TRANS) { break; }
    }

    if (tMaxX < tMaxY) {
      if (tMaxX < tMaxZ) { cx += step_x; t_local = tMaxX; tMaxX += tDeltaX; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    } else {
      if (tMaxY < tMaxZ) { cy += step_y; t_local = tMaxY; tMaxY += tDeltaY; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    }

    let ox = cam.grid_origin_chunk.x;
    let oy = cam.grid_origin_chunk.y;
    let oz = cam.grid_origin_chunk.z;

    let nx = i32(cam.grid_dims.x);
    let ny = i32(cam.grid_dims.y);
    let nz = i32(cam.grid_dims.z);

    if (cx < ox || cy < oy || cz < oz || cx >= ox + nx || cy >= oy + ny || cz >= oz + nz) {
      break;
    }
  }

  return trans * Tc;
}

// ------------------------------------------------------------
// Shading
// ------------------------------------------------------------

fn color_for_material(m: u32) -> vec3<f32> {
  if (m == MAT_AIR)   { return vec3<f32>(0.0); }

  if (m == MAT_GRASS) { return vec3<f32>(0.18, 0.75, 0.18); }
  if (m == MAT_DIRT)  { return vec3<f32>(0.45, 0.30, 0.15); }
  if (m == MAT_STONE) { return vec3<f32>(0.50, 0.50, 0.55); }
  if (m == MAT_WOOD)  { return vec3<f32>(0.38, 0.26, 0.14); }
  if (m == MAT_LEAF)  { return vec3<f32>(0.10, 0.55, 0.12); }

  return vec3<f32>(1.0, 0.0, 1.0);
}

fn shade_hit(ro: vec3<f32>, rd: vec3<f32>, hg: HitGeom) -> vec3<f32> {
  let hp = ro + hg.t * rd;
  let base = color_for_material(hg.mat);

  let voxel_size = cam.voxel_params.x;
  let hp_shadow  = hp + hg.n * (0.75 * voxel_size);

  let shadow = select(1.0, 0.0, in_shadow(hp_shadow, SUN_DIR));
  let cloud = cloud_sun_transmittance(hp_shadow, SUN_DIR);

  let diff = max(dot(hg.n, SUN_DIR), 0.0);

  let ambient = select(0.22, 0.28, hg.mat == MAT_LEAF);

  var dapple = 1.0;
  if (hg.mat == MAT_LEAF) {
    let time_s = cam.voxel_params.y;
    let d0 = sin(dot(hp.xz, vec2<f32>(3.0, 2.2)) + time_s * 3.5);
    let d1 = sin(dot(hp.xz, vec2<f32>(6.5, 4.1)) - time_s * 6.0);
    dapple = 0.90 + 0.10 * (0.6 * d0 + 0.4 * d1);
  }

  let direct = SUN_COLOR * SUN_INTENSITY * diff * shadow * cloud;
  return base * (ambient + (1.0 - ambient) * direct) * dapple;
}

// src/shaders/ray_main.wgsl
// -------------------------
// ray_main.wgsl
//
// Compute entrypoints only.
// Depends on: common.wgsl + ray_core.wgsl

@group(0) @binding(4) var color_img : texture_storage_2d<rgba16float, write>;
@group(0) @binding(5) var depth_img : texture_storage_2d<r32float, write>;

@group(1) @binding(0) var depth_tex       : texture_2d<f32>;
@group(1) @binding(1) var godray_hist_tex : texture_2d<f32>;
@group(1) @binding(2) var godray_out      : texture_storage_2d<rgba16float, write>;

@group(2) @binding(0) var color_tex  : texture_2d<f32>;
@group(2) @binding(1) var godray_tex : texture_2d<f32>;
@group(2) @binding(2) var out_img    : texture_storage_2d<rgba16float, write>;

fn tonemap_exp(hdr: vec3<f32>) -> vec3<f32> {
  return vec3<f32>(1.0) - exp(-hdr * POST_EXPOSURE);
}

// Quarter-res upsample (manual bilerp)
fn godray_sample_bilerp(px_full: vec2<f32>) -> vec3<f32> {
  let q = px_full * 0.25;
  let q0 = vec2<i32>(i32(floor(q.x)), i32(floor(q.y)));
  let f  = fract(q);

  let qdims = textureDimensions(godray_tex);
  let x0 = clamp(q0.x, 0, i32(qdims.x) - 1);
  let y0 = clamp(q0.y, 0, i32(qdims.y) - 1);
  let x1 = min(x0 + 1, i32(qdims.x) - 1);
  let y1 = min(y0 + 1, i32(qdims.y) - 1);

  let c00 = textureLoad(godray_tex, vec2<i32>(x0, y0), 0).xyz;
  let c10 = textureLoad(godray_tex, vec2<i32>(x1, y0), 0).xyz;
  let c01 = textureLoad(godray_tex, vec2<i32>(x0, y1), 0).xyz;
  let c11 = textureLoad(godray_tex, vec2<i32>(x1, y1), 0).xyz;

  let cx0 = mix(c00, c10, f.x);
  let cx1 = mix(c01, c11, f.x);
  return mix(cx0, cx1, f.y);
}

fn godray_integrate(ro: vec3<f32>, rd: vec3<f32>, t_end: f32, j: f32) -> vec3<f32> {
  let base = fog_density_godray();
  if (base <= 0.0 || t_end <= 0.0) { return vec3<f32>(0.0); }

  let costh = dot(rd, SUN_DIR);
  let phase = phase_blended(costh);

  let dt = t_end / f32(GODRAY_STEPS_FAST);

  var sum = vec3<f32>(0.0);

  // Stronger stabilization to kill shimmer:
  // - LP Ts (sun visibility)
  // - LP shaft weight itself
  var ts_lp: f32    = 1.0;
  var shaft_lp: f32 = 0.0;

  // Make smoothing scale with step length so it behaves consistently as t_end changes.
  let a_ts    = 1.0 - exp(-dt * 3.0);  // Ts smoothing
  let a_shaft = 1.0 - exp(-dt * 5.0);  // shaft smoothing

  for (var i: u32 = 0u; i < GODRAY_STEPS_FAST; i = i + 1u) {
    let ti = (f32(i) + 0.5 + j) * dt;
    if (ti <= 0.0) { continue; }

    let p = ro + rd * ti;

    let Tv = fog_transmittance_godray(ro, rd, ti);
    if (Tv < GODRAY_TV_CUTOFF) { break; }

    // Sun visibility (occluders + clouds).
    let Ts0 = sun_transmittance(p, SUN_DIR);

    // Soften hard leaf cutouts a bit (helps “go through leaves” look).
    // < 1.0 makes dimmer-but-present transmission survive.
    let Ts_soft = pow(clamp(Ts0, 0.0, 1.0), 0.75);

    // LP Ts heavily to remove per-frame sparkle from undersampling/jitter.
    let ts_prev = ts_lp;
    ts_lp = mix(ts_lp, Ts_soft, a_ts);

    // Edge energy from *stabilized* Ts change (this is where shafts come from).
    // Using ts_prev avoids “derivative of already-updated state” weirdness.
    let dTs = abs(Ts_soft - ts_prev);

    // Convert edge energy into a soft mask, then LP that too.
    var shaft = smoothstep(GODRAY_EDGE0, GODRAY_EDGE1, dTs);
    shaft = sqrt(shaft); // widen/soften
    shaft_lp = mix(shaft_lp, shaft, a_shaft);
    shaft = shaft_lp;

    // Small baseline haze so it stays volumetric (but doesn’t milk out the scene).
    let haze_ramp = 1.0 - exp(-ti / GODRAY_HAZE_NEAR_FADE);
    let haze = GODRAY_BASE_HAZE * haze_ramp;

    // Prevent shafts from looking “painted on” in fully-dark regions:
    // tie shaft contribution to how much sun is actually present.
    let shaft_sun_gate = smoothstep(0.10, 0.55, ts_lp);

    let w = haze + (1.0 - haze) * (shaft * shaft_sun_gate);

    // Godray scatter density with its own height behavior.
    let hfall = GODRAY_SCATTER_HEIGHT_FALLOFF;
    let hmin  = GODRAY_SCATTER_MIN_FRAC;
    let height_term = max(exp(-hfall * p.y), hmin);

    let dens = base * height_term;

    // Slight strength reduction here (so you don't have to rebalance everything else).
    let strength_scale = 0.70;

    sum += (SUN_COLOR * SUN_INTENSITY) * (dens * dt) * Tv * ts_lp * phase * w * strength_scale;
  }

  return sum * GODRAY_STRENGTH;
}


@compute @workgroup_size(8, 8, 1)
fn main_primary(@builtin(global_invocation_id) gid: vec3<u32>) {
  let dims = textureDimensions(color_img);
  if (gid.x >= dims.x || gid.y >= dims.y) { return; }

  let res = vec2<f32>(f32(dims.x), f32(dims.y));
  let px  = vec2<f32>(f32(gid.x) + 0.5, f32(gid.y) + 0.5);

  let ro = cam.cam_pos.xyz;
  let rd = ray_dir_from_pixel(px, res);

  let sky = sky_color(rd);

  let voxel_size = cam.voxel_params.x;
  let nudge_p = PRIMARY_NUDGE_VOXEL_FRAC * voxel_size;

  if (cam.chunk_count == 0u) {
    let ip = vec2<i32>(i32(gid.x), i32(gid.y));
    textureStore(color_img, ip, vec4<f32>(sky, 1.0));
    textureStore(depth_img, ip, vec4<f32>(FOG_MAX_DIST, 0.0, 0.0, 0.0));
    return;
  }

  let chunk_size_m = f32(cam.chunk_size) * voxel_size;

  let go = cam.grid_origin_chunk;
  let gd = cam.grid_dims;

  let grid_bmin = vec3<f32>(
    f32(go.x) * chunk_size_m,
    f32(go.y) * chunk_size_m,
    f32(go.z) * chunk_size_m
  );

  let grid_bmax = grid_bmin + vec3<f32>(
    f32(gd.x) * chunk_size_m,
    f32(gd.y) * chunk_size_m,
    f32(gd.z) * chunk_size_m
  );

  let rtg = intersect_aabb(ro, rd, grid_bmin, grid_bmax);
  var t_enter = max(rtg.x, 0.0);
  let t_exit  = rtg.y;

  if (t_exit < t_enter) {
    let ip = vec2<i32>(i32(gid.x), i32(gid.y));
    textureStore(color_img, ip, vec4<f32>(sky, 1.0));
    textureStore(depth_img, ip, vec4<f32>(FOG_MAX_DIST, 0.0, 0.0, 0.0));
    return;
  }

  let start_t = t_enter + nudge_p;
  let p0 = ro + start_t * rd;

  var c = chunk_coord_from_pos(p0, chunk_size_m);
  var cx: i32 = c.x;
  var cy: i32 = c.y;
  var cz: i32 = c.z;

  var t_local: f32 = 0.0;

  let inv = vec3<f32>(safe_inv(rd.x), safe_inv(rd.y), safe_inv(rd.z));
  let step_x: i32 = select(-1, 1, rd.x > 0.0);
  let step_y: i32 = select(-1, 1, rd.y > 0.0);
  let step_z: i32 = select(-1, 1, rd.z > 0.0);

  let bx = select(f32(cx) * chunk_size_m, f32(cx + 1) * chunk_size_m, rd.x > 0.0);
  let by = select(f32(cy) * chunk_size_m, f32(cy + 1) * chunk_size_m, rd.y > 0.0);
  let bz = select(f32(cz) * chunk_size_m, f32(cz + 1) * chunk_size_m, rd.z > 0.0);

  var tMaxX: f32 = (bx - p0.x) * inv.x;
  var tMaxY: f32 = (by - p0.y) * inv.y;
  var tMaxZ: f32 = (bz - p0.z) * inv.z;

  let tDeltaX: f32 = abs(chunk_size_m * inv.x);
  let tDeltaY: f32 = abs(chunk_size_m * inv.y);
  let tDeltaZ: f32 = abs(chunk_size_m * inv.z);

  if (abs(rd.x) < EPS_INV) { tMaxX = BIG_F32; }
  if (abs(rd.y) < EPS_INV) { tMaxY = BIG_F32; }
  if (abs(rd.z) < EPS_INV) { tMaxZ = BIG_F32; }

  var best = HitGeom(false, BIG_F32, MAT_AIR, vec3<f32>(0.0));
  let t_exit_local = max(t_exit - start_t, 0.0);

  let max_chunk_steps = min((gd.x + gd.y + gd.z) * 6u + 8u, 1024u);

  for (var s: u32 = 0u; s < max_chunk_steps; s = s + 1u) {
    if (t_local > t_exit_local) { break; }

    let tNextLocal = min(tMaxX, min(tMaxY, tMaxZ));
    if (best.hit && (start_t + tNextLocal) >= best.t) { break; }

    let slot = grid_lookup_slot(cx, cy, cz);
    if (slot != INVALID_U32 && slot < cam.chunk_count) {
      let ch = chunks[slot];

      let cell_enter = start_t + t_local;
      let cell_exit  = start_t + min(tNextLocal, t_exit_local);

      let h = trace_chunk_hybrid_interval(ro, rd, ch, cell_enter, cell_exit);
      if (h.hit && h.t < best.t) { best = h; }
    }

    if (tMaxX < tMaxY) {
      if (tMaxX < tMaxZ) { cx += step_x; t_local = tMaxX; tMaxX += tDeltaX; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    } else {
      if (tMaxY < tMaxZ) { cy += step_y; t_local = tMaxY; tMaxY += tDeltaY; }
      else               { cz += step_z; t_local = tMaxZ; tMaxZ += tDeltaZ; }
    }

    let ox = cam.grid_origin_chunk.x;
    let oy = cam.grid_origin_chunk.y;
    let oz = cam.grid_origin_chunk.z;
    let nx = i32(cam.grid_dims.x);
    let ny = i32(cam.grid_dims.y);
    let nz = i32(cam.grid_dims.z);
    if (cx < ox || cy < oy || cz < oz || cx >= ox + nx || cy >= oy + ny || cz >= oz + nz) { break; }
  }

  let surface = select(sky, shade_hit(ro, rd, best), best.hit);
  let t_scene = select(min(t_exit, FOG_MAX_DIST), min(best.t, FOG_MAX_DIST), best.hit);

  let T = fog_transmittance_primary(ro, rd, t_scene);
  let fogc = fog_color(rd);

  let fog_amt = (1.0 - T) * FOG_PRIMARY_VIS;
  let col = mix(surface, fogc, fog_amt);

  let ip = vec2<i32>(i32(gid.x), i32(gid.y));
  textureStore(color_img, ip, vec4<f32>(col, 1.0));
  textureStore(depth_img, ip, vec4<f32>(t_scene, 0.0, 0.0, 0.0));
}

@compute @workgroup_size(8, 8, 1)
fn main_godray(@builtin(global_invocation_id) gid: vec3<u32>) {
  let qdims = textureDimensions(godray_out);
  if (gid.x >= qdims.x || gid.y >= qdims.y) { return; }

  let fdims = textureDimensions(depth_tex);
  let ro = cam.cam_pos.xyz;

  // quarter-res pixel
  let hip  = vec2<i32>(i32(gid.x), i32(gid.y));
  let qpx  = vec2<f32>(f32(gid.x), f32(gid.y));

  // frame-stable-ish pattern selector
  let frame = floor(cam.voxel_params.y * GODRAY_FRAME_FPS);
  let flip = select(
    0.0, 1.0,
    hash12(qpx * GODRAY_PATTERN_HASH_SCALE + vec2<f32>(frame, frame * 0.21)) > 0.5
  );

  // map quarter-res pixel -> a 4x4 block in full-res
  let base_x = i32(gid.x) * GODRAY_BLOCK_SIZE;
  let base_y = i32(gid.y) * GODRAY_BLOCK_SIZE;

  // 4 taps in the block (your existing pattern)
  let ax0 = select(1, 2, flip > 0.5);
  let ay0 = 1;
  let ax1 = select(3, 1, flip > 0.5);
  let ay1 = select(1, 2, flip > 0.5);
  let ax2 = select(1, 3, flip > 0.5);
  let ay2 = select(3, 2, flip > 0.5);
  let ax3 = select(3, 2, flip > 0.5);
  let ay3 = 3;

  let fp0 = vec2<i32>(clamp(base_x + ax0, 0, i32(fdims.x) - 1),
                      clamp(base_y + ay0, 0, i32(fdims.y) - 1));
  let fp1 = vec2<i32>(clamp(base_x + ax1, 0, i32(fdims.x) - 1),
                      clamp(base_y + ay1, 0, i32(fdims.y) - 1));
  let fp2 = vec2<i32>(clamp(base_x + ax2, 0, i32(fdims.x) - 1),
                      clamp(base_y + ay2, 0, i32(fdims.y) - 1));
  let fp3 = vec2<i32>(clamp(base_x + ax3, 0, i32(fdims.x) - 1),
                      clamp(base_y + ay3, 0, i32(fdims.y) - 1));

  let res_full = vec2<f32>(f32(fdims.x), f32(fdims.y));

  // per-tap jitter
  let j0 = (hash12(qpx * J0_SCALE + vec2<f32>(frame * J0_F.x, frame * J0_F.y)) - 0.5);
  let j1 = (hash12(qpx * J1_SCALE + vec2<f32>(frame * J1_F.x, frame * J1_F.y)) - 0.5);
  let j2 = (hash12(qpx * J2_SCALE + vec2<f32>(frame * J2_F.x, frame * J2_F.y)) - 0.5);
  let j3 = (hash12(qpx * J3_SCALE + vec2<f32>(frame * J3_F.x, frame * J3_F.y)) - 0.5);

  // read depth for each tap (also used for a cheap "edge/disocclusion" heuristic)
  let t_scene0 = textureLoad(depth_tex, fp0, 0).x;
  let t_scene1 = textureLoad(depth_tex, fp1, 0).x;
  let t_scene2 = textureLoad(depth_tex, fp2, 0).x;
  let t_scene3 = textureLoad(depth_tex, fp3, 0).x;

  // integrate godrays for the taps
  var acc = vec3<f32>(0.0);
  var wsum = 0.0;

  let t_end0 = min(t_scene0, GODRAY_MAX_DIST);
  if (t_end0 > 0.0 && fog_density_godray() > 0.0) {
    let px0 = vec2<f32>(f32(fp0.x) + 0.5, f32(fp0.y) + 0.5);
    acc += godray_integrate(ro, ray_dir_from_pixel(px0, res_full), t_end0, j0);
    wsum += 1.0;
  }

  let t_end1 = min(t_scene1, GODRAY_MAX_DIST);
  if (t_end1 > 0.0 && fog_density_godray() > 0.0) {
    let px1 = vec2<f32>(f32(fp1.x) + 0.5, f32(fp1.y) + 0.5);
    acc += godray_integrate(ro, ray_dir_from_pixel(px1, res_full), t_end1, j1);
    wsum += 1.0;
  }

  let t_end2 = min(t_scene2, GODRAY_MAX_DIST);
  if (t_end2 > 0.0 && fog_density_godray() > 0.0) {
    let px2 = vec2<f32>(f32(fp2.x) + 0.5, f32(fp2.y) + 0.5);
    acc += godray_integrate(ro, ray_dir_from_pixel(px2, res_full), t_end2, j2);
    wsum += 1.0;
  }

  let t_end3 = min(t_scene3, GODRAY_MAX_DIST);
  if (t_end3 > 0.0 && fog_density_godray() > 0.0) {
    let px3 = vec2<f32>(f32(fp3.x) + 0.5, f32(fp3.y) + 0.5);
    acc += godray_integrate(ro, ray_dir_from_pixel(px3, res_full), t_end3, j3);
    wsum += 1.0;
  }

  let cur = max(select(vec3<f32>(0.0), acc / wsum, wsum > 0.0), vec3<f32>(0.0));

  // -------------------------------
  // Temporal resolve (reduced ghosting)
  // -------------------------------

  // history (quarter-res)
  let hist = textureLoad(godray_hist_tex, hip, 0).xyz;

  // (A) depth-edge heuristic inside this quarter-res block:
  // large depth span => likely edge/disocclusion => reduce history
  let dmin = min(min(t_scene0, t_scene1), min(t_scene2, t_scene3));
  let dmax = max(max(t_scene0, t_scene1), max(t_scene2, t_scene3));
  let span = (dmax - dmin) / max(dmin, 1e-3);
  let edge = smoothstep(0.03, 0.15, span); // tune

  // (B) reactive heuristic: large change in godray energy => reduce history
  let delta = length(cur - hist);
  let react = smoothstep(0.03, 0.18, delta); // tune

  // stable = 1 when safe to accumulate, 0 when we should mostly trust current
  let stable = 1.0 - max(edge, react);

  // clamp history near current to prevent trails / overshoot
  let clamp_w = max(cur * 0.75, vec3<f32>(0.02)); // tune (bigger = less ghosting, more flicker)
  let hist_clamped = clamp(hist, cur - clamp_w, cur + clamp_w);

  // history weight (how much of hist_clamped survives)
  // GODRAY_TS_LP_ALPHA is your knob: higher = smoother but more ghost risk.
  let hist_w = clamp(GODRAY_TS_LP_ALPHA * stable, 0.0, 0.90);

  // final
  let blended = mix(cur, hist_clamped, hist_w);

  textureStore(godray_out, hip, vec4<f32>(blended, 1.0));
}


@compute @workgroup_size(8, 8, 1)
fn main_composite(@builtin(global_invocation_id) gid: vec3<u32>) {
  let dims = textureDimensions(out_img);
  if (gid.x >= dims.x || gid.y >= dims.y) { return; }

  let ip = vec2<i32>(i32(gid.x), i32(gid.y));
  let base = textureLoad(color_tex, ip, 0).xyz;

  let px = vec2<f32>(f32(gid.x) + 0.5, f32(gid.y) + 0.5);

  let g = godray_sample_bilerp(px);

  let gx = godray_sample_bilerp(px + vec2<f32>( 1.0, 0.0)) + godray_sample_bilerp(px + vec2<f32>(-1.0, 0.0));
  let gy = godray_sample_bilerp(px + vec2<f32>(0.0,  1.0)) + godray_sample_bilerp(px + vec2<f32>(0.0, -1.0));
  let blur = 0.25 * (gx + gy);

  var god_raw = max(g + COMPOSITE_SHARPEN * (g - blur), vec3<f32>(0.0));

  // remove baseline haze (keeps only “excess” beam energy)
  god_raw = max(god_raw - vec3<f32>(GODRAY_BLACK_LEVEL), vec3<f32>(0.0));

  let god = (vec3<f32>(1.0) - exp(-god_raw));

  let hdr = max(base + COMPOSITE_GOD_SCALE * god, vec3<f32>(0.0));
  let ldr = tonemap_exp(hdr);

  textureStore(out_img, ip, vec4<f32>(ldr, 1.0));
}

// src/streaming/manager.rs
// ------------------------
// src/streaming/manager.rs
// ------------------------
// Chunk streaming + background SVO building + CPU cache.
//
// New behavior:
// - Chunks are built once, then stored in a CPU cache (budgeted, LRU-ish).
// - When chunks come back into range, we "promote" from cache: allocate GPU node arena
//   range + upload nodes/meta, without rebuilding on worker threads.

use std::collections::{HashMap, HashSet, VecDeque};
use std::mem::size_of;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};

use crossbeam_channel::{unbounded, Receiver, Sender};
use glam::{Vec2, Vec3};

use crate::{
    config,
    render::gpu_types::{ChunkMetaGpu, NodeGpu},
    svo::{build_chunk_svo_sparse_cancelable_with_scratch, BuildScratch},
    world::WorldGen,
};

use super::NodeArena;

const INVALID_U32: u32 = 0xFFFF_FFFF;

// Vertical band dy in [-1..=2]
const GRID_Y_MIN_DY: i32 = -1;
const GRID_Y_COUNT: u32 = 4;

// How many eviction attempts to make when we can't fit a chunk's nodes contiguously.
const EVICT_ATTEMPTS: usize = 8;

#[derive(Clone, Copy, Hash, PartialEq, Eq, Debug)]
struct ChunkKey {
    x: i32,
    y: i32,
    z: i32,
}

enum ChunkState {
    Missing,
    Queued,
    Building,
    Resident(Resident),
}

#[derive(Clone, Copy, Debug)]
struct Resident {
    slot: u32,      // index into chunk_meta (dense)
    node_base: u32, // base index into global node arena
    node_count: u32,
}

#[derive(Clone, Debug)]
struct BuildJob {
    key: ChunkKey,
    cancel: Arc<AtomicBool>,
}

struct BuildDone {
    key: ChunkKey,
    cancel: Arc<AtomicBool>,
    canceled: bool,
    nodes: Vec<NodeGpu>,
}

pub struct ChunkUpload {
    pub slot: u32,
    pub meta: ChunkMetaGpu,

    pub node_base: u32,
    pub nodes: Arc<[NodeGpu]>,
}

// -----------------------------
// CPU cache (budgeted, LRU-ish)
// -----------------------------

#[derive(Clone)]
struct CachedChunk {
    nodes: Arc<[NodeGpu]>,
    bytes: usize,
    stamp: u64,
}

fn spawn_workers(gen: Arc<WorldGen>, rx_job: Receiver<BuildJob>, tx_done: Sender<BuildDone>) {
    for _ in 0..config::WORKER_THREADS {
        let gen = gen.clone();
        let rx_job = rx_job.clone();
        let tx_done = tx_done.clone();

        std::thread::spawn(move || {
            // One reusable scratch per worker thread: removes most per-chunk allocations.
            let mut scratch = BuildScratch::new();

            while let Ok(job) = rx_job.recv() {
                let k = job.key;

                // If we were already cancelled before starting, still notify the main thread
                // so it can decrement `in_flight`.
                if job.cancel.load(Ordering::Relaxed) {
                    if tx_done
                        .send(BuildDone {
                            key: k,
                            cancel: job.cancel,
                            canceled: true,
                            nodes: Vec::new(),
                        })
                        .is_err()
                    {
                        break;
                    }
                    continue;
                }

                let origin = [
                    k.x * config::CHUNK_SIZE as i32,
                    k.y * config::CHUNK_SIZE as i32,
                    k.z * config::CHUNK_SIZE as i32,
                ];

                let nodes = build_chunk_svo_sparse_cancelable_with_scratch(
                    &gen,
                    origin,
                    config::CHUNK_SIZE,
                    job.cancel.as_ref(),
                    &mut scratch,
                );

                // If we got cancelled mid-build, still notify the main thread,
                // but drop nodes to save main-thread work + upload pressure.
                let canceled = job.cancel.load(Ordering::Relaxed);
                let nodes = if canceled { Vec::new() } else { nodes };

                if tx_done
                    .send(BuildDone {
                        key: k,
                        cancel: job.cancel,
                        canceled,
                        nodes,
                    })
                    .is_err()
                {
                    break;
                }
            }
        });
    }
}

fn sort_queue_near_first(queue: &mut VecDeque<ChunkKey>, center: ChunkKey, cam_fwd: Vec3) {
    let mut v: Vec<ChunkKey> = queue.drain(..).collect();

    // Horizontal forward (XZ) for “look direction”.
    let mut f = Vec2::new(cam_fwd.x, cam_fwd.z);
    if f.length_squared() > 1e-6 {
        f = f.normalize();
    }

    v.sort_by(|a, b| {
        let sa = chunk_priority_score(*a, center, f);
        let sb = chunk_priority_score(*b, center, f);
        sa.partial_cmp(&sb).unwrap_or(std::cmp::Ordering::Equal)
    });

    queue.extend(v);
}

fn chunk_priority_score(k: ChunkKey, c: ChunkKey, _fwd_xz: Vec2) -> f32 {
    let dx = (k.x - c.x) as f32;
    let dz = (k.z - c.z) as f32;
    let dy = (k.y - c.y) as f32;

    // Lower score = higher priority.
    // Base distance (prefer close). Penalize vertical moves more.
    dx.abs() + dz.abs() + 2.0 * dy.abs()
}

pub struct ChunkManager {
    gen: Arc<WorldGen>,

    chunks: HashMap<ChunkKey, ChunkState>,
    build_queue: VecDeque<ChunkKey>,

    // Deduplicate queued keys (prevents unbounded queue growth).
    queued_set: HashSet<ChunkKey>,

    // Only sort/purge when center chunk changes.
    last_center: Option<ChunkKey>,

    // Per-chunk cancel tokens
    cancels: HashMap<ChunkKey, Arc<AtomicBool>>,

    tx_job: Sender<BuildJob>,
    rx_done: Receiver<BuildDone>,
    in_flight: usize,

    // Dense slots for resident chunks
    slot_to_key: Vec<ChunkKey>,    // slot -> key
    chunk_meta: Vec<ChunkMetaGpu>, // slot -> meta
    uploads: Vec<ChunkUpload>,     // pending GPU writes this frame

    // General “something changed” flag (kept for other systems).
    changed: bool,

    // Grid dirty flag:
    // - true when the GPU lookup grid needs rebuilding (origin shift or resident slot mapping changed)
    // - update() returns this so the renderer can skip `write_chunk_grid()` on most frames.
    grid_dirty: bool,

    // Node arena (in units of NodeGpu elements)
    arena: NodeArena,

    // Chunk grid for GPU lookup: maps grid cell -> resident slot index (or INVALID_U32).
    grid_origin_chunk: [i32; 3],
    grid_dims: [u32; 3],
    chunk_grid: Vec<u32>,

    // ----------------
    // CPU chunk cache
    // ----------------
    cache: HashMap<ChunkKey, CachedChunk>,
    cache_lru: VecDeque<(ChunkKey, u64)>, // (key, stamp) entries; duplicates are allowed
    cache_stamp: u64,
    cache_bytes: usize,
}

impl ChunkManager {
    pub fn new(gen: Arc<WorldGen>) -> Self {
        let (tx_job, rx_job) = unbounded::<BuildJob>();
        let (tx_done, rx_done) = unbounded::<BuildDone>();
        spawn_workers(gen.clone(), rx_job, tx_done);

        // Arena capacity in NodeGpu elements.
        let node_capacity = (config::NODE_BUDGET_BYTES / size_of::<NodeGpu>()) as u32;

        // Grid size (KEEP box).
        let nx = (2 * config::KEEP_RADIUS + 1) as u32;
        let nz = nx;
        let ny = GRID_Y_COUNT;
        let grid_len = (nx * ny * nz) as usize;

        Self {
            gen,
            chunks: HashMap::new(),
            build_queue: VecDeque::new(),
            queued_set: HashSet::new(),
            last_center: None,

            cancels: HashMap::new(),
            tx_job,
            rx_done,
            in_flight: 0,

            slot_to_key: Vec::new(),
            chunk_meta: Vec::new(),
            uploads: Vec::new(),
            changed: false,

            grid_dirty: true, // first update should build + upload the grid
            arena: NodeArena::new(node_capacity),

            grid_origin_chunk: [0, 0, 0],
            grid_dims: [nx, ny, nz],
            chunk_grid: vec![INVALID_U32; grid_len],

            cache: HashMap::new(),
            cache_lru: VecDeque::new(),
            cache_stamp: 1,
            cache_bytes: 0,
        }
    }

    // -------------------------------------------------------------------------
    // Public API
    // -------------------------------------------------------------------------

    pub fn chunk_count(&self) -> u32 {
        self.slot_to_key.len() as u32
    }

    pub fn grid_origin(&self) -> [i32; 3] {
        self.grid_origin_chunk
    }

    pub fn grid_dims(&self) -> [u32; 3] {
        self.grid_dims
    }

    pub fn chunk_grid(&self) -> &[u32] {
        &self.chunk_grid
    }

    pub fn take_uploads(&mut self) -> Vec<ChunkUpload> {
        std::mem::take(&mut self.uploads)
    }

    // -------------------------------------------------------------------------
    // Streaming update
    // -------------------------------------------------------------------------
    //
    // Returns:
    // - true  if the chunk_grid mapping changed (origin shift and/or resident slot mapping changed)
    // - false if chunk_grid is identical to last frame (safe to skip GPU upload)

    pub fn update(&mut self, world: &Arc<WorldGen>, cam_pos_m: Vec3, cam_fwd: Vec3) -> bool {
        self.uploads.clear();

        // Center chunk (ground-anchored).
        let cam_vx = (cam_pos_m.x / config::VOXEL_SIZE_M_F32).floor() as i32;
        let cam_vz = (cam_pos_m.z / config::VOXEL_SIZE_M_F32).floor() as i32;

        let ccx = cam_vx.div_euclid(config::CHUNK_SIZE as i32);
        let ccz = cam_vz.div_euclid(config::CHUNK_SIZE as i32);

        let ground_y_vox = world.ground_height(cam_vx, cam_vz);
        let ground_cy = ground_y_vox.div_euclid(config::CHUNK_SIZE as i32);

        let center = ChunkKey {
            x: ccx,
            y: ground_cy,
            z: ccz,
        };

        // Desired vs keep sets.
        let desired = Self::desired_chunks(center, config::ACTIVE_RADIUS);
        let keep = Self::desired_chunks(center, config::KEEP_RADIUS);
        let keep_set: HashSet<ChunkKey> = keep.iter().copied().collect();

        // Promote cached desired chunks immediately (no rebuild).
        // For missing desired chunks that are not cached, queue a build.
        for k in &desired {
            match self.chunks.get(k) {
                Some(ChunkState::Resident(_)) | Some(ChunkState::Queued) | Some(ChunkState::Building) => {
                    // Already handled / in progress.
                }
                None | Some(ChunkState::Missing) => {
                    // Cache hit: try promote from cache (alloc arena + upload), DO NOT queue build.
                    if self.cache.contains_key(k) {
                        let _ = self.try_promote_from_cache(center, *k);
                        continue;
                    }

                    // Cache miss: queue build.
                    let c = self.cancel_token(*k);
                    c.store(false, Ordering::Relaxed);

                    self.chunks.insert(*k, ChunkState::Queued);

                    // Dedupe queue entries.
                    if self.queued_set.insert(*k) {
                        self.build_queue.push_back(*k);
                    }
                }
            }
        }

        // Unload outside keep (also cancel queued/building).
        {
            let keys_snapshot: Vec<ChunkKey> = self.chunks.keys().copied().collect();
            for k in keys_snapshot {
                if !keep_set.contains(&k) {
                    self.unload_chunk(k);
                }
            }
        }

        // Only purge + sort when the center chunk changes.
        let center_changed = self.last_center.map_or(true, |c| c != center);
        if center_changed {
            self.last_center = Some(center);

            // Purge stale keys aggressively: keep only keys that are still queued and still in KEEP.
            self.build_queue.retain(|k| {
                keep_set.contains(k) && matches!(self.chunks.get(k), Some(ChunkState::Queued))
            });

            // Rebuild queued_set from the queue so it matches reality.
            self.queued_set.clear();
            self.queued_set.extend(self.build_queue.iter().copied());

            // Sort once per center change.
            sort_queue_near_first(&mut self.build_queue, center, cam_fwd);
        }

        // Dispatch builds (only for cache misses).
        while self.in_flight < config::MAX_IN_FLIGHT {
            let Some(k) = self.build_queue.pop_front() else { break; };

            // Popped => no longer queued.
            self.queued_set.remove(&k);

            if !keep_set.contains(&k) {
                // Cancel if it was pending.
                self.cancel_token(k).store(true, Ordering::Relaxed);
                self.chunks.insert(k, ChunkState::Missing);
                continue;
            }

            // If it became cached since it was queued (rare, but possible if you later add disk caching),
            // don't rebuild it.
            if self.cache.contains_key(&k) {
                self.chunks.insert(k, ChunkState::Missing);
                let _ = self.try_promote_from_cache(center, k);
                continue;
            }

            if matches!(self.chunks.get(&k), Some(ChunkState::Queued)) {
                self.chunks.insert(k, ChunkState::Building);

                let cancel = self.cancel_token(k);
                cancel.store(false, Ordering::Relaxed);

                if self
                    .tx_job
                    .send(BuildJob {
                        key: k,
                        cancel: cancel.clone(),
                    })
                    .is_ok()
                {
                    self.in_flight += 1;
                } else {
                    // Channel closed; keep it queued.
                    self.chunks.insert(k, ChunkState::Queued);

                    // Put it back (dedup-safe).
                    if self.queued_set.insert(k) {
                        self.build_queue.push_back(k);
                    }
                    break;
                }
            }
        }

        // Harvest done builds.
        while let Ok(done) = self.rx_done.try_recv() {
            if self.in_flight > 0 {
                self.in_flight -= 1;
            }

            // If the job was canceled (either before start or mid-build),
            // the chunk MUST NOT stay in Building forever.
            if done.canceled || done.cancel.load(Ordering::Relaxed) {
                if self.chunks.get(&done.key).is_some() {
                    self.chunks.insert(done.key, ChunkState::Missing);
                }
                continue;
            }

            // If it finished but is no longer in KEEP, drop it and mark Missing.
            if !keep_set.contains(&done.key) {
                self.cancel_token(done.key).store(true, Ordering::Relaxed);
                self.chunks.insert(done.key, ChunkState::Missing);
                continue;
            }

            // Still relevant: cache + try resident.
            self.on_build_done(center, done.key, done.nodes);
        }

        // If the keep-grid origin would shift, the lookup mapping changes.
        if self.keep_origin_for(center) != self.grid_origin_chunk {
            self.grid_dirty = true;
        }

        // Rebuild grid mapping for current KEEP region only when needed.
        let grid_changed = self.grid_dirty;
        if self.grid_dirty {
            self.rebuild_grid(center);
            self.grid_dirty = false;
        }

        grid_changed
    }

    // -------------------------------------------------------------------------
    // Internals
    // -------------------------------------------------------------------------

    fn cancel_token(&mut self, key: ChunkKey) -> Arc<AtomicBool> {
        self.cancels
            .entry(key)
            .or_insert_with(|| Arc::new(AtomicBool::new(false)))
            .clone()
    }

    fn desired_chunks(center: ChunkKey, radius: i32) -> Vec<ChunkKey> {
        let mut out = Vec::new();
        for dy in GRID_Y_MIN_DY..=(GRID_Y_MIN_DY + GRID_Y_COUNT as i32 - 1) {
            for dz in -radius..=radius {
                for dx in -radius..=radius {
                    out.push(ChunkKey {
                        x: center.x + dx,
                        y: center.y + dy,
                        z: center.z + dz,
                    });
                }
            }
        }
        out
    }

    fn evict_one_farthest(&mut self, center: ChunkKey, protect: ChunkKey) -> bool {
        if self.slot_to_key.is_empty() {
            return false;
        }

        let mut best: Option<(f32, ChunkKey)> = None;
        for &k in &self.slot_to_key {
            if k == protect {
                continue;
            }
            let dx = (k.x - center.x) as f32;
            let dz = (k.z - center.z) as f32;
            let dy = (k.y - center.y) as f32;

            // Weighted distance (favor keeping vertical neighbors).
            let d = dx * dx + dz * dz + 4.0 * dy * dy;

            if best.map_or(true, |(bd, _)| d > bd) {
                best = Some((d, k));
            }
        }

        if let Some((_, k)) = best {
            self.unload_chunk(k);
            return true;
        }

        false
    }

    // ----------------
    // Cache helpers
    // ----------------

    fn cache_touch(&mut self, key: ChunkKey) {
        if let Some(e) = self.cache.get_mut(&key) {
            self.cache_stamp = self.cache_stamp.wrapping_add(1).max(1);
            e.stamp = self.cache_stamp;
            self.cache_lru.push_back((key, e.stamp));
        }
    }

    fn cache_put(&mut self, key: ChunkKey, nodes: Arc<[NodeGpu]>) {
        let bytes = nodes.len() * size_of::<NodeGpu>();

        // If replacing an existing entry, subtract its bytes first.
        if let Some(old) = self.cache.remove(&key) {
            self.cache_bytes = self.cache_bytes.saturating_sub(old.bytes);
        }

        self.cache_stamp = self.cache_stamp.wrapping_add(1).max(1);
        let stamp = self.cache_stamp;

        self.cache.insert(
            key,
            CachedChunk {
                nodes,
                bytes,
                stamp,
            },
        );

        self.cache_bytes = self.cache_bytes.saturating_add(bytes);
        self.cache_lru.push_back((key, stamp));

        self.evict_cache_as_needed();
    }

    fn evict_cache_as_needed(&mut self) {
        let budget = config::CHUNK_CACHE_BUDGET_BYTES;

        while self.cache_bytes > budget {
            let Some((k, stamp)) = self.cache_lru.pop_front() else { break; };

            // Only evict if this LRU record matches the current entry stamp.
            let should_evict = self
                .cache
                .get(&k)
                .map(|e| e.stamp == stamp)
                .unwrap_or(false);

            if !should_evict {
                continue;
            }

            if let Some(ev) = self.cache.remove(&k) {
                self.cache_bytes = self.cache_bytes.saturating_sub(ev.bytes);
            }
        }
    }

    // -------------------------------
    // Resident creation / promotion
    // -------------------------------

    fn try_make_resident(
        &mut self,
        center: ChunkKey,
        key: ChunkKey,
        nodes: Arc<[NodeGpu]>,
    ) -> bool {
        // If already resident, nothing to do.
        if matches!(self.chunks.get(&key), Some(ChunkState::Resident(_))) {
            return true;
        }

        let need = nodes.len() as u32;

        // If we have nothing (shouldn't happen for non-air chunks, but be safe).
        if need == 0 {
            self.chunks.insert(key, ChunkState::Missing);
            return false;
        }

        // Try allocate; if fails, evict farthest chunks and retry a few times.
        let mut node_base = self.arena.alloc(need);
        if node_base.is_none() {
            for _ in 0..EVICT_ATTEMPTS {
                if !self.evict_one_farthest(center, key) {
                    break;
                }
                node_base = self.arena.alloc(need);
                if node_base.is_some() {
                    break;
                }
            }
        }

        let Some(node_base) = node_base else {
            // Can't fit right now; keep cache so we can promote later.
            self.chunks.insert(key, ChunkState::Missing);
            return false;
        };

        // Allocate slot (dense).
        let slot = self.slot_to_key.len() as u32;
        self.slot_to_key.push(key);

        let origin_vox = [
            key.x * config::CHUNK_SIZE as i32,
            key.y * config::CHUNK_SIZE as i32,
            key.z * config::CHUNK_SIZE as i32,
        ];

        let meta = ChunkMetaGpu {
            origin: [origin_vox[0], origin_vox[1], origin_vox[2], 0],
            node_base,
            node_count: need,
            _pad0: 0,
            _pad1: 0,
        };

        self.chunk_meta.push(meta);

        // Mark resident.
        self.chunks.insert(
            key,
            ChunkState::Resident(Resident {
                slot,
                node_base,
                node_count: need,
            }),
        );

        // Schedule GPU upload (nodes + meta).
        self.uploads.push(ChunkUpload {
            slot,
            meta,
            node_base,
            nodes,
        });

        // Resident set changed => grid mapping may change.
        self.grid_dirty = true;
        self.changed = true;

        true
    }

    fn try_promote_from_cache(&mut self, center: ChunkKey, key: ChunkKey) -> bool {
        let Some(entry) = self.cache.get(&key).cloned() else {
            return false;
        };

        // Touch LRU.
        self.cache_touch(key);

        // Try to make resident from cached nodes.
        self.try_make_resident(center, key, entry.nodes)
    }

    fn on_build_done(&mut self, center: ChunkKey, key: ChunkKey, nodes: Vec<NodeGpu>) {
        // If this chunk got cancelled while the result was in flight, drop it.
        if let Some(c) = self.cancels.get(&key) {
            if c.load(Ordering::Relaxed) {
                self.chunks.insert(key, ChunkState::Missing);
                return;
            }
        }

        // Convert to Arc slice once (cheap clones thereafter).
        let nodes_arc: Arc<[NodeGpu]> = nodes.into();

        // Cache it (so we never rebuild this chunk again unless evicted).
        self.cache_put(key, nodes_arc.clone());

        // If already resident (should be rare), don't allocate/upload again.
        if matches!(self.chunks.get(&key), Some(ChunkState::Resident(_))) {
            return;
        }

        // Try to allocate + upload now; if we can't fit, keep it cached and mark missing.
        let ok = self.try_make_resident(center, key, nodes_arc);
        if !ok {
            self.chunks.insert(key, ChunkState::Missing);
        }
    }

    fn unload_chunk(&mut self, key: ChunkKey) {
        let Some(state) = self.chunks.get(&key) else { return; };

        match *state {
            ChunkState::Resident(res) => {
                // Free node arena range.
                self.arena.free(res.node_base, res.node_count);

                // Remove slot densely by swap-remove.
                let dead_slot = res.slot as usize;
                let last_slot = self.slot_to_key.len().saturating_sub(1);

                if dead_slot != last_slot {
                    let moved_key = self.slot_to_key[last_slot];
                    self.slot_to_key[dead_slot] = moved_key;

                    // Move meta.
                    let moved_meta = self.chunk_meta[last_slot];
                    self.chunk_meta[dead_slot] = moved_meta;

                    // Update moved chunk's Resident.slot.
                    if let Some(state) = self.chunks.get_mut(&moved_key) {
                        if let ChunkState::Resident(mr) = state {
                            mr.slot = dead_slot as u32;
                        }
                    }

                    // Schedule meta rewrite for moved slot (GPU needs updated slot meta).
                    self.uploads.push(ChunkUpload {
                        slot: dead_slot as u32,
                        meta: self.chunk_meta[dead_slot],
                        node_base: 0,
                        nodes: Arc::<[NodeGpu]>::from(Vec::<NodeGpu>::new()),
                    });
                }

                self.slot_to_key.pop();
                self.chunk_meta.pop();

                self.chunks.insert(key, ChunkState::Missing);

                // Slot mapping changed => grid mapping changed.
                self.grid_dirty = true;
                self.changed = true;
            }

            ChunkState::Queued | ChunkState::Building => {
                // Cancel work in-flight.
                self.cancel_token(key).store(true, Ordering::Relaxed);

                // If it was queued, prevent duplicate re-adds.
                self.queued_set.remove(&key);

                self.chunks.insert(key, ChunkState::Missing);

                // Conservative dirty.
                self.grid_dirty = true;
                self.changed = true;
            }

            _ => {}
        }
    }

    /// Compute the KEEP-grid origin for a given center (helper so we can detect origin shifts).
    #[inline]
    fn keep_origin_for(&self, center: ChunkKey) -> [i32; 3] {
        let ox = center.x - config::KEEP_RADIUS;
        let oz = center.z - config::KEEP_RADIUS;
        let oy = center.y + GRID_Y_MIN_DY;
        [ox, oy, oz]
    }

    /// Rebuild the chunk_grid mapping for the current KEEP volume.
    ///
    /// This is intentionally called only when `grid_dirty` is set, because it is O(ncells + nchunks)
    /// and it forces a full GPU upload if you do it every frame.
    fn rebuild_grid(&mut self, center: ChunkKey) {
        let nx = (2 * config::KEEP_RADIUS + 1) as u32;
        let nz = nx;
        let ny = GRID_Y_COUNT;

        self.grid_dims = [nx, ny, nz];
        self.grid_origin_chunk = self.keep_origin_for(center);

        let needed = (nx * ny * nz) as usize;
        if self.chunk_grid.len() != needed {
            self.chunk_grid.resize(needed, INVALID_U32);
        }
        self.chunk_grid.fill(INVALID_U32);

        // Fill grid from resident chunks (slot -> key).
        for (slot, &k) in self.slot_to_key.iter().enumerate() {
            if let Some(idx) = self.grid_index_for_chunk(k) {
                self.chunk_grid[idx] = slot as u32;
            }
        }
    }

    #[inline]
    fn grid_index_for_chunk(&self, k: ChunkKey) -> Option<usize> {
        let [ox, oy, oz] = self.grid_origin_chunk;
        let [nx, ny, nz] = self.grid_dims;

        let ix = k.x - ox;
        let iy = k.y - oy;
        let iz = k.z - oz;

        if ix < 0 || iy < 0 || iz < 0 {
            return None;
        }

        let ix = ix as u32;
        let iy = iy as u32;
        let iz = iz as u32;

        if ix >= nx || iy >= ny || iz >= nz {
            return None;
        }

        let idx = (iz * ny * nx) + (iy * nx) + ix;
        Some(idx as usize)
    }
}

// src/streaming/mod.rs
// --------------------
// src/streaming/mod.rs
// --------------------
// Chunk streaming + node arena + uploads.

pub mod manager;
pub mod node_arena;

pub use manager::{ChunkManager, ChunkUpload};
pub use node_arena::NodeArena;

// src/streaming/node_arena.rs
// ---------------------------
// src/streaming/node_arena.rs
//
// Very simple free-list arena for node ranges (in units of NodeGpu elements).
// Improvements:
// - free() now fully coalesces adjacent ranges (fixes long-run fragmentation).
// - alloc() uses best-fit (smallest range that fits) to reduce fragmentation further.

#[derive(Clone, Copy, Debug)]
struct Range {
    start: u32,
    len: u32,
}

pub struct NodeArena {
    free: Vec<Range>, // kept sorted by start
}

impl NodeArena {
    pub fn new(capacity: u32) -> Self {
        Self {
            free: vec![Range {
                start: 0,
                len: capacity,
            }],
        }
    }

    /// Allocate a contiguous range of `len` elements.
    /// Returns the start index in the arena, or None if no free range fits.
    pub fn alloc(&mut self, len: u32) -> Option<u32> {
        if len == 0 {
            return Some(0);
        }

        // Best-fit: choose the smallest free range that still fits.
        let mut best_i: Option<usize> = None;
        let mut best_len: u32 = u32::MAX;

        for (i, r) in self.free.iter().enumerate() {
            if r.len >= len && r.len < best_len {
                best_len = r.len;
                best_i = Some(i);
                if r.len == len {
                    break; // perfect fit
                }
            }
        }

        let i = best_i?;
        let r = self.free[i];
        let start = r.start;

        if r.len == len {
            self.free.remove(i);
        } else {
            self.free[i] = Range {
                start: r.start + len,
                len: r.len - len,
            };
        }

        Some(start)
    }

    /// Free a previously allocated range.
    pub fn free(&mut self, start: u32, len: u32) {
        if len == 0 {
            return;
        }

        // Insert sorted by start.
        let mut idx = 0usize;
        while idx < self.free.len() && self.free[idx].start < start {
            idx += 1;
        }
        self.free.insert(idx, Range { start, len });

        // Fully coalesce with neighbors (both directions).
        self.coalesce_at(idx);
    }

    fn coalesce_at(&mut self, mut i: usize) {
        // Merge backward as long as possible.
        while i > 0 {
            let a = self.free[i - 1];
            let b = self.free[i];
            if a.start + a.len == b.start {
                self.free[i - 1] = Range {
                    start: a.start,
                    len: a.len + b.len,
                };
                self.free.remove(i);
                i -= 1;
            } else {
                break;
            }
        }

        // Merge forward as long as possible.
        while i + 1 < self.free.len() {
            let a = self.free[i];
            let b = self.free[i + 1];
            if a.start + a.len == b.start {
                self.free[i] = Range {
                    start: a.start,
                    len: a.len + b.len,
                };
                self.free.remove(i + 1);
            } else {
                break;
            }
        }
    }

    // Optional: quick stats for debugging.
    pub fn free_range_count(&self) -> usize {
        self.free.len()
    }

    pub fn largest_free_range(&self) -> u32 {
        self.free.iter().map(|r| r.len).max().unwrap_or(0)
    }

    pub fn total_free(&self) -> u32 {
        self.free.iter().map(|r| r.len).sum()
    }
}

// src/svo/builder.rs
// ------------------
// src/svo/builder.rs

use std::sync::atomic::{AtomicBool, Ordering};

use crate::{
    config,
    render::NodeGpu,
    world::{
        materials::{AIR, DIRT, GRASS, STONE, WOOD},
        WorldGen,
    },
};

use super::mips::{build_max_mip_inplace, build_minmax_mip_inplace, MaxMipView, MinMaxMipView};

const LEAF: u32 = 0xFFFF_FFFF;

#[inline]
fn is_empty_leaf(n: &NodeGpu) -> bool {
    n.child_base == LEAF && n.material == AIR
}

#[inline]
fn should_cancel(cancel: &AtomicBool) -> bool {
    cancel.load(Ordering::Relaxed)
}

/// Reusable scratch buffers for chunk building (reduces allocations & improves locality).
pub struct BuildScratch {
    // 2D (side*side)
    ground: Vec<i32>,
    tree_top: Vec<i32>,

    // --- add this ---
    height_cache: Vec<i32>,
    height_cache_w: usize,
    height_cache_h: usize,

    // 3D (side^3)
    material: Vec<u32>,
    prefix: Vec<u32>,

    // mip storage
    ground_min_levels: Vec<Vec<i32>>,
    ground_max_levels: Vec<Vec<i32>>,
    tree_levels: Vec<Vec<i32>>,
}


impl BuildScratch {
    pub fn new() -> Self {
        Self {
            ground: Vec::new(),
            tree_top: Vec::new(),

            height_cache: Vec::new(),
            height_cache_w: 0,
            height_cache_h: 0,

            material: Vec::new(),
            prefix: Vec::new(),
            ground_min_levels: Vec::new(),
            ground_max_levels: Vec::new(),
            tree_levels: Vec::new(),
        }
    }

    #[inline]
    fn ensure_height_cache(&mut self, w: usize, h: usize) {
        let need = w * h;
        if self.height_cache.len() != need {
            self.height_cache.resize(need, 0);
        } else {
            self.height_cache.fill(0);
        }
        self.height_cache_w = w;
        self.height_cache_h = h;
    }


    #[inline]
    fn ensure_2d(v: &mut Vec<i32>, side: usize, fill: i32) {
        let need = side * side;
        if v.len() != need {
            v.resize(need, fill);
        } else {
            v.fill(fill);
        }
    }

    #[inline]
    fn ensure_3d_u32(v: &mut Vec<u32>, side: usize, fill: u32) {
        let need = side * side * side;
        if v.len() != need {
            v.resize(need, fill);
        } else {
            v.fill(fill);
        }
    }

    #[inline]
    fn ensure_prefix(v: &mut Vec<u32>, side: usize) {
        let dim = side + 1;
        let need = dim * dim * dim;
        if v.len() != need {
            v.resize(need, 0);
        } else {
            v.fill(0);
        }
    }
}

#[inline]
fn idx2(side: usize, x: usize, z: usize) -> usize {
    z * side + x
}

#[inline]
fn idx3(side: usize, x: usize, y: usize, z: usize) -> usize {
    (y * side * side) + (z * side) + x
}

#[inline]
fn pidx(dim: usize, x: usize, y: usize, z: usize) -> usize {
    (z * dim * dim) + (y * dim) + x
}

#[inline]
fn prefix_sum_cube(prefix: &[u32], side: usize, x0: usize, y0: usize, z0: usize, size: usize) -> u32 {
    let dim = side + 1;
    let x1 = x0 + size;
    let y1 = y0 + size;
    let z1 = z0 + size;

    let a = prefix[pidx(dim, x1, y1, z1)] as i64;
    let b = prefix[pidx(dim, x0, y1, z1)] as i64;
    let c = prefix[pidx(dim, x1, y0, z1)] as i64;
    let d = prefix[pidx(dim, x1, y1, z0)] as i64;
    let e = prefix[pidx(dim, x0, y0, z1)] as i64;
    let f = prefix[pidx(dim, x0, y1, z0)] as i64;
    let g = prefix[pidx(dim, x1, y0, z0)] as i64;
    let h = prefix[pidx(dim, x0, y0, z0)] as i64;

    let s = a - b - c - d + e + f + g - h;
    debug_assert!(s >= 0);
    s as u32
}

/// Cancelable build with reusable scratch (fast path).
pub fn build_chunk_svo_sparse_cancelable_with_scratch(
    gen: &WorldGen,
    chunk_origin: [i32; 3],
    chunk_size: u32,
    cancel: &AtomicBool,
    scratch: &mut BuildScratch,
) -> Vec<NodeGpu> {
    if should_cancel(cancel) {
        return Vec::new();
    }

    let chunk_ox = chunk_origin[0];
    let chunk_oy = chunk_origin[1];
    let chunk_oz = chunk_origin[2];

    let cs_u = chunk_size;
    let cs_i = chunk_size as i32;
    debug_assert!(cs_u.is_power_of_two());

    let side = cs_u as usize;
    let vpm: i32 = config::VOXELS_PER_METER as i32;
    debug_assert!(vpm > 0);

    // -------------------------------------------------------------------------
    // Height cache (local array)
    // -------------------------------------------------------------------------
    let margin_m: i32 = 6;
    let margin: i32 = margin_m * vpm + (vpm - 1);

    let cache_x0 = chunk_ox - margin;
    let cache_z0 = chunk_oz - margin;
    let cache_x1 = chunk_ox + cs_i + margin; // inclusive
    let cache_z1 = chunk_oz + cs_i + margin; // inclusive

    let cache_w = (cache_x1 - cache_x0 + 1) as usize;
    let cache_h = (cache_z1 - cache_z0 + 1) as usize;

    scratch.ensure_height_cache(cache_w, cache_h);
    for z in 0..cache_h {
        if (z & 15) == 0 && should_cancel(cancel) {
            return Vec::new();
        }
        let wz = cache_z0 + z as i32;
        let row = z * cache_w;
        for x in 0..cache_w {
            let wx = cache_x0 + x as i32;
            scratch.height_cache[row + x] = gen.ground_height(wx, wz);
        }
    }

    let height_at = |wx: i32, wz: i32| -> i32 {
        if wx < cache_x0 || wx > cache_x1 || wz < cache_z0 || wz > cache_z1 {
            gen.ground_height(wx, wz)
        } else {
            let ix = (wx - cache_x0) as usize;
            let iz = (wz - cache_z0) as usize;
            scratch.height_cache[iz * scratch.height_cache_w + ix]
        }
    };


    // -------------------------------------------------------------------------
    // Tree cache/mask (fast O(1) material lookup)
    // -------------------------------------------------------------------------
    let (_tree_cache_unused, tree_mask) = gen.build_tree_cache_with_mask(
        chunk_ox,
        chunk_oy,
        chunk_oz,
        cs_i,
        &height_at,
        cancel,
    );

    // -------------------------------------------------------------------------
    // 2D maps (ground)
    // -------------------------------------------------------------------------
    BuildScratch::ensure_2d(&mut scratch.ground, side, 0);

    for lz in 0..cs_i {
        if (lz & 15) == 0 && should_cancel(cancel) {
            return Vec::new();
        }
        for lx in 0..cs_i {
            let wx = chunk_ox + lx;
            let wz = chunk_oz + lz;
            let g = height_at(wx, wz);

            let i = idx2(side, lx as usize, lz as usize);
            scratch.ground[i] = g;
        }
    }

    let ground_mip: MinMaxMipView<'_> = build_minmax_mip_inplace(
        &scratch.ground,
        cs_u,
        &mut scratch.ground_min_levels,
        &mut scratch.ground_max_levels,
    );

    // -------------------------------------------------------------------------
    // Tree top stamp (2D) for fast “above everything” pruning
    // -------------------------------------------------------------------------
    BuildScratch::ensure_2d(&mut scratch.tree_top, side, -1);

    let pad_m = 4;
    let xm0 = (chunk_ox.div_euclid(vpm)) - pad_m;
    let xm1 = ((chunk_ox + cs_i).div_euclid(vpm)) + pad_m;
    let zm0 = (chunk_oz.div_euclid(vpm)) - pad_m;
    let zm1 = ((chunk_oz + cs_i).div_euclid(vpm)) + pad_m;

    for zm in zm0..=zm1 {
        if ((zm - zm0) & 3) == 0 && should_cancel(cancel) {
            return Vec::new();
        }

        for xm in xm0..=xm1 {
            let Some((trunk_h_vox, crown_r_vox)) = gen.tree_instance_at_meter(xm, zm) else {
                continue;
            };

            let tx = xm * vpm;
            let tz = zm * vpm;

            let g = height_at(tx, tz);
            let trunk_base = g + vpm;
            let trunk_top = trunk_base + trunk_h_vox;

            let canopy_h_vox = 5 * vpm;
            let top_y = trunk_top + canopy_h_vox + 2 * vpm;

            let r = crown_r_vox + 2 * vpm;

            for dz in -r..=r {
                for dx in -r..=r {
                    if dx * dx + dz * dz > r * r {
                        continue;
                    }

                    let wx = tx + dx;
                    let wz = tz + dz;

                    let lx = wx - chunk_ox;
                    let lz = wz - chunk_oz;
                    if lx >= 0 && lx < cs_i && lz >= 0 && lz < cs_i {
                        let i = idx2(side, lx as usize, lz as usize);
                        scratch.tree_top[i] = scratch.tree_top[i].max(top_y);
                    }
                }
            }

            // ensure trunk column included
            let lx = tx - chunk_ox;
            let lz = tz - chunk_oz;
            if lx >= 0 && lx < cs_i && lz >= 0 && lz < cs_i {
                let i = idx2(side, lx as usize, lz as usize);
                scratch.tree_top[i] = scratch.tree_top[i].max(trunk_top);
            }
        }
    }

    let tree_mip: MaxMipView<'_> =
        build_max_mip_inplace(&scratch.tree_top, cs_u, &mut scratch.tree_levels);

    // -------------------------------------------------------------------------
    // Precompute per-voxel material + occupancy (terrain + trees only)
    // -------------------------------------------------------------------------
    BuildScratch::ensure_3d_u32(&mut scratch.material, side, AIR);

    let dirt_depth = 3 * vpm;

    for ly in 0..cs_i {
        if (ly & 7) == 0 && should_cancel(cancel) {
            return Vec::new();
        }

        let wy = chunk_oy + ly;

        for lz in 0..cs_i {
            for lx in 0..cs_i {
                let wx = chunk_ox + lx;
                let wz = chunk_oz + lz;

                let col = idx2(side, lx as usize, lz as usize);
                let g = scratch.ground[col];

                // base terrain + trees (FAST)
                let m: u32 = if wy < g {
                    if wy >= g - dirt_depth { DIRT } else { STONE }
                } else if wy == g {
                    let tm = tree_mask.material_fast(wx, wy, wz);
                    if tm == WOOD { WOOD } else { GRASS }
                } else {
                    let tm = tree_mask.material_fast(wx, wy, wz);
                    if tm != AIR { tm } else { AIR }
                };

                let i3 = idx3(side, lx as usize, ly as usize, lz as usize);
                scratch.material[i3] = m;
            }
        }
    }

    // -------------------------------------------------------------------------
    // Prefix sum over solid occupancy
    // -------------------------------------------------------------------------
    BuildScratch::ensure_prefix(&mut scratch.prefix, side);
    let dim = side + 1;

    for z in 1..=side {
        if (z & 7) == 0 && should_cancel(cancel) {
            return Vec::new();
        }
        for y in 1..=side {
            let mut run: u32 = 0;
            for x in 1..=side {
                let v = (scratch.material[idx3(side, x - 1, y - 1, z - 1)] != AIR) as u32;
                run += v;

                let a = scratch.prefix[pidx(dim, x, y, z - 1)] as i64;
                let b = scratch.prefix[pidx(dim, x, y - 1, z)] as i64;
                let c = scratch.prefix[pidx(dim, x, y - 1, z - 1)] as i64;

                let p = a + b - c + (run as i64);
                debug_assert!(p >= 0);
                scratch.prefix[pidx(dim, x, y, z)] = p as u32;
            }
        }
    }

    fn build_node(
        nodes: &mut Vec<NodeGpu>,
        ox: i32,
        oy: i32,
        oz: i32,
        size: i32,
        chunk_oy: i32,
        material: &[u32],
        prefix: &[u32],
        side: usize,
        ground_mip: &MinMaxMipView<'_>,
        tree_mip: &MaxMipView<'_>,
        dirt_depth: i32,
        cancel: &AtomicBool,
    ) -> NodeGpu {
        if should_cancel(cancel) {
            return NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 };
        }

        let size_u = size as u32;

        let (gmin, gmax) = ground_mip.query(ox, oz, size_u);
        let tmax = tree_mip.query_max(ox, oz, size_u);

        let y0 = chunk_oy + oy;
        let y1 = y0 + size - 1;

        // above everything (ground or tree top)
        let top_solid = gmax.max(tmax);
        if y0 > top_solid {
            return NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 };
        }

        // deep solid stone (below dirt band everywhere in this node footprint)
        if y1 < gmin - dirt_depth {
            return NodeGpu { child_base: LEAF, child_mask: 0, material: STONE, _pad: 0 };
        }

        // empty check via prefix
        let sx = ox as usize;
        let sy = oy as usize;
        let sz = oz as usize;
        let s = size as usize;

        let sum = prefix_sum_cube(prefix, side, sx, sy, sz, s);
        if sum == 0 {
            return NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 };
        }

        if size == 1 {
            let m = material[idx3(side, sx, sy, sz)];
            return NodeGpu { child_base: LEAF, child_mask: 0, material: m, _pad: 0 };
        }

        let half = size / 2;
        let mut child_roots: [NodeGpu; 8] =
            [NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 }; 8];

        for ci in 0..8 {
            if (ci & 3) == 0 && should_cancel(cancel) {
                return NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 };
            }

            let dx = if (ci & 1) != 0 { half } else { 0 };
            let dy = if (ci & 2) != 0 { half } else { 0 };
            let dz = if (ci & 4) != 0 { half } else { 0 };

            child_roots[ci] = build_node(
                nodes,
                ox + dx,
                oy + dy,
                oz + dz,
                half,
                chunk_oy,
                material,
                prefix,
                side,
                ground_mip,
                tree_mip,
                dirt_depth,
                cancel,
            );
        }

        let base = nodes.len() as u32;
        let mut mask: u32 = 0;

        for ci in 0..8 {
            if !is_empty_leaf(&child_roots[ci]) {
                mask |= 1u32 << ci;
                nodes.push(child_roots[ci]);
            }
        }

        if mask == 0 {
            return NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 };
        }

        NodeGpu { child_base: base, child_mask: mask, material: 0, _pad: 0 }
    }

    // Root must be at index 0 for GPU.
    let mut nodes = vec![NodeGpu { child_base: LEAF, child_mask: 0, material: AIR, _pad: 0 }];

    let root = build_node(
        &mut nodes,
        0,
        0,
        0,
        cs_i,
        chunk_oy,
        &scratch.material,
        &scratch.prefix,
        side,
        &ground_mip,
        &tree_mip,
        dirt_depth,
        cancel,
    );

    if should_cancel(cancel) {
        return Vec::new();
    }

    nodes[0] = root;
    nodes
}

// src/svo/mips.rs
// ---------------
// src/svo/mips.rs

pub struct MinMaxMipView<'a> {
    pub root_side: u32,
    pub min_levels: &'a [Vec<i32>],
    pub max_levels: &'a [Vec<i32>],
}

pub fn build_minmax_mip_inplace<'a>(
    base: &[i32],
    side: u32,
    min_levels: &'a mut Vec<Vec<i32>>,
    max_levels: &'a mut Vec<Vec<i32>>,
) -> MinMaxMipView<'a> {
    debug_assert!(side.is_power_of_two());
    debug_assert_eq!(base.len(), (side * side) as usize);

    let levels = side.trailing_zeros() as usize + 1;

    if min_levels.len() != levels {
        min_levels.resize_with(levels, Vec::new);
    }
    if max_levels.len() != levels {
        max_levels.resize_with(levels, Vec::new);
    }

    // lvl 0
    min_levels[0].clear();
    min_levels[0].extend_from_slice(base);

    max_levels[0].clear();
    max_levels[0].extend_from_slice(base);

    let mut cur_side = side;

    for lvl in 1..levels {
        let next_side = cur_side / 2;
        let need = (next_side * next_side) as usize;

        // --- min: borrow prev + out without aliasing
        {
            let (prev, rest) = min_levels.split_at_mut(lvl);
            let cur_min: &[i32] = &prev[lvl - 1];
            let mn: &mut Vec<i32> = &mut rest[0];
            mn.resize(need, 0);

            for z in 0..next_side {
                for x in 0..next_side {
                    let i00 = ((2 * z) * cur_side + (2 * x)) as usize;
                    let i10 = ((2 * z) * cur_side + (2 * x + 1)) as usize;
                    let i01 = ((2 * z + 1) * cur_side + (2 * x)) as usize;
                    let i11 = ((2 * z + 1) * cur_side + (2 * x + 1)) as usize;

                    let o = (z * next_side + x) as usize;

                    let a0 = cur_min[i00];
                    let a1 = cur_min[i10];
                    let a2 = cur_min[i01];
                    let a3 = cur_min[i11];

                    mn[o] = a0.min(a1).min(a2).min(a3);
                }
            }
        }

        // --- max: borrow prev + out without aliasing
        {
            let (prev, rest) = max_levels.split_at_mut(lvl);
            let cur_max: &[i32] = &prev[lvl - 1];
            let mx: &mut Vec<i32> = &mut rest[0];
            mx.resize(need, 0);

            for z in 0..next_side {
                for x in 0..next_side {
                    let i00 = ((2 * z) * cur_side + (2 * x)) as usize;
                    let i10 = ((2 * z) * cur_side + (2 * x + 1)) as usize;
                    let i01 = ((2 * z + 1) * cur_side + (2 * x)) as usize;
                    let i11 = ((2 * z + 1) * cur_side + (2 * x + 1)) as usize;

                    let o = (z * next_side + x) as usize;

                    let b0 = cur_max[i00];
                    let b1 = cur_max[i10];
                    let b2 = cur_max[i01];
                    let b3 = cur_max[i11];

                    mx[o] = b0.max(b1).max(b2).max(b3);
                }
            }
        }

        cur_side = next_side;
    }

    MinMaxMipView {
        root_side: side,
        min_levels: &min_levels[..],
        max_levels: &max_levels[..],
    }
}

impl<'a> MinMaxMipView<'a> {
    #[inline]
    pub fn query(&self, x0: i32, z0: i32, size: u32) -> (i32, i32) {
        debug_assert!(size.is_power_of_two());
        debug_assert!(size <= self.root_side);
        debug_assert!(x0 >= 0 && z0 >= 0);

        let level = size.trailing_zeros() as usize;
        debug_assert!(level < self.min_levels.len());

        let side = self.root_side >> level;
        let x = (x0 as u32) / size;
        let z = (z0 as u32) / size;
        let idx = (z * side + x) as usize;

        (self.min_levels[level][idx], self.max_levels[level][idx])
    }
}

pub struct MaxMipView<'a> {
    pub root_side: u32,
    pub levels: &'a [Vec<i32>],
}

pub fn build_max_mip_inplace<'a>(
    base: &[i32],
    side: u32,
    levels: &'a mut Vec<Vec<i32>>,
) -> MaxMipView<'a> {
    debug_assert!(side.is_power_of_two());
    debug_assert_eq!(base.len(), (side * side) as usize);

    let nlevels = side.trailing_zeros() as usize + 1;

    if levels.len() != nlevels {
        levels.resize_with(nlevels, Vec::new);
    }

    // lvl 0
    levels[0].clear();
    levels[0].extend_from_slice(base);

    let mut cur_side = side;

    for lvl in 1..nlevels {
        let next_side = cur_side / 2;
        let need = (next_side * next_side) as usize;

        let (prev, rest) = levels.split_at_mut(lvl);
        let cur: &[i32] = &prev[lvl - 1];
        let out: &mut Vec<i32> = &mut rest[0];
        out.resize(need, 0);

        for z in 0..next_side {
            for x in 0..next_side {
                let i00 = ((2 * z) * cur_side + (2 * x)) as usize;
                let i10 = ((2 * z) * cur_side + (2 * x + 1)) as usize;
                let i01 = ((2 * z + 1) * cur_side + (2 * x)) as usize;
                let i11 = ((2 * z + 1) * cur_side + (2 * x + 1)) as usize;

                let o = (z * next_side + x) as usize;
                out[o] = cur[i00].max(cur[i10]).max(cur[i01]).max(cur[i11]);
            }
        }

        cur_side = next_side;
    }

    MaxMipView {
        root_side: side,
        levels: &levels[..],
    }
}

impl<'a> MaxMipView<'a> {
    #[inline]
    pub fn query_max(&self, x0: i32, z0: i32, size: u32) -> i32 {
        debug_assert!(size.is_power_of_two());
        debug_assert!(size <= self.root_side);
        debug_assert!(x0 >= 0 && z0 >= 0);

        let level = size.trailing_zeros() as usize;
        debug_assert!(level < self.levels.len());

        let side = self.root_side >> level;
        let x = (x0 as u32) / size;
        let z = (z0 as u32) / size;
        let idx = (z * side + x) as usize;

        self.levels[level][idx]
    }
}

// src/svo/mod.rs
// --------------
// src/svo/mod.rs
pub mod builder;
pub mod mips;

pub use builder::{
    BuildScratch,
    build_chunk_svo_sparse_cancelable_with_scratch,
};

// src/world/generator.rs
// ----------------------
// src/world/generator.rs

use noise::{Fbm, MultiFractal, NoiseFn, Perlin};

use crate::config;

#[derive(Clone)]
pub struct WorldGen {
    pub seed: u32,
    height: Fbm<Perlin>,
    detail: Fbm<Perlin>,
}

impl WorldGen {
    pub fn new(seed: u32) -> Self {
        let height = Fbm::<Perlin>::new(seed).set_octaves(7).set_frequency(0.010);
        let detail = Fbm::<Perlin>::new(seed ^ 0xA5A5_A5A5).set_octaves(3).set_frequency(0.02);

        Self { seed, height, detail }
    }

    pub fn ground_height(&self, x_vox: i32, z_vox: i32) -> i32 {
        let xm = x_vox as f64 * config::VOXEL_SIZE_M_F64;
        let zm = z_vox as f64 * config::VOXEL_SIZE_M_F64;

        let h0 = self.height.get([xm, zm]) as f32;
        let h1 = self.detail.get([xm, zm]) as f32;

        let base_m = 10.0;
        let amp_m = 18.0;
        let hills_m = h0 * amp_m + h1 * 3.0;

        let voxels_per_meter = (1.0 / config::VOXEL_SIZE_M_F64) as f32;
        ((base_m + hills_m) * voxels_per_meter).round() as i32
    }
}

// src/world/hash.rs
// -----------------
// src/world/hash.rs
#[inline]
pub fn hash_u32(mut v: u32) -> u32 {
    v ^= v >> 16;
    v = v.wrapping_mul(0x7feb_352d);
    v ^= v >> 15;
    v = v.wrapping_mul(0x846c_a68b);
    v ^= v >> 16;
    v
}

#[inline]
pub fn hash2(seed: u32, x: i32, z: i32) -> u32 {
    let a = (x as u32).wrapping_mul(0x9e37_79b1);
    let b = (z as u32).wrapping_mul(0x85eb_ca6b);
    hash_u32(seed ^ a ^ b)
}

#[inline]
pub fn hash3(seed: u32, x: i32, y: i32, z: i32) -> u32 {
    let a = (x as u32).wrapping_mul(0x9e37_79b1);
    let b = (y as u32).wrapping_mul(0x85eb_ca6b);
    let c = (z as u32).wrapping_mul(0xc2b2_ae35);
    hash_u32(seed ^ a ^ b ^ c)
}

#[inline]
pub fn u01(v: u32) -> f32 {
    (v as f32) * (1.0 / 4294967296.0)
}

// src/world/materials.rs
// ----------------------
// src/world/materials.rs
pub const AIR: u32 = 0;
pub const GRASS: u32 = 1;
pub const DIRT: u32 = 2;
pub const STONE: u32 = 3;
pub const WOOD: u32 = 4;
pub const LEAF: u32 = 5;

// src/world/mod.rs
// ----------------
// src/world/mod.rs
pub mod generator;
pub mod materials;
pub mod hash;
pub mod trees;

pub use generator::WorldGen;

// src/world/trees.rs
// ------------------
// src/world/trees.rs
use crate::config;

use super::{
    generator::WorldGen,
    hash::{hash2, hash3, hash_u32, u01},
    materials::{AIR, LEAF, WOOD},
};

// ================================================================================================
// TREE TUNING KNOBS
// ================================================================================================
// Conventions
// - vpm = voxels per meter (VOXELS_PER_METER)
// - Fast probability via bitmask:
//      (hash & mask) == 0  => true with probability 1/(mask+1)
//
// Notes:
// - AABB = axis-aligned bounding box
// - BFS = breadth-first search
// - SVO = Sparse Voxel Octree
// ================================================================================================

// Tree density: 1 tree per N meter-cells (lower => more trees)
const TREE_CELL_MOD: u32 = 256;

// ----------------------------------------
// Primary branches (depth=0)
// ----------------------------------------

// Fewer primaries, but less “spike crown”
const PRIMARY_MIN: usize = 6;
const PRIMARY_MAX: usize = 14;
const PRIMARY_MAX_CLAMP: usize = 18;

// Start height along trunk (% of trunk height)
// IMPORTANT: allow starts right near the top so the trunk doesn't look “pruned”
const PRIMARY_START_Y_LO_FRAC: i32 = 28;
const PRIMARY_START_Y_HI_FRAC: i32 = 99; // was 92
const PRIMARY_START_JITTER_FRAC: f32 = 0.10;

// Shape
const PRIMARY_ANG_JITTER: f32 = 1.05; // more irregular azimuth (less radial symmetry)

// SHORTER primaries (big lever for “branches too long”)
const PRIMARY_LEN_M_MIN: f32 = 1.40;
const PRIMARY_LEN_M_RAND: f32 = 2.20;

// More vertical variation + less spear-like
const PRIMARY_PITCH_BASE: f32 = 0.10;
const PRIMARY_PITCH_H_SCALE: f32 = 0.18;
const PRIMARY_PITCH_QUAD_BASE: f32 = 0.44;
const PRIMARY_PITCH_QUAD_H_SCALE: f32 = 0.22;

const PRIMARY_R0_M_MIN: f32 = 0.13;
const PRIMARY_R0_M_RAND: f32 = 0.22;
const PRIMARY_R1_SCALE_MIN: f32 = 0.28;
const PRIMARY_R1_SCALE_RAND: f32 = 0.22;

// More curvature so branches feel “grown”, not extruded
const PRIMARY_BEND_M_MIN: f32 = 1.05;
const PRIMARY_BEND_M_RAND: f32 = 1.85;
const PRIMARY_C1_T: f32 = 0.28;
const PRIMARY_C2_T: f32 = 0.72;
const PRIMARY_C1_BEND_SCALE: f32 = 1.10;
const PRIMARY_C2_BEND_SCALE: f32 = 0.85;
const PRIMARY_C1_Y_BEND_SCALE: f32 = 0.44;
const PRIMARY_C2_Y_BEND_SCALE: f32 = 0.34;

// ----------------------------------------
// Recursion / complexity
// ----------------------------------------

const MAX_BRANCH_DEPTH: u8 = 4;
const BRANCH_CAP: usize = 520;

// How many child candidates per parent depth: min + uniform(0..rand)
// Index = parent.depth clamped to 0..3
const CHILD_COUNT_MIN: [usize; 4] = [3, 3, 2, 1];
const CHILD_COUNT_RAND: [usize; 4] = [3, 3, 3, 3];

// Aggressive thinning (keeps overall sparse structure)
// Keep child only if (sj & mask) == 0
const CHILD_SPAWN_THIN_MASK: [u32; 4] = [
    3,  // depth=0: keep ~1/4
    7,  // depth=1: keep ~1/8
    15, // depth=2: keep ~1/16
    31, // depth>=3: keep ~1/32
];

// Spawn position along parent
const CHILD_SPAWN_T_MIN: f32 = 0.32;
const CHILD_SPAWN_T_RAND: f32 = 0.58;

// SHORTER children
const CHILD_LEN_M_MIN: f32 = 0.35;
const CHILD_LEN_M_RAND: f32 = 1.05;
const CHILD_LEN_M_FLOOR: f32 = 0.28;

// Clamp children harder vs parent length
const CHILD_MAXLEN_A: f32 = 0.48;
const CHILD_MAXLEN_B: f32 = 0.18;

// Direction shaping
const CHILD_FAN_AMP_BASE: f32 = 0.95;
const CHILD_FAN_AMP_DEPTH: f32 = 0.38;

const CHILD_UP_BASE: f32 = 0.10;
const CHILD_UP_DEPTH: f32 = 0.10;
const CHILD_UP_RAND: f32 = 0.28;

// Radius shrink factor by child depth (depth=1..)
const CHILD_SHRINK: [f32; 4] = [0.58, 0.52, 0.46, 0.40];

const CHILD_R0_MIN_VOX: f32 = 0.70;
const CHILD_R1_MIN_VOX: f32 = 0.50;
const CHILD_R1_SCALE_BASE: f32 = 0.34;
const CHILD_R1_SCALE_RAND: f32 = 0.16;

// Curvature
const CHILD_BEND_M_MIN: f32 = 0.45;
const CHILD_BEND_M_RAND: f32 = 1.25;
const CHILD_C1_T: f32 = 0.28;
const CHILD_C2_T: f32 = 0.72;
const CHILD_C1_BEND_SCALE: f32 = 1.05;
const CHILD_C2_BEND_SCALE: f32 = 0.78;
const CHILD_C1_Y_BEND_SCALE: f32 = 0.34;
const CHILD_C2_Y_BEND_SCALE: f32 = 0.26;

// ----------------------------------------
// Branch rasterization
// ----------------------------------------

const BRANCH_STEPS_MIN: i32 = 8;
const BRANCH_STEPS_MAX: i32 = 30;
const BRANCH_STEPS_BASE: f32 = 10.0;
const BRANCH_STEPS_LEN_DIV_M: f32 = 0.30;
const BRANCH_RADIUS_MIN_VOX: f32 = 0.55;

// ----------------------------------------
// Leaves
// ----------------------------------------

const LEAF_ALWAYS_TIP_FOR_ALL_BRANCHES: bool = true;
const LEAF_RARE_SKIP_MASK: u32 = 16383;

// Canopy extent along branches: more sleeves, distributed earlier
const LEAF_SLEEVE_N: [usize; 5] = [3, 3, 4, 4, 5];
const LEAF_SLEEVE_T_MIN: f32 = 0.14;
const LEAF_SLEEVE_T_RAND: f32 = 0.78;

// Disable extra offset tip tuft (tends to create little dense “buttons”)
const LEAF_OFFSET_TIP_MASK: u32 = 0;

// Bigger offsets = wider canopy without adding branches
const LEAF_OFFSET_M_XZ: f32 = 0.95;
const LEAF_OFFSET_M_Y: f32 = 0.46;

const LEAF_SLEEVE_OFFSET_M_XZ: f32 = 0.62;
const LEAF_SLEEVE_OFFSET_M_Y: f32 = 0.34;

// Big tufts (canopy size)
const TUFT_R_BASE: [f32; 5] = [0.42, 0.50, 0.60, 0.66, 0.72];
const TUFT_R_RAND: [f32; 5] = [0.30, 0.36, 0.52, 0.60, 0.66];

// Sparse/airy fill
const LEAF_SPHERE_Y_SCALE: f32 = 1.16;
const LEAF_SHELL_THRESH: f32 = 0.90;

// TIP: visible but airy
const TIP_GUARANTEED_GATE_MASK: u32 = 1;           // keep ~1/2 candidates
const TIP_GUARANTEED_INTERIOR_KEEP_MASK: u32 = 31; // keep 1/32 interior
const TIP_GUARANTEED_SHELL_DROP_MASK: u32 = 3;     // drop 1/4 near shell

// SLEEVE: very sparse
const TUFT_SPARSE_GATE_MASK: u32 = 15;             // keep ~1/16 candidates
const TUFT_SPARSE_INTERIOR_KEEP_MASK: u32 = 255;   // keep 1/256 interior
const TUFT_SPARSE_SHELL_DROP_MASK: u32 = 3;        // drop 1/4 near shell

// Trunk wobble (meters)
const TRUNK_WOBBLE_M_MAX: f32 = 0.25;

// ----------------------------------------
// Crown at trunk tip (prevents "pruned top")
// ----------------------------------------

const TOP_CROWN_ENABLE: bool = true;
const TOP_CROWN_RING_TUFTS: usize = 6;
const TOP_CROWN_R_SCALE: f32 = 1.65;
const TOP_CROWN_RING_RAD_SCALE: f32 = 0.85;
const TOP_CROWN_LIFT_M: f32 = 0.45;

// ================================================================================================

/// Procedural tree instance (voxel units for positions/sizes).
#[derive(Clone, Copy)]
struct Tree {
    tx: i32,
    tz: i32,
    base_y: i32,   // touches ground
    trunk_h: i32,  // voxels
    crown_r: i32,  // voxels (horizontal extent)
    canopy_h: i32, // conservative bounds / variety
    trunk_r0: f32, // voxels radius at base
    trunk_r1: f32, // voxels radius near top
    seed: u32,
}

/// A single curved branch segment (cubic bezier), plus metadata for recursion.
#[derive(Clone, Copy)]
struct Branch {
    ax: f32,
    ay: f32,
    az: f32,
    c1x: f32,
    c1y: f32,
    c1z: f32,
    c2x: f32,
    c2y: f32,
    c2z: f32,
    bx: f32,
    by: f32,
    bz: f32,
    r0: f32,
    r1: f32,
    len: f32,
    depth: u8,
    seed: u32,
}

/// Per-chunk cache of trees that can affect material queries.
pub struct TreeCache {
    trees: Vec<Tree>,
}

/// Chunk-local voxel mask for trees (fast O(1) queries in the chunk build).
/// mask codes: 0 = none, 1 = wood, 2 = leaf
pub struct TreeMaskCache {
    pub origin: [i32; 3], // chunk origin in world-voxel coords
    pub size: i32,        // chunk side in voxels
    mask: Vec<u8>,
    stride_z: usize,
    stride_y: usize,
}

#[inline(always)]
fn idx3_strided(stride_z: usize, stride_y: usize, x: i32, y: i32, z: i32) -> usize {
    (y as usize) * stride_y + (z as usize) * stride_z + (x as usize)
}

impl TreeMaskCache {
    #[inline(always)]
    pub fn contains_point_fast(&self, x: i32, y: i32, z: i32) -> u8 {
        let lx = x - self.origin[0];
        let ly = y - self.origin[1];
        let lz = z - self.origin[2];
        if (lx | ly | lz) < 0 || lx >= self.size || ly >= self.size || lz >= self.size {
            return 0;
        }
        self.mask[idx3_strided(self.stride_z, self.stride_y, lx, ly, lz)]
    }

    #[inline(always)]
    pub fn material_fast(&self, x: i32, y: i32, z: i32) -> u32 {
        match self.contains_point_fast(x, y, z) {
            1 => WOOD,
            2 => LEAF,
            _ => AIR,
        }
    }

    #[inline(always)]
    fn write_leaf(&mut self, lx: i32, ly: i32, lz: i32) {
        if (lx | ly | lz) < 0 || lx >= self.size || ly >= self.size || lz >= self.size {
            return;
        }
        let i = idx3_strided(self.stride_z, self.stride_y, lx, ly, lz);
        if self.mask[i] != 1 {
            self.mask[i] = 2;
        }
    }

    #[inline(always)]
    fn write_wood(&mut self, lx: i32, ly: i32, lz: i32) {
        if (lx | ly | lz) < 0 || lx >= self.size || ly >= self.size || lz >= self.size {
            return;
        }
        let i = idx3_strided(self.stride_z, self.stride_y, lx, ly, lz);
        self.mask[i] = 1;
    }
}

impl WorldGen {
    // -------------------------------------------------------------------------
    // Small math helpers
    // -------------------------------------------------------------------------

    #[inline(always)]
    fn lerp(a: f32, b: f32, t: f32) -> f32 {
        a + (b - a) * t
    }

    #[inline(always)]
    fn s11(n: u32) -> f32 {
        (u01(n) - 0.5) * 2.0
    }

    #[inline(always)]
    fn bezier3(a: f32, b: f32, c: f32, d: f32, t: f32) -> f32 {
        let u = 1.0 - t;
        u * u * u * a + 3.0 * u * u * t * b + 3.0 * u * t * t * c + t * t * t * d
    }

    #[inline(always)]
    fn bezier3_tangent(a: f32, b: f32, c: f32, d: f32, t: f32) -> f32 {
        let u = 1.0 - t;
        3.0 * u * u * (b - a) + 6.0 * u * t * (c - b) + 3.0 * t * t * (d - c)
    }

    #[inline(always)]
    fn bez_point(b: &Branch, t: f32) -> (f32, f32, f32) {
        (
            Self::bezier3(b.ax, b.c1x, b.c2x, b.bx, t),
            Self::bezier3(b.ay, b.c1y, b.c2y, b.by, t),
            Self::bezier3(b.az, b.c1z, b.c2z, b.bz, t),
        )
    }

    #[inline(always)]
    fn bez_tangent(b: &Branch, t: f32) -> (f32, f32, f32) {
        (
            Self::bezier3_tangent(b.ax, b.c1x, b.c2x, b.bx, t),
            Self::bezier3_tangent(b.ay, b.c1y, b.c2y, b.by, t),
            Self::bezier3_tangent(b.az, b.c1z, b.c2z, b.bz, t),
        )
    }

    #[inline(always)]
    fn norm3(x: f32, y: f32, z: f32) -> (f32, f32, f32) {
        let inv = 1.0 / (x * x + y * y + z * z).sqrt().max(1e-6);
        (x * inv, y * inv, z * inv)
    }

    #[inline(always)]
    fn cross3(ax: f32, ay: f32, az: f32, bx: f32, by: f32, bz: f32) -> (f32, f32, f32) {
        (ay * bz - az * by, az * bx - ax * bz, ax * by - ay * bx)
    }

    /// Orthonormal basis around direction `w` (unit). Returns (u, v, w).
    #[inline(always)]
    fn basis_from_w(
        w: (f32, f32, f32),
    ) -> ((f32, f32, f32), (f32, f32, f32), (f32, f32, f32)) {
        let (wx, wy, wz) = w;
        let (hx, hy, hz) = if wy.abs() < 0.95 {
            (0.0, 1.0, 0.0)
        } else {
            (1.0, 0.0, 0.0)
        };
        let (ux, uy, uz) = Self::cross3(hx, hy, hz, wx, wy, wz);
        let (ux, uy, uz) = Self::norm3(ux, uy, uz);
        let (vx, vy, vz) = Self::cross3(wx, wy, wz, ux, uy, uz);
        ((ux, uy, uz), (vx, vy, vz), (wx, wy, wz))
    }

    // -------------------------------------------------------------------------
    // Knob helpers (compact)
    // -------------------------------------------------------------------------

    #[inline(always)]
    fn idx4(d: u8) -> usize {
        (d as usize).min(3)
    }
    #[inline(always)]
    fn idx5(d: u8) -> usize {
        (d as usize).min(4)
    }

    #[inline(always)]
    fn child_count_for_depth(depth: u8, base: u32) -> usize {
        let i = Self::idx4(depth);
        CHILD_COUNT_MIN[i] + (base % (CHILD_COUNT_RAND[i] as u32 + 1)) as usize
    }

    #[inline(always)]
    fn spawn_thin_mask(depth: u8) -> u32 {
        CHILD_SPAWN_THIN_MASK[Self::idx4(depth)]
    }

    #[inline(always)]
    fn shrink_for_child_depth(depth: u8) -> f32 {
        // child depth starts at 1, so map 1->0, 2->1, 3->2, 4+->3
        let i = ((depth as usize).saturating_sub(1)).min(3);
        CHILD_SHRINK[i]
    }

    #[inline(always)]
    fn sleeve_n(depth: u8) -> usize {
        LEAF_SLEEVE_N[Self::idx5(depth)]
    }

    #[inline(always)]
    fn tuft_r_m(depth: u8, seed: u32) -> f32 {
        let i = Self::idx5(depth);
        TUFT_R_BASE[i] + TUFT_R_RAND[i] * u01(hash_u32(seed))
    }

    // -------------------------------------------------------------------------
    // Tree placement + params
    // -------------------------------------------------------------------------

    #[inline]
    fn tree_at_meter_cell(
        &self,
        xm: i32,
        zm: i32,
    ) -> Option<(u32 /*seed*/, i32 /*trunk_h_vox*/, i32 /*crown_r_vox*/)> {
        let r = hash2(self.seed, xm, zm);
        if (r % TREE_CELL_MOD) != 0 {
            return None;
        }

        let trunk_h_m = 5 + (hash_u32(r) % 6) as i32; // 5..10m
        let crown_r_m = 3 + (hash_u32(r ^ 0xBEEF) % 4) as i32; // 3..6m
        let vpm = config::VOXELS_PER_METER;

        Some((r, trunk_h_m * vpm, crown_r_m * vpm))
    }

    #[inline]
    fn tree_params_at_trunk(&self, tx: i32, tz: i32, ground: i32) -> Option<Tree> {
        let xm = tx.div_euclid(config::VOXELS_PER_METER);
        let zm = tz.div_euclid(config::VOXELS_PER_METER);
        let (seed, trunk_h, crown_r) = self.tree_at_meter_cell(xm, zm)?;

        let vpm = config::VOXELS_PER_METER as f32;

        // trunk radii (voxels): base ~0.45..0.75m, top ~0.18..0.30m
        let r0 = 0.45 * vpm + u01(hash_u32(seed ^ 0x1111)) * (0.30 * vpm);
        let r1 = 0.18 * vpm + u01(hash_u32(seed ^ 0x2222)) * (0.12 * vpm);

        // kept for conservative bounds / variety
        let canopy_h =
            ((2.5 * vpm) + u01(hash_u32(seed ^ 0x3333)) * (2.0 * vpm)).round() as i32;

        Some(Tree {
            tx,
            tz,
            base_y: ground,
            trunk_h,
            crown_r,
            canopy_h,
            trunk_r0: r0.max(1.0),
            trunk_r1: r1.max(1.0),
            seed,
        })
    }

    /// Build a per-chunk tree cache. Call once per chunk build.
    pub fn build_tree_cache<F: Fn(i32, i32) -> i32>(
        &self,
        chunk_ox: i32,
        chunk_oz: i32,
        chunk_size: i32,
        height_at: &F,
    ) -> TreeCache {
        let vpm = config::VOXELS_PER_METER;

        // Extra slack because canopy tufts can extend beyond crown_r
        let pad_m = 10;

        let xm0 = chunk_ox.div_euclid(vpm) - pad_m;
        let xm1 = (chunk_ox + chunk_size).div_euclid(vpm) + pad_m;
        let zm0 = chunk_oz.div_euclid(vpm) - pad_m;
        let zm1 = (chunk_oz + chunk_size).div_euclid(vpm) + pad_m;

        let mut trees = Vec::new();

        for zm in zm0..=zm1 {
            for xm in xm0..=xm1 {
                if self.tree_at_meter_cell(xm, zm).is_none() {
                    continue;
                }

                let tx = xm * vpm;
                let tz = zm * vpm;
                let ground = height_at(tx, tz);

                let Some(t) = self.tree_params_at_trunk(tx, tz, ground) else {
                    continue;
                };

                // Conservative XZ AABB reject vs chunk footprint
                let r = t.crown_r + 5 * vpm; // extra slack for large tufts
                let x0 = t.tx - r;
                let x1 = t.tx + r;
                let z0 = t.tz - r;
                let z1 = t.tz + r;

                let cx0 = chunk_ox;
                let cx1 = chunk_ox + chunk_size;
                let cz0 = chunk_oz;
                let cz1 = chunk_oz + chunk_size;

                if x1 < cx0 || x0 > cx1 || z1 < cz0 || z0 > cz1 {
                    continue;
                }

                trees.push(t);
            }
        }

        TreeCache { trees }
    }

    /// Build a tree cache + chunk-local voxel mask (fast O(1) tree material queries).
    pub fn build_tree_cache_with_mask<F: Fn(i32, i32) -> i32>(
        &self,
        chunk_ox: i32,
        chunk_oy: i32,
        chunk_oz: i32,
        chunk_size: i32,
        height_at: &F,
        cancel: &std::sync::atomic::AtomicBool,
    ) -> (TreeCache, TreeMaskCache) {
        let cache = self.build_tree_cache(chunk_ox, chunk_oz, chunk_size, height_at);

        let side = chunk_size.max(1) as i32;
        let side_u = side as usize;

        let mask = vec![0u8; side_u * side_u * side_u];

        let mut out = TreeMaskCache {
            origin: [chunk_ox, chunk_oy, chunk_oz],
            size: side,
            mask,
            stride_z: side_u,
            stride_y: side_u * side_u,
        };

        for t in &cache.trees {
            if cancel.load(std::sync::atomic::Ordering::Relaxed) {
                break;
            }
            self.raster_tree_into_mask(t, &mut out);
        }

        (cache, out)
    }

    // -------------------------------------------------------------------------
    // Geometry helpers
    // -------------------------------------------------------------------------

    #[inline]
    fn trunk_radius_at(tree: &Tree, y: i32) -> f32 {
        let t = ((y - tree.base_y) as f32 / (tree.trunk_h as f32)).clamp(0.0, 1.0);
        tree.trunk_r0 + (tree.trunk_r1 - tree.trunk_r0) * t
    }

    #[inline]
    fn trunk_wobble(&self, tree: &Tree, y: i32) -> (f32, f32) {
        let t = ((y - tree.base_y) as f32 / (tree.trunk_h as f32)).clamp(0.0, 1.0);

        let a = u01(hash_u32(tree.seed ^ 0xA001 ^ (y as u32).wrapping_mul(97)));
        let b = u01(hash_u32(tree.seed ^ 0xA002 ^ (y as u32).wrapping_mul(193)));

        let amp = TRUNK_WOBBLE_M_MAX * (config::VOXELS_PER_METER as f32) * t;
        ((a - 0.5) * 2.0 * amp, (b - 0.5) * 2.0 * amp)
    }

    #[inline]
    fn dist2_point_segment(
        px: f32,
        py: f32,
        pz: f32,
        ax: f32,
        ay: f32,
        az: f32,
        bx: f32,
        by: f32,
        bz: f32,
    ) -> (f32 /*d2*/, f32 /*t*/) {
        let abx = bx - ax;
        let aby = by - ay;
        let abz = bz - az;

        let apx = px - ax;
        let apy = py - ay;
        let apz = pz - az;

        let ab2 = abx * abx + aby * aby + abz * abz;
        if ab2 <= 1e-8 {
            return (apx * apx + apy * apy + apz * apz, 0.0);
        }

        let t = ((apx * abx + apy * aby + apz * abz) / ab2).clamp(0.0, 1.0);
        let cx = ax + t * abx;
        let cy = ay + t * aby;
        let cz = az + t * abz;

        let dx = px - cx;
        let dy = py - cy;
        let dz = pz - cz;

        (dx * dx + dy * dy + dz * dz, t)
    }

    // -------------------------------------------------------------------------
    // Primary layout
    // -------------------------------------------------------------------------

    #[inline]
    fn primary_count(&self, tree: &Tree) -> usize {
        let r = hash_u32(tree.seed ^ 0xBABA_1234);
        let span = (PRIMARY_MAX - PRIMARY_MIN + 1) as u32;
        let mut n = PRIMARY_MIN + (r % span) as usize;

        // tiny bias extremes sometimes
        if (r & 31) == 0 {
            n = PRIMARY_MIN;
        } else if (r & 63) == 1 {
            n = PRIMARY_MAX;
        }
        n.min(PRIMARY_MAX_CLAMP)
    }

    fn primary_starts(&self, tree: &Tree, count: usize) -> [i32; 32] {
        let mut out = [tree.base_y; 32];

        let y_lo = tree.base_y + (tree.trunk_h * PRIMARY_START_Y_LO_FRAC) / 100;
        let y_hi = tree.base_y + (tree.trunk_h * PRIMARY_START_Y_HI_FRAC) / 100;

        for i in 0..count.min(32) {
            let t = if count <= 1 {
                0.5
            } else {
                (i as f32) / ((count - 1) as f32)
            };
            let y_base = (Self::lerp(y_lo as f32, y_hi as f32, t)) as i32;

            let r = hash_u32(tree.seed ^ 0xC0DE_0001 ^ (i as u32).wrapping_mul(0x9E37_79B9));
            let jitter =
                (Self::s11(r ^ 0x1111) * PRIMARY_START_JITTER_FRAC * (tree.trunk_h as f32)) as i32;
            out[i] = (y_base + jitter).clamp(y_lo, y_hi);
        }

        // insertion sort ascending
        for i in 1..count.min(32) {
            let mut j = i;
            while j > 0 && out[j - 1] > out[j] {
                out.swap(j - 1, j);
                j -= 1;
            }
        }

        out
    }

    // -------------------------------------------------------------------------
    // Branch generation
    // -------------------------------------------------------------------------

    fn child_branches_from_parent(&self, parent: &Branch, tree_seed: u32, out: &mut Vec<Branch>) {
        if parent.depth >= MAX_BRANCH_DEPTH {
            return;
        }

        let vpm = config::VOXELS_PER_METER as f32;
        let base = hash_u32(parent.seed ^ 0xCC11_0000);

        let child_count = Self::child_count_for_depth(parent.depth, base);

        for j in 0..child_count {
            let sj = hash_u32(base ^ (j as u32).wrapping_mul(0x9E37_79B9));

            if (sj & Self::spawn_thin_mask(parent.depth)) != 0 {
                continue;
            }

            let t = (CHILD_SPAWN_T_MIN + CHILD_SPAWN_T_RAND * u01(sj ^ 0x1111)).clamp(0.0, 1.0);

            let (ax, ay, az) = Self::bez_point(parent, t);
            let (tx, ty, tz) = Self::bez_tangent(parent, t);
            let w = Self::norm3(tx, ty, tz);
            let (u, v, w) = Self::basis_from_w(w);

            let phi = u01(sj ^ 0xFACE_B00C) * std::f32::consts::TAU;
            let (cs, sn) = (phi.cos(), phi.sin());
            let sideways = (u.0 * cs + v.0 * sn, u.1 * cs + v.1 * sn, u.2 * cs + v.2 * sn);

            let depth = parent.depth + 1;

            let max_from_parent = parent.len * (CHILD_MAXLEN_A - CHILD_MAXLEN_B * (depth as f32));
            let mut len =
                (CHILD_LEN_M_MIN * vpm + u01(sj ^ 0x2222) * (CHILD_LEN_M_RAND * vpm)).min(
                    max_from_parent,
                );
            len = len.max(CHILD_LEN_M_FLOOR * vpm);

            let fan_amp = CHILD_FAN_AMP_BASE + CHILD_FAN_AMP_DEPTH * (depth as f32);
            let fan = Self::s11(sj ^ 0x3333) * fan_amp;

            let up = 1.65 * (CHILD_UP_BASE + CHILD_UP_DEPTH * (depth as f32))
                + 1.25 * (CHILD_UP_RAND * u01(sj ^ 0x4444));

            let dirx = (w.0 + sideways.0 * fan).clamp(-2.0, 2.0);
            let diry = (w.1 + sideways.1 * fan + up).clamp(0.15, 3.0);
            let dirz = (w.2 + sideways.2 * fan).clamp(-2.0, 2.0);
            let (dirx, diry, dirz) = Self::norm3(dirx, diry, dirz);

            let pr = parent.r0 + (parent.r1 - parent.r0) * t;

            let shrink = Self::shrink_for_child_depth(depth);
            let r0 = (pr * shrink).max(CHILD_R0_MIN_VOX);
            let r1 =
                (r0 * (CHILD_R1_SCALE_BASE + CHILD_R1_SCALE_RAND * u01(sj ^ 0x5555))).max(
                    CHILD_R1_MIN_VOX,
                );

            let bx = ax + dirx * len;
            let by = ay + diry * len;
            let bz = az + dirz * len;

            let bend = (CHILD_BEND_M_MIN * vpm) + (CHILD_BEND_M_RAND * vpm) * u01(sj ^ 0x6666);

            let k1 = Self::s11(sj ^ 0x7777);
            let k2 = Self::s11(sj ^ 0x8888);
            let u1 = Self::s11(sj ^ 0x9999);
            let u2 = Self::s11(sj ^ 0xAAAA);

            let c1x = ax + dirx * (CHILD_C1_T * len)
                + sideways.0 * (bend * CHILD_C1_BEND_SCALE * k1);
            let c1y = ay + diry * (CHILD_C1_T * len) + (bend * CHILD_C1_Y_BEND_SCALE * u1.abs());
            let c1z = az + dirz * (CHILD_C1_T * len)
                + sideways.2 * (bend * CHILD_C1_BEND_SCALE * k1);

            let c2x = ax + dirx * (CHILD_C2_T * len)
                + sideways.0 * (bend * CHILD_C2_BEND_SCALE * k2);
            let c2y = ay + diry * (CHILD_C2_T * len) + (bend * CHILD_C2_Y_BEND_SCALE * u2.abs());
            let c2z = az + dirz * (CHILD_C2_T * len)
                + sideways.2 * (bend * CHILD_C2_BEND_SCALE * k2);

            out.push(Branch {
                ax,
                ay,
                az,
                c1x,
                c1y,
                c1z,
                c2x,
                c2y,
                c2z,
                bx,
                by,
                bz,
                r0,
                r1,
                len,
                depth,
                seed: hash_u32(tree_seed ^ sj ^ 0xBEEF_1234),
            });
        }
    }

    // -------------------------------------------------------------------------
    // Rasterization into chunk-local mask
    // -------------------------------------------------------------------------

    fn raster_tree_into_mask(&self, tree: &Tree, out: &mut TreeMaskCache) {
        let side = out.size;

        // --- trunk ---
        let top_y = tree.base_y + tree.trunk_h;
        let y0 = tree.base_y.max(out.origin[1]);
        let y1 = top_y.min(out.origin[1] + side - 1);

        for wy in y0..=y1 {
            let (wx, wz) = self.trunk_wobble(tree, wy);
            let cx = tree.tx as f32 + wx;
            let cz = tree.tz as f32 + wz;
            let rr = Self::trunk_radius_at(tree, wy).max(1.0);
            let r = rr.ceil() as i32;
            let rr2 = rr * rr;

            let minx = (cx.floor() as i32 - r).max(out.origin[0]);
            let maxx = (cx.ceil() as i32 + r).min(out.origin[0] + side - 1);
            let minz = (cz.floor() as i32 - r).max(out.origin[2]);
            let maxz = (cz.ceil() as i32 + r).min(out.origin[2] + side - 1);

            for x in minx..=maxx {
                let dx = (x as f32) - cx;
                let dx2 = dx * dx;
                for z in minz..=maxz {
                    let dz = (z as f32) - cz;
                    if dx2 + dz * dz <= rr2 {
                        out.write_wood(x - out.origin[0], wy - out.origin[1], z - out.origin[2]);
                    }
                }
            }
        }

        // --- top crown (leaf cluster at trunk tip) ---
        if TOP_CROWN_ENABLE {
            let vpm_f = config::VOXELS_PER_METER as f32;

            let tip_y = tree.base_y + tree.trunk_h;
            let (twx, twz) = self.trunk_wobble(tree, tip_y);

            let cx = tree.tx as f32 + twx;
            let cy = tip_y as f32 + TOP_CROWN_LIFT_M * vpm_f;
            let cz = tree.tz as f32 + twz;

            let crown_r =
                Self::tuft_r_m(0, tree.seed ^ 0xC0A7_0001) * vpm_f * TOP_CROWN_R_SCALE;

            // center tuft (tip profile)
            self.raster_sphere_leaf_tuft_with_masks(
                out,
                cx,
                cy,
                cz,
                crown_r,
                tree.seed ^ 0xC0A7_CE17,
                TIP_GUARANTEED_GATE_MASK,
                TIP_GUARANTEED_INTERIOR_KEEP_MASK,
                TIP_GUARANTEED_SHELL_DROP_MASK,
            );

            // ring tufts (sleeve profile) for a crown silhouette
            let ring_r = crown_r * TOP_CROWN_RING_RAD_SCALE;
            for i in 0..TOP_CROWN_RING_TUFTS {
                let rr = hash_u32(tree.seed ^ 0xC0A7_1E99 ^ (i as u32).wrapping_mul(0x9E37_79B9));
                let ang = u01(rr ^ 0xA1) * std::f32::consts::TAU;

                let ox = ang.cos() * ring_r;
                let oz = ang.sin() * ring_r;
                let oy = Self::s11(rr ^ 0xB2) * (0.18 * vpm_f);

                self.raster_sphere_leaf_tuft_with_masks(
                    out,
                    cx + ox,
                    cy + oy,
                    cz + oz,
                    crown_r * (0.70 + 0.15 * u01(rr ^ 0xC3)),
                    tree.seed ^ rr ^ 0xC0A7_7AF7,
                    TUFT_SPARSE_GATE_MASK,
                    TUFT_SPARSE_INTERIOR_KEEP_MASK,
                    TUFT_SPARSE_SHELL_DROP_MASK,
                );
            }
        }

        // --- branches ---
        let vpm_f = config::VOXELS_PER_METER as f32;

        let primary_count = self.primary_count(tree);
        let starts = self.primary_starts(tree, primary_count);
        let ang0 = u01(hash_u32(tree.seed ^ 0xA0A0_0001)) * std::f32::consts::TAU;

        let mut branches: Vec<Branch> = Vec::with_capacity(BRANCH_CAP.min(1024));

        // primary branches
        for i in 0..primary_count.min(32) {
            let sy = starts[i];
            let br_seed = hash_u32(tree.seed ^ 0xB000 ^ (i as u32).wrapping_mul(0x9E37_79B9));

            let ang_j = Self::s11(hash_u32(br_seed ^ 0xABCD_0001)) * PRIMARY_ANG_JITTER;
            let ang =
                ang0 + (i as f32) * (std::f32::consts::TAU / (primary_count as f32)) + ang_j;

            let dirx = ang.cos();
            let dirz = ang.sin();

            let len = (PRIMARY_LEN_M_MIN * vpm_f)
                + u01(hash_u32(br_seed ^ 0x1111)) * (PRIMARY_LEN_M_RAND * vpm_f);

            let h = ((sy - tree.base_y) as f32 / (tree.trunk_h as f32)).clamp(0.0, 1.0);
            let p = u01(hash_u32(br_seed ^ 0x2222));
            let pitch = (PRIMARY_PITCH_BASE + PRIMARY_PITCH_H_SCALE * h)
                + (p * p) * (PRIMARY_PITCH_QUAD_BASE + PRIMARY_PITCH_QUAD_H_SCALE * h);

            let br0 = (PRIMARY_R0_M_MIN * vpm_f)
                + u01(hash_u32(br_seed ^ 0x3333)) * (PRIMARY_R0_M_RAND * vpm_f);
            let br1 = br0
                * (PRIMARY_R1_SCALE_MIN + PRIMARY_R1_SCALE_RAND * u01(hash_u32(br_seed ^ 0x3334)));

            let (twx, twz) = self.trunk_wobble(tree, sy);
            let ax = tree.tx as f32 + twx;
            let ay = sy as f32;
            let az = tree.tz as f32 + twz;

            let bx = ax + dirx * len;
            let by = ay + pitch * len;
            let bz = az + dirz * len;

            let bend = (PRIMARY_BEND_M_MIN * vpm_f)
                + (PRIMARY_BEND_M_RAND * vpm_f) * u01(hash_u32(br_seed ^ 0x9000));
            let k1 = Self::s11(hash_u32(br_seed ^ 0x9001));
            let k2 = Self::s11(hash_u32(br_seed ^ 0x9002));
            let u1 = Self::s11(hash_u32(br_seed ^ 0x9003));
            let u2 = Self::s11(hash_u32(br_seed ^ 0x9004));

            let perpx = -dirz;
            let perpz = dirx;

            let c1x = ax + dirx * (PRIMARY_C1_T * len)
                + perpx * (bend * (PRIMARY_C1_BEND_SCALE * k1));
            let c1z = az + dirz * (PRIMARY_C1_T * len)
                + perpz * (bend * (PRIMARY_C1_BEND_SCALE * k1));
            let c1y = ay + (pitch * len) * PRIMARY_C1_T + (PRIMARY_C1_Y_BEND_SCALE * bend * u1);

            let c2x = ax + dirx * (PRIMARY_C2_T * len)
                + perpx * (bend * (PRIMARY_C2_BEND_SCALE * k2));
            let c2z = az + dirz * (PRIMARY_C2_T * len)
                + perpz * (bend * (PRIMARY_C2_BEND_SCALE * k2));
            let c2y = ay + (pitch * len) * PRIMARY_C2_T + (PRIMARY_C2_Y_BEND_SCALE * bend * u2);

            branches.push(Branch {
                ax,
                ay,
                az,
                c1x,
                c1y,
                c1z,
                c2x,
                c2y,
                c2z,
                bx,
                by,
                bz,
                r0: br0.max(1.0),
                r1: br1.max(0.80),
                len,
                depth: 0,
                seed: hash_u32(tree.seed ^ br_seed ^ 0x1A2B_3C4D),
            });
        }

        // BFS recursion (generate)
        let mut k = 0usize;
        while k < branches.len() && branches.len() < BRANCH_CAP {
            let b = branches[k];
            self.child_branches_from_parent(&b, tree.seed, &mut branches);
            k += 1;
        }

        // wood raster
        for b in &branches {
            let len_m = b.len / vpm_f;
            let steps = (BRANCH_STEPS_BASE + (len_m / BRANCH_STEPS_LEN_DIV_M)).round() as i32;
            let steps = steps.clamp(BRANCH_STEPS_MIN, BRANCH_STEPS_MAX);
            self.raster_bezier_wood(out, b, steps);
        }

        // leaves raster
        for b in &branches {
            if (hash_u32(b.seed ^ 0x1357_2468) & LEAF_RARE_SKIP_MASK) == 0 {
                continue;
            }

            let tuft_r = Self::tuft_r_m(b.depth, b.seed ^ 0x4440) * vpm_f;

            // tip tuft
            if LEAF_ALWAYS_TIP_FOR_ALL_BRANCHES {
                self.raster_sphere_leaf_tuft_with_masks(
                    out,
                    b.bx,
                    b.by,
                    b.bz,
                    tuft_r,
                    b.seed ^ 0x1EE7_1EAF,
                    TIP_GUARANTEED_GATE_MASK,
                    TIP_GUARANTEED_INTERIOR_KEEP_MASK,
                    TIP_GUARANTEED_SHELL_DROP_MASK,
                );
            }

            // sleeve tufts along branch
            let sleeve_n = Self::sleeve_n(b.depth);
            for si in 0..sleeve_n {
                let rr = hash_u32(b.seed ^ 0x9000_1000 ^ (si as u32).wrapping_mul(0x9E37_79B9));
                let t = LEAF_SLEEVE_T_MIN + LEAF_SLEEVE_T_RAND * u01(rr ^ 0x0101);
                let (mx, my, mz) = Self::bez_point(b, t);

                let ox = Self::s11(rr ^ 0x0202) * (LEAF_SLEEVE_OFFSET_M_XZ * vpm_f);
                let oy = u01(rr ^ 0x0303) * (LEAF_SLEEVE_OFFSET_M_Y * vpm_f);
                let oz = Self::s11(rr ^ 0x0404) * (LEAF_SLEEVE_OFFSET_M_XZ * vpm_f);

                self.raster_sphere_leaf_tuft_with_masks(
                    out,
                    mx + ox,
                    my + oy,
                    mz + oz,
                    tuft_r * (0.55 + 0.10 * (si as f32)),
                    b.seed ^ rr ^ 0x2AA2_2AA2,
                    TUFT_SPARSE_GATE_MASK,
                    TUFT_SPARSE_INTERIOR_KEEP_MASK,
                    TUFT_SPARSE_SHELL_DROP_MASK,
                );
            }

            // extra offset tip tuft (disabled by LEAF_OFFSET_TIP_MASK=0)
            let h = hash_u32(b.seed ^ 0xABC0_0001);
            if (h & LEAF_OFFSET_TIP_MASK) != 0 {
                let rr = hash_u32(b.seed ^ 0xABC0_0002);
                let ox = Self::s11(rr ^ 0xABC1) * (LEAF_OFFSET_M_XZ * vpm_f);
                let oy = u01(rr ^ 0xABC2) * (LEAF_OFFSET_M_Y * vpm_f);
                let oz = Self::s11(rr ^ 0xABC3) * (LEAF_OFFSET_M_XZ * vpm_f);

                self.raster_sphere_leaf_tuft_with_masks(
                    out,
                    b.bx + ox,
                    b.by + oy,
                    b.bz + oz,
                    tuft_r * 0.75,
                    b.seed ^ 0x600D_600D,
                    TUFT_SPARSE_GATE_MASK,
                    TUFT_SPARSE_INTERIOR_KEEP_MASK,
                    TUFT_SPARSE_SHELL_DROP_MASK,
                );
            }
        }
    }

    // -------------------------------------------------------------------------
    // Wood rasterization
    // -------------------------------------------------------------------------

    fn raster_bezier_wood(&self, out: &mut TreeMaskCache, b: &Branch, steps: i32) {
        let steps = steps.max(2);
        let inv = 1.0 / (steps as f32);

        let mut px = b.ax;
        let mut py = b.ay;
        let mut pz = b.az;

        for i in 1..=steps {
            let t = (i as f32) * inv;

            let qx = Self::bezier3(b.ax, b.c1x, b.c2x, b.bx, t);
            let qy = Self::bezier3(b.ay, b.c1y, b.c2y, b.by, t);
            let qz = Self::bezier3(b.az, b.c1z, b.c2z, b.bz, t);

            let rr0 = b.r0 + (b.r1 - b.r0) * (((i - 1) as f32) * inv);
            let rr1 = b.r0 + (b.r1 - b.r0) * t;

            Self::raster_segment_wood_capsule_stamps(out, px, py, pz, qx, qy, qz, rr0, rr1);

            px = qx;
            py = qy;
            pz = qz;
        }
    }

    fn raster_segment_wood_capsule_stamps(
        out: &mut TreeMaskCache,
        ax: f32, ay: f32, az: f32,
        bx: f32, by: f32, bz: f32,
        r0: f32, r1: f32,
    ) {
        let vx = bx - ax;
        let vy = by - ay;
        let vz = bz - az;

        let len2 = vx*vx + vy*vy + vz*vz;
        if len2 <= 1e-8 {
            Self::stamp_sphere_wood(out, ax, ay, az, r0.max(r1));
            return;
        }
        let len = len2.sqrt();

        // Step size in voxels. 0.75 tends to be safe (no holes) but not too expensive.
        let step = 0.75_f32;
        let n = (len / step).ceil() as i32;

        let inv_n = 1.0 / (n as f32);

        for i in 0..=n {
            let t = (i as f32) * inv_n;
            let cx = ax + vx * t;
            let cy = ay + vy * t;
            let cz = az + vz * t;

            let r = r0 + (r1 - r0) * t;
            Self::stamp_sphere_wood(out, cx, cy, cz, r);
        }
    }

    fn stamp_sphere_wood(out: &mut TreeMaskCache, cx: f32, cy: f32, cz: f32, r: f32) {
        let rr = r.max(1.0);
        let ir = rr.ceil() as i32;
        let r2 = rr * rr;

        let minx = (cx.floor() as i32 - ir).max(out.origin[0]);
        let maxx = (cx.ceil()  as i32 + ir).min(out.origin[0] + out.size - 1);
        let miny = (cy.floor() as i32 - ir).max(out.origin[1]);
        let maxy = (cy.ceil()  as i32 + ir).min(out.origin[1] + out.size - 1);
        let minz = (cz.floor() as i32 - ir).max(out.origin[2]);
        let maxz = (cz.ceil()  as i32 + ir).min(out.origin[2] + out.size - 1);

        for y in miny..=maxy {
            let dy = (y as f32) - cy;
            let dy2 = dy * dy;
            for x in minx..=maxx {
                let dx = (x as f32) - cx;
                let dx2 = dx * dx;
                for z in minz..=maxz {
                    let dz = (z as f32) - cz;
                    if dx2 + dy2 + dz*dz <= r2 {
                        out.write_wood(x - out.origin[0], y - out.origin[1], z - out.origin[2]);
                    }
                }
            }
        }
    }


    // -------------------------------------------------------------------------
    // Leaf rasterization
    // -------------------------------------------------------------------------

    fn raster_sphere_leaf_tuft_with_masks(
        &self,
        out: &mut TreeMaskCache,
        cx: f32,
        cy: f32,
        cz: f32,
        r: f32,
        seed: u32,
        gate_mask: u32,
        interior_keep_mask: u32,
        shell_drop_mask: u32,
    ) {
        let rr = r.max(1.0);
        let ir = rr.ceil() as i32;

        let minx = (cx.floor() as i32 - ir).max(out.origin[0]);
        let maxx = (cx.ceil() as i32 + ir).min(out.origin[0] + out.size - 1);
        let miny = (cy.floor() as i32 - ir).max(out.origin[1]);
        let maxy = (cy.ceil() as i32 + ir).min(out.origin[1] + out.size - 1);
        let minz = (cz.floor() as i32 - ir).max(out.origin[2]);
        let maxz = (cz.ceil() as i32 + ir).min(out.origin[2] + out.size - 1);

        let r2 = rr * rr;

        for y in miny..=maxy {
            let py = y as f32;
            let dy = (py - cy) * LEAF_SPHERE_Y_SCALE;
            let dy2 = dy * dy;

            for x in minx..=maxx {
                let px = x as f32;
                let dx = px - cx;
                let dx2 = dx * dx;

                for z in minz..=maxz {
                    let pz = z as f32;
                    let dz = pz - cz;
                    let d2 = dx2 + dy2 + dz * dz;
                    if d2 > r2 {
                        continue;
                    }

                    // gate AFTER sphere test
                    if (hash3(seed ^ 0xA11C_E5ED, x, y, z) & gate_mask) != 0 {
                        continue;
                    }

                    // only now do sqrt + interior/shell hashing
                    let shell2 = (LEAF_SHELL_THRESH * rr) * (LEAF_SHELL_THRESH * rr);
                    if d2 < shell2 {
                        let n = hash3(seed ^ 0xCAFE_BABE, x, y, z);
                        if (n & interior_keep_mask) != 0 {
                            continue;
                        }
                    } else {
                        let n = hash3(seed ^ 0xD00D_F00D, x, y, z);
                        if (n & shell_drop_mask) == 0 {
                            continue;
                        }
                    }

                    out.write_leaf(x - out.origin[0], y - out.origin[1], z - out.origin[2]);
                }
            }
        }
    }

    // -------------------------------------------------------------------------
    // SVO bounds helper
    // -------------------------------------------------------------------------

    /// Used by the SVO builder to stamp conservative tree-top bounds.
    pub fn tree_instance_at_meter(&self, xm: i32, zm: i32) -> Option<(i32, i32)> {
        let (_seed, trunk_h_vox, crown_r_vox) = self.tree_at_meter_cell(xm, zm)?;
        Some((trunk_h_vox, crown_r_vox))
    }
}

